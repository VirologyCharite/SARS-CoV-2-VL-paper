---
title: "Statistical analysis for Science manuscript abi5273: Estimating infectiousness throughout SARS-CoV-2 infection course"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  bookdown::html_document2:
    css: code.css
    toc_depth: '3'
    df_print: paged
    code_folding: hide
    toc: true
    toc_float: true
    toc_collapsed: true
bibliography: refs.bib
---

```{r setup, include=FALSE}
show_code = T
knitr::opts_chunk$set(warning=F, message=F, fig.width=9, fig.align= 'center',root.dir = here::here(), echo = show_code)
library(data.table)
setDTthreads(1)
library(here)
library(ggplot2)
library(ggthemes)
library(patchwork)
library(kableExtra)
library(ggbeeswarm)
library(magrittr)
library(dplyr)
library(boot)
library(knitr)
library(english)
library(MASS)
library(flextable)
library(officer)
library(brms)
library(rstanarm)
library(extraDistr)
library(colorspace)
library(ggmosaic)
library(ggdist)

source(here("utils.R"))

# for mcmc sampling
n_warmup = 1000
n_samples = 1000

# minimum number of tests for time course data
min_N_tests = 3

# for kable tables 
table_format = "html"

dodge_with = .7
my_legend_position = c(0.3, 0.8)

testing = F
if (testing == T) {
  tc_days = c(-5:4, seq(5,25,2.5),40)
  thin = 20
  test_thin = 10
} else {
  tc_days = c(seq(-5,-3,by = .5),seq(-2.75,0,by = .25), seq(0.5,5,by = .5), seq(6,25,1),27,30,35,40)
  thin = 4
  test_thin = 1
}


HOSPITAL_TEST_CENTRE = c('H', 'ICU', 'IDW', 'WD')
PAMS_CENTRE = c("AIR", "C19", "SM")

```

`r ifelse(show_code == T, "The analysis pipeline makes heavy use of custom functions which can be found the the R-script utils.R.
This analysis documents the analysis steps and generates figures and tables for the paper. While this document shows the code for running the Bayesian analyses, due to their time-consuming nature they were implemented as standalone scripts.","")`


The document is organized as follows: The section *Data* data gives an overview of the data used for the investigations of viral load at the first positive test, viral load differences between B.1.1.7 and non-B.1.1.7 cases, viral load time course, and viral load - culture probability.  The section *Analysis* describes the analytic approaches, implements the analyses, verifies that model parameters were estimated reliably, and that the employed statistical models capture important characteristics of the observed data. The description of the viral load time course analysis includes descriptions of priors for the Bayesian analysis as well as prior predictive checks to examine that appropriate priors were chosen. The section *Results*  `r ifelse(show_code == T,"contains the code to calculate","calculates the")` posterior predictions, from which all reported results are derived, and generates the results presented in the main paper as well as supplementary analyses. The section *Figures* `r ifelse(show_code == T,"contains the code to generate","generates")` the figures for the results section of the main article.

# Data

The analysis uses following data files:

-   `viral-load-with-negatives.tsv.bz2` has first positive test results and initial negative test results
-   `Culture_probability_data_wild_type.xlsx` and `Culture_probability_data_wild_type_woelfel.csv` and contain culture-positivity data
-   `min-3-timeseries.json` has time course data of subjects with at least 3 test results
-   `Culture_probability_data_B.1.1.7.xlsx` has data from the culturing experiment conducted for the B.1.1.7 and B.1.177 types.


## RT-PCR test data

In this data analysis, subjects are classified into one of the following groups:

- Hospitalised: This includes subjects with a positive test, where the sample was taken in a stationary hospital ward. See table \@ref(tab:centreTable) groups of test centres or locations
- Pre-symptomatic, asymptomatic, and mildly-symptomatic (PAMS): This includes subjects where the first positive test was taken in a test centre established for SARS-CoV-2 testing and who later did not test positive in a hospital ward.
- Other: All subjects that do not fall into one of the first two groups.

```{r load1stPosData}
## get_full_data() loads and pre-processes the data. 
dt = get_full_data() %>%
  .[log10Load < 0, log10Load := NA] 
```


Table \@ref(tab:centreTable) gives an overview of the number of tests, subjects and positive tests in the different test centre types (testing locations).

```{r centreTable}
centre_table = 
  dt %>% 
  .[, .(`N centres` = length(unique(TestCentre)),
        `N tests`= .N,
        `N individuals` = length(unique(personHash)),
        `N positive` = sum(!is.na(log10Load)),
        `N hosp.` = sum(Hospitalized == T & !is.na(log10Load)),
        `% hosp.` = round(sum(Hospitalized == T & !is.na(log10Load))/sum(!is.na(log10Load))*100),
        `Mean VL` = round(mean(log10Load,na.rm = T),1)), 
   by = .(TestCentreCategory)] %>% 
  setnames(c("TestCentreCategory"), c("Centr abbr.")) %>% 
  .[, Status := ifelse(`Centr abbr.` %in% c("C19"),"Likely PAMS",
                       ifelse(`Centr abbr.` %in% c(HOSPITAL_TEST_CENTRE,"C19-H"),
                             "Likely hospitalized","Other"))] 

abbrevs = 
  matrix(c('Airport', 'AIR',
           'COVID-19 testing centre', 'C19',
           'COVID-19 testing centre\nlater hospitalized', 'C19-H',
           'Infectious diseases ward', 'IDW',
           'Company physician', 'CP',
           'Emergency department', 'ED',
           'Forensic medicine', 'FM',
           'Hospital', 'H',
           'Intensive care unit', 'ICU',
           'Other laboratory \n(not Labor Berlin)', 'L',
           'Labour ward', 'LW',
           'Outpatient department', 'OD',
           'Public health department ', 'PHD',
           'Unclassified', '?',
           'Sports Medicine', "SM",
           'Ward', 'WD',
           'Prison','PRI',
           'Age residence','RES'),
         nrow = 2) %>%
  t() %>%
  data.table() %>%
  setnames(c("V1","V2"), c("Centre type", "Centr abbr.")) 

centre_table = 
  merge(centre_table, abbrevs) %>% 
  .[,.(Status,`Centr abbr.`, `Centre type`,`N centres`,`N positive`, `N tests`, `N individuals`,`Mean VL`, `N hosp.`, `% hosp.`)] %>% 
  .[, `Positivity rate` := round(`N positive`/`N tests` *100,1)] %>% 
  .[order(Status,-`N tests`)]
 
caption_centre_table = paste("Test centre categories and test counts for",format(length(unique(dt$personHash)),big.mark = ","),"subjects.*")
note_centre_table = "First-positive RT-PCR tests are broken down according to test centre type. Each centre type category includes data from many different test centres. A category of Other is assigned to all those who were not at a centre testing people who were likely PAMS or likely hospitalized. For example, emergency departments fall into the Other category because subjects presenting there are not likely to be asymptomatic, but are not counted as formally hospitalized at that point."
centre_table %>% 
  kable(format = table_format,
        caption = caption_centre_table) %>%
  kable_styling(full_width = F) %>% 
  add_footnote(note_centre_table, notation="symbol")

centre_table[, `N centres` := NULL]
ft_centre_table = 
  do.call(rbind,
  lapply(unique(centre_table$Status), function(status) {
    status_val = paste0(
            status,"\n (",
            sum(centre_table[Status == status,`N positive`]),", ",
            round(sum(centre_table[Status == status,`N positive`])/
                    sum(centre_table$`N positive`)*100,1),"%)")
    centre_table[Status == status][,Status := status_val]
  }
  )) 

ft_centre_table[c(3:5,7:17), Status := ""]

ft_centre_table = 
  flextable(ft_centre_table) %>%
  autofit() %>%
  set_caption(caption = caption_centre_table) %>%
  footnote(i = 1,
           j = c(5),
           value = as_paragraph(
             c(note_centre_table)),
           ref_symbols = c("*"),
           part = "header",
           inline = TRUE) %>% 
  hline(i = c(1,5))

table_doc <- read_docx() %>% 
  body_add_flextable(ft_centre_table) %>%
  body_end_section_portrait() # a landscape section is ending here
```


The following table and figures provide an overview over the data used in the analysis of first positive RT-PCR tests.

```{r loadData}
my_breaks = c(seq(0,25,5),seq(35,65,10),120)
my_labels = c("0-5","5-10","10-15","15-20","20-25","25-35","35-45","45-55","55-65",">65")
## get_TC_data() loads and pre-processes the data. 
TC_data = get_TC_data()
time_course_table =  
  TC_data %>%
  .[, `Age category` := cut(Age, breaks = my_breaks, ordered_result = T,
                    labels = my_labels)] %>%
  .[day == 0, 
    list(`N time` = .N),
    by = .(`Age category`)] %>% 
  .[order(`Age category`)] %>%
  .[!is.na(`Age category`)]

dt[, positive := ifelse(is.na(log10Load),F,T)]

t1 = function(dt) {
  dt[, list(`N pos.` = sum(positive,na.rm = T),
            `pos. rate` = round((sum(positive,na.rm = T) / .N)*100,1),
            `log~10~load` = paste0(round(mean(log10Load,na.rm = T),1),
                                  " (",round(sd(log10Load,na.rm = T),2),")")),
     by = .(`Age category`)] %>%
    .[order(`Age category`)]
}
table_1 = 
  cbind(t1(dt),
        time_course_table[, .(`N time`)],
        t1(dt[Group == "PAMS"])[,-1,with = F],
        t1(dt[Hospital_centre == 1])[,-1,with = F])
table_1_caption = "Viral load by age groups for the full sample, pre-, asymptomatic, and mild- (PAMS) cases, and hospitalized cases"
table_1_note = "N pos. = number of positive tests, pos. rate = positivity rate, N time = number of cases with time course data."
tbl = 
  kable(table_1, digits = 1, 
        format = table_format,
        caption = table_1_caption) %>%
  add_header_above(c(" " = 1, "Full sample" = 4, "PAMS" = 3, "Hospitalized" = 3)) %>%
  kable_styling(full_width = F) %>%
  add_footnote(table_1_note, notation="symbol")
tbl

names(table_1)[6:8] = paste("P",names(table_1)[6:8])
names(table_1)[9:11] = paste("nP",names(table_1)[9:11])

ft = 
  flextable(table_1) %>%
  autofit() %>%
  set_caption(caption = table_1_caption) %>%
  footnote(i = 1,
           j = c(2,3,4,5),
           value = as_paragraph(
             c("number of positive tests",
               "proportion positive tests",
               "mean (standard deviation)",
               "number of cases with time course data")),
           ref_symbols = c("a", "b", "c","d"),
           part = "header",
           inline = TRUE)

save_as_docx(ft,path = "figures/Table1.docx")

table_doc <- table_doc %>%
  body_add_flextable(ft) %>%
  body_end_section_landscape() # a landscape section is ending here

rm(time_course_table)

```

```{r agesByMonth, fig.cap = "Number of ositive tests over time."}
## get_log10Load_data() loads and pre-processes the data.
bdata = 
  get_log10Load_data() 

lvls = do.call(c,lapply(levels(bdata$Month), function(x) substr(x,1,3)))
bdata %>% 
  .[, month := factor(as.numeric(Month), labels = lvls)] %>% 
  .[, AgeGroup_r := factor(AgeGroup, levels = rev(levels(bdata$AgeGroup)))]



p_N_age = 
  bdata %>% 
  ggplot(aes(x = Date, fill = AgeGroup_r)) + 
  geom_histogram(bins = 25) +
  scale_fill_ordinal(name = "Age group") +
  theme(legend.position = c(.3,.8)) +
  ylab("N") +
  xlab("Date")  +
  gg_text_size() + 
  gg_legend_size(2) + 
  scale_y_continuous(expand = expansion(0.005,0)) +
  theme(axis.text.x = element_text(size = 4)) + 
  geom_vline(xintercept = as.Date("2021-01-01"), col = "grey") 

p_N_age

```


The cobas and LC480 PCR systems appear to result in slightly different distributions of viral loads. 

```{r plotHistLoadByPCR, fig.cap= "Distribution of viral load by PCR system and clinical status."}
ggplot(bdata, aes(x = log10Load, fill = Group)) + 
  geom_histogram(bins = 30, alpha = .75) +
  xlab(expression(log[10]~viral~load)) + 
  facet_wrap(~PCR, nrow = 2, scale = "free_y", ncol = 2) +
  red_blue(1:3) + 
  theme(legend.position = "top")
```



```{r AgeDistPAMS, fig.cap = "Distribution of subject ages by clinical status."}
agehist_by_PAMS = 
  bdata %>% 
  .[, `Sub-sample` := Group] %>% 
  ggplot(aes(x = Age, fill = `Sub-sample`)) + 
  geom_histogram(alpha = .5, breaks = seq(0,101,1))  + 
  theme(legend.position = c(.8,.9)) + 
  ylab("Number of subjects") + 
  gg_add_grid() + 
  red_blue(1:3) + 
  gg_expand() + 
  gg_legend_size()

agehist_by_PAMS
```

```{r BeesswarmByPAMS, fig.cap = "Distribution of viral loads by subject ages and clinical status."}
bdata %>% 
  .[, Age5 := cut(Age,breaks = c(seq(0,95,by = 5),101), labels = paste0(seq(0,95,5),"-",seq(5,100,5)))] %>% 
  .[, Age5 := ordered(Age5)] %>% 
  .[, Group := factor(Group, levels = c("PAMS","Hospitalized","Other"))]

N_Age5_Group=
  bdata[, .(N = .N), by = .(Group,Age5)]

Group.labs = 
  c(PAMS = paste0("PAMS (",sum(bdata$Group == "PAMS"),")"),
    Hospitalized = paste0("Hospitalized (",sum(bdata$Group == "Hospitalized"),")"),
    Other = paste0("Other (",sum(bdata$Group == "Other"),")"))

beesPAMS =
  bdata %>% 
  ggplot(aes(x = Age5, y = log10Load, color = Group)) + 
  geom_quasirandom(method = "tukeyDense", size = .1) + 
  ylab(expression(log[10]~viral~load)) +
  red_blue(c(2,3,1)) +  
  geom_text(data = N_Age5_Group, aes(y = 11, label = N), size = 3, show.legend = F) +
  scale_y_continuous(expand = expansion(0,1), breaks = seq(2,10,2)) + 
  coord_cartesian(ylim = c(2.5,10.6)) + 
  facet_grid(Group~.,labeller = labeller(Group = Group.labs)) +
  gg_add_grid("y") +
  theme(strip.text.x = element_blank(), legend.position = "none") + 
  xlab("Age")

beesPAMS
```


```{r TopLoadCharacteristics, fig.height=12, Fig.cap = "Characteristics of subjects with first-positive viral load above the 95th percentile. The area of each square indicates the proportion of participants. Among subjects that were not identified as B.1.1.7 cases, PAMS subjects aged 20-60 and hospitalized patients aged 60-90 are the most important groups with high viral load. Among subjects identified as B.1.1.7, the proportion of PAMS cases is relatively higher, whereas the proportion of  cases with older age is smaller."}
tmp = 
  copy(bdata) %>% 
  .[, log10Load.cat := cut(log10Load, breaks = c(1.5,4,5:9,12))] %>% 
  .[, Age.cat := cut(Age, 
                     breaks = c(seq(0,90,10),101),
                     labels = paste0(seq(0,90,10),"-",seq(10,100,10)))] %>% 
  .[, rAge := round(Age/5)*5] %>% 
  .[, high.load := log10Load > 9] 


prop.gen = 
  tmp[, .(N.gen = .N), by = .(Group,Age.cat)] %>% 
  .[, prop.gen := N.gen/sum(N.gen)] %>% 
  setkeyv(c("Group","Age.cat"))

prop.high = 
  tmp[high.load == T, .(N.high = .N), by = .(Group,Age.cat)] %>% 
  .[, prop.high := N.high/sum(N.high)] %>% 
  setkeyv(c("Group","Age.cat")) %>% 
  .[prop.gen, rel.high := prop.high/prop.gen] %>% 
  setnames(.,"N.high","N with\nhigh load") 

p_rel_risk_high_load =
  prop.high  %>% 
  ggplot(aes(x = Age.cat, y = rel.high, color = Group, size = `N with\nhigh load`)) + 
  geom_hline(yintercept = 1, lty = 3) + 
  geom_point(alpha = .75) + 
  red_blue(1:3) + 
  ylab("Relative risk of high load") +
  xlab("Age category") + 
  ggtitle("B")

p_high_VL = 
  tmp[log10Load > quantile(bdata$log10Load,.95)] %>% 
  ggplot() +
  geom_mosaic(aes(product(Group , Age.cat), fill = Group), divider = ddecker(),) + 
  red_blue(1:3) +
  theme(axis.text.x = element_text(angle=90)) + 
  ylab("Clinical status") +
  xlab("Age category") + 
  ggtitle("A")


px = p_high_VL / p_rel_risk_high_load
px
ggsave(px, file = "figures/S3_p_high_VL.png", height = 25, width = 20, units = "cm", dpi = 600)
ggsave(px, file = "figures/S3_p_high_VL.pdf", height = 25, width = 20, units = "cm")

N_high_load = sum(tmp[,high.load == T])
p_high_load = round(mean(tmp[,high.load == T])*100,1)
N_high_load_PAMS20_60 = nrow(tmp[high.load == T & ((Age > 20 & Age < 60 & Group == "PAMS"))])
N_high_load_Hosp60 = nrow(tmp[high.load == T & ((Age > 60 & Group == "Hospitalized"))])
```

`r N_high_load` (`r p_high_load`)% subjects have a log~10˙ viral load higher than 9. To a large part, these are PAMS subjects aged 20 to 60 (N = `r N_high_load_PAMS20_60`, `r round(N_high_load_PAMS20_60/N_high_load*100,1)`%) or Hospitalized patients older than 60 years (`r N_high_load_Hosp60`, `r round(N_high_load_Hosp60/N_high_load*100,1)`%).


### Symptom onset data

For a subset of `r nrow(bdata[!is.na(Onset)])` subjects with positive test results data about symptom onset is available, of which `r nrow(bdata[!is.na(Onset) & Onset < 21])` remain after exclusion of cases who reported symptoms onset more than 3 weeks before the first positive test.



```{r FPloadOnset, fig.cap = "Association between viral load at first positive test and temporal distance to symptom onset by clinical status. Points depict raw data. The dotted line depicts the average regression line across the three groups. The figure shows that subjects who reported high viral loads were more likely tested close to symptom onset, and subjects who reported low viral loads were more likely tested more than a week before reported symptoms onset. After adjustment for time of testing relative to symptom onset, first positive tests for hospitalized patients are likely highest, though the current data set does not include sufficient PAMS cases for a reliable quantification. The analysis adjusted for PCR system, age, and test centre type."}
onset_data = 
  bdata[,.(Onset,Group,log10Load, PCR, Age,TestCentreCategory)] %>% 
  .[!is.na(Onset) & Onset <= 21 & Onset >= 0] #%>% 
  #.[Group == "Hospitalized" & TestCentreCategory == "C19", Group := "PAMS"]

if(file.exists("pdata/onset.Rdata")) {
  load("pdata/onset.Rdata")
} else {
  bfit_onset = brm(log10Load ~ Onset*Group + s(Age) + PCR + (1 | TestCentreCategory),
                 onset_data,
                 family = gaussian(),
                 backend = "cmdstanr",
                 adapt_delta = .99)
  save(bfit_onset,file = "pdata/onset.Rdata")
}

new_data = 
  expand.grid(Onset = 0:21,
              Group = levels(onset_data$Group))  %>% 
  data.table() %>% 
  .[, Age := mean(onset_data$Age)] %>% 
  .[, TestCentreCategory := names(sort(-table(onset_data$TestCentreCategory)))[1]] %>% 
  .[, PCR := names(sort(-table(onset_data$PCR)))[1]]
pep = 
  new_data %>% 
  cbind(t(posterior_epred(bfit_onset, newdata = new_data))) %>% 
  melt(id.vars = c(names(new_data))) %>% 
  .[, .draw := as.numeric(gsub("V","",variable))] %>% 
  .[, variable := NULL] %>% 
  get_stats(by = c("Onset","Group"))

N_table = 
  onset_data[,.(N = .N),by = Group] %>%
  .[, label := paste0(Group," (N = ",N,")")] %>% 
  .[c(3,2,1)]

setkeyv(pep,"Group")
setkeyv(N_table,"Group")
setkeyv(onset_data,"Group")
pep[N_table, label := label] %>% 
  .[, Group := label]
onset_data[N_table, label := label] %>% 
  .[, Group := label]

VL_by_onset = 
  pep %>% 
  ggplot(aes(x = Onset, y = mean, color = Group)) + 
  geom_line() + 
  conf_ribbon(pep, fill = "Group") + 
  geom_point(data = onset_data,aes(y = log10Load), alpha = .5, shape = 16) + 
  red_blue(c(3,1,2)) + 
  facet_wrap(~Group) + 
  ylab(expression(log[10]~viral~load)) + 
  xlab("Days from symptom onset") +
  theme(legend.position = "none") +
  geom_line(data = pep[,.(mean = mean(mean)), by = .(Onset)], aes(color = NULL), lty = 3)

ggsave(VL_by_onset,file = "figures/VL_by_onset.png", height = 10, width = 20, units = "cm")
ggsave(VL_by_onset,file = "figures/VL_by_onset.pdf", height = 10, width = 20, units = "cm")
VL_by_onset
rm(pep,bfit_onset,VL_by_onset)
```


## B.1.1.7 first positive test viral load data

Here is a short overview of first positive test viral load data from subjects with the B.1.1.7 variant of the virus, together with different comparison groups. The reasoning behind the ever-more restrictive comparison groups is to compare B.1.1.7 subjects to non-B.1.1.7 subjects that were tested in increasing temporal- and spatial proximity.

```{r loadB117BeeSwarm, fig.cap="Distribution of viral load for B.1.1.7 and non-B.1.1.7  cases for different data sub-sets.", fig.height= 10, fig.width=6}

B117data = 
  copy(bdata) %>% 
  .[, B117 := ifelse(B117 == 1, "B.1.1.7","non-B.1.1.7")]
B117.density.all = 
  B117data %>% 
  ggplot(aes(x = log10Load, fill = B117)) + 
  geom_density(alpha = .5, color = NA) + 
  gg_expand() + 
  scale_fill_manual(name = "All cases",
                    values = c("#7E6148FF","#00A087FF")) +
  ylab(expression(log[10]~viral~load))


B117data = B117data[B117CentreDay5 == 1]
B117.density.5 = 
  B117data %>% 
  ggplot(aes(x = log10Load, fill = B117)) + 
  geom_density(alpha = .5, color = NA) + 
  gg_expand() + 
  scale_fill_manual(name = "Within +/- 5 days\nof B1.1.7 cases",
                    values = c("#7E6148FF","#00A087FF")) +
  ylab(expression(log[10]~viral~load))

B117data = B117data[B117CentreDay1 == 1]
B117.density.1 = 
  B117data %>% 
  ggplot(aes(x = log10Load, fill = B117)) + 
  geom_density(alpha = .5, color = NA) + 
  gg_expand() + 
  scale_fill_manual(name = "Within +/- 1 day\nof B1.1.7 cases",
                    values = c("#7E6148FF","#00A087FF")) +
  ylab(expression(log[10]~viral~load))

B117data = 
  B117data %>%
  .[B117CentreDay1 == 1] 
CentresWithMin2Cases = 
  B117data[,.(N = .N), by = .(TestCentre)][N > 1,TestCentre]
B117data = B117data[TestCentre %in% CentresWithMin2Cases]
B117.density.1p = 
  B117data %>% 
  ggplot(aes(x = log10Load, fill = B117)) + 
  geom_density(alpha = .5, color = NA) + 
  gg_expand() + 
  scale_fill_manual(name = "Within +/- 1 day\nonly centres\nwith both types",
                    values = c("#7E6148FF","#00A087FF")) +
  ylab(expression(log[10]~viral~load))

B117.density.all / 
  B117.density.5 / 
  B117.density.1 / 
  B117.density.1p

rm(B117.density.all,B117.density.5,B117.density.1,B117.density.1p)
```

```{r Table1B117}

B117_table1 = 
  B117data %>% 
  .[, .(N = .N,
     `Mean age` = sprint_mci(Age,0),
     `Mean viral load` = sprint_mci(log10Load,1),
     `% hospitalized` = sprint_mcib(Hospitalized,0),
     `% PAMS` = sprint_mcib(PAMS1,1)),
   by = .(B117)] 

B117_table1 = 
  kable(B117_table1,
        format = table_format,
        caption = "Sample description for focussed B.1.1.7 analysis.")  %>% 
  kable_styling(full_width = F) %>%
  add_footnote("Numbers are means and 95% confidence intervals.",
               notation = "none")

B117_table1
```

A crude comparison of log~10~ viral load of B.1.1.7 and non-B.1.1.7 subjects suggests higher viral load in the former group in adults (see Figure \@ref(fig:loadB117byAge)). There is little data from children. 

```{r loadB117byAge, fig.cap="Viral load by age group, clinical status, and B.1.1.7. Lines indicate 95% confidence intervals. Confidence intervals cannot be shown when a group has only one member. This comparison uses the most restrictive data set, that includes B.1.1.7 cases only when there was a test result for a non-B.1.1.7 centre from the same location +/- one day."}
B117data %>% 
  .[, B.1.1.7 := B117] %>% 
  .[, AgeCat := cut(Age,breaks = c(0,20,65,101))]

B117data[, .(log10Load = mean(log10Load),
          sd = sd(log10Load), N = .N),
      by = .(Group,B.1.1.7,AgeCat)] %>% 
  .[, lower := log10Load + (sd/sqrt(N))*1.96] %>% 
  .[, upper := log10Load - (sd/sqrt(N))*1.96] %>% 
  setkeyv(c("AgeCat","Group","B.1.1.7")) %>% 
  ggplot(aes(x = AgeCat, y = log10Load, shape = Group, color = B.1.1.7)) + 
  geom_point(position = position_dodge(.5)) + 
  geom_linerange(aes(ymin = lower, ymax = upper),
                 position = position_dodge(.5)) + 
  green_brown() +
  xlab(expression(log[10]~viral~load))
```

## B.1.1.7 cell culture isolation data

Table \@ref(tab:B117CulturingData) gives an overview of the cell culturing data shown in figure  \@ref(fig:pB117CulturingPlot). 

```{r B117CulturingData }
# get_CP_data() loads and pre-processes the data. 
CP = 
  get_CP_data() %>% 
  .[Study == "Own data" & culture_positive == 1]

CPstats = 
  CP %>% 
  .[,.(log10Load = mean(log10Load), 
       sd = sd(log10Load),
       N = .N),
    by = .(Clade)] %>% 
  .[, lower := log10Load - 1.96 * (sd/sqrt(N))] %>% 
  .[, upper := log10Load + 1.96 * (sd/sqrt(N))]

CPdata = 
  get_CP_data() %>% 
  .[Study == "Own data"] %>%
  .[, `Culture positive` := ordered(if_else(culture_positive == 1,"Yes","No"), levels = c("Yes","No"))]
levels(CPdata$`Culture positive`) = c("Yes","No")

CPdataTBL = 
  CPdata[, .(N = .N,mean = mean(log10Load), sd = sd(log10Load)),
         by = .(Clade,`Culture positive`)]

CPdata_table = 
  kable(CPdataTBL,
        format = table_format,
        digits = c(0,0,1,2),
        caption = "Sample description for  B.1.1.7 culturing data")  %>% 
  kable_styling(full_width = F) 

if (file.exists("pdata/culture_fit.Rdata")) {
  load("pdata/culture_fit.Rdata")
} else {
  culture_fit = 
    brm(bf(log10Load ~ Clade,
           sigma ~ Clade),
        family = student(),
        CP,
        backend = "cmdstanr")
  save(culture_fit,file = "pdata/culture_fit.Rdata")
}

mean_difference = 
  culture_fit$fit %>% 
  as_draws() %>% 
  subset_draws("b_CladeB.1.1.7") %>% 
  as.numeric() %>% 
  sprint_stat(2)

sigma_par = 
  culture_fit$fit %>% 
    as_draws() %>% 
    subset_draws(c("b_sigma_Intercept","b_sigma_CladeB.1.1.7")) %>% 
  as_draws_matrix() 

sigma_difference = 
  sigma_par %*% matrix(c(1,0,1,1),ncol = 2) %>% 
  exp() %>% 
  apply(1,diff) %>% 
  sprint_stat(2)

CPdata_table
```

Application of the Inter-ocular trauma test to the culturing data does not indicate that the distribution of pre-culturing viral loads are different (or identical) for positive B.1.1.7 and B.1.177 cultures. (A Bayesian regression model confirms inconclusive results for the difference of means `r mean_difference` and for the difference of standard deviations `r sigma_difference`).

```{r pB117CulturingPlot, fig.cap="Pre-culturing viral loads split by clade and culturing outcome. The cross indicates mean (horizontal lines) and 95% confidence intervals (vertical lines) of pre-culturing viral loads for culture-positive samples."}
rm(mean_difference,sigma_par,sigma_difference)
p_culturing = 
  CPdata %>% 
  ggplot(aes(x = Clade, y = log10Load, color = `Culture positive`)) + 
  geom_quasirandom(data = CPdata[`Culture positive` == "Yes"]) +
  geom_quasirandom(data = CPdata[`Culture positive` == "No"], alpha = .25) +
  theme(legend.position ="top") + 
  scale_colour_manual(values = rev(diverge_hcl(2, palette = "Blue-Red 2"))) +
  geom_point(data = CPstats, shape = 3, size = 3, color = diverge_hcl(2, palette = "Blue-Red 2")[1]) + 
  geom_linerange(data = CPstats,aes(ymin = lower,ymax = upper),color = diverge_hcl(2, palette = "Blue-Red 2")[1]) + 
  ylab(expression(log[10]~viral~load~before~culturing))

ggsave(p_culturing, filename = "figures/S4_Culturing.png", width = 12, height = 12, units = "cm", dpi = 600)
ggsave(p_culturing, filename = "figures/S4_Culturing.pdf", width = 12, height = 12, units = "cm")

p_culturing
```

## RT-PCR time course data

For a subset of participants, multiple RT-PCR test results were available. These data can be used to estimate the time course of viral load. For this analysis we used data from participants with 3 or more RT-PCR results.

To enable a robust estimation of viral load time courses, we only included cases that fulfilled following criteria:

- at least 3 test results, at least two of which must be positive
- test results must cover a period of at least 5 days
- if the first and the last test are negative, the results need to cover a period of at least 10 days.
- at most an increase of five log~10~ load per day from the first to the second test

```{r timeCourseDataHist, fig.cap = "Distribution of age and number of tests of subjects included in the time course analysis.", results = F}
make_time_course_standata(
  max_diff_load_12perday = 5,
  ub_log_slope_up_mu = Inf) %>% 
  list2env(.GlobalEnv)

PCR_data_info = 
  unique(day_data[,.(ID,N_tests,Age,first_test_negative,last_test_negative, PAMS1, Hospitalized)]) 

PCR_data_info %>% 
  .[, number_tests := cut(N_tests,
                          breaks = c(2.9,3,4,6,9,20),
                          labels = c("3","4","5-6","7-9",">9"),
                          ordered_result = T)] %>%
  ggplot(aes(x = Age, fill = number_tests)) +
  geom_histogram(breaks = seq(0,100,5)) + 
  scale_fill_ordinal(name = "Number \nof tests") 
```

The time series data set has few patients who are younger than 20 years.

```{r Table1TC}

TC_table1 = 
  PCR_data_info[, 
              .(N = .N,
                `Mean age` = sprint_mci(Age,0),
                `% leading neg. test` = sprint_mcib(first_test_negative,0),
                `% trailing neg. test` = sprint_mcib(last_test_negative,0),
                `% hospitalized` = sprint_mcib(Hospitalized,0),
                `% PAMS` = sprint_mcib(PAMS1,1)),
              by = .(number_tests)] %>% 
  .[order(number_tests)] %>% 
  setnames("number_tests", "Number of tests")

TC_table1 = 
  kable(TC_table1,
        format = table_format,
        caption = "Sample for time course analysis.") %>% 
  kable_styling(full_width = F) %>%
  add_footnote("Numbers are means and 95% confidence intervals",
               notation = "none")

TC_table1
```

Few participants with time course data never had a positive test outside a hospital ward, i.e., were classified as PAMS. These participants are almost exclusively among subjects with three or four data points.

```{r timeCourseDataRaw, fig.width=8, fig.height=6, fig.cap = "Observed viral load time courses. Red dots are PCR results. Data points are jittered to reduce visual overlap."}
grp_var = "ID"

day_data = 
  prep_time_course_data(TC_data)

TC_raw_data = 
  day_data %>% 
  .[, NtestsCats := factor(as.numeric(NtestsCat),labels = c(3:9,"10+"))] %>% 
  ggplot(aes(x = day, y = log10Load, group = ID)) + 
  geom_line(alpha = .2) + 
  geom_jitter(col = adjustcolor("red", alpha = .1), size = 1) +
  facet_wrap(~NtestsCats) +
  ylab(expression(log[10]~viral~load)) + 
  xlab("Day since first test") +
  red_blue(c(1,3))

TC_raw_data

ggsave(TC_raw_data + facet_wrap(~NtestsCats,ncol = 2),
       filename = "figures/S8_TC_rawdata.png", width = 20, height = 30, units = "cm")
ggsave(TC_raw_data + facet_wrap(~NtestsCats,ncol = 2),
       filename = "figures/S8_TC_rawdata.pdf", width = 20, height = 30, units = "cm")

```

```{r scatterHistTimecoures, fig.cap="Scatterplot with marginal histograms for time course data.", eval = F}
my_hist = 
  ggplot(day_data, aes(x = day, y = log10Load)) + 
  geom_point(alpha = 0) +
  geom_jitter() +
  ylab(expression(log[10]~viral~load)) + 
  xlab("Days since first test")
  
ggMarginal(my_hist,type = "histogram")
rm(my_hist)
```

## Wild type cell culture isolation data

Here we briefly describe data from three published articles [@Wolfel2020-fu, @Perera2020-nc, @Van_Kampen2020-mc] that assessed infectivity of samples with different viral loads by performing cell culture isolation trials.

```{r plotCultureData, fig.width=25/2.54, fig.height=10/2.54, fig.cap = "Distribution of viral loads for data considered for the estimation of the association between viral load and culture probability."}
culture_data = 
  get_CP_data() %>% 
  .[!is.na(culture_positive) & Study !=  "Own data" & log10Load > 2]

ggplot(culture_data, aes(x = log10Load, fill = Study, color = culture_positive)) + 
  geom_histogram(bins = 20) + 
  xlab(expression(log[10]~viral~load)) + 
  facet_wrap(~Study, nrow = 1, scale = "free_y") + 
  theme(legend.position = "top") + 
  theme(legend.position = "none")
```

We estimated a Bayesian hierarchical logistic regressions in rstanarm [@rstanarm1] for the three datasets to investigate if the association between viral load and positive culture outcome is sufficiently similar to pool the data from these studies:

```{r checkPoolingCultureData, fig.cap="Estimated association between viral load and culture probability by data set. Coloured bands show 90% credible intervals."}

if (!file.exists("pdata/culture_model.Rdata")) {
  culture_model = stan_glmer(culture_positive ~ log10Load + (log10Load | Study),
                    data = data.frame(culture_data),
                    family = binomial)
  save(culture_model, culture_model, file = "pdata/culture_model.Rdata")
} else {
  load("pdata/culture_model.Rdata")
}


newdata = 
  expand.grid(log10Load = seq(0,10, length.out = 100),
              Study = unique(culture_data$Study)) %>%
  data.table()

pp = posterior_epred(culture_model,newdata = newdata)

pp = 
  cbind(newdata, t(pp)) %>%
  melt(id.vars = names(newdata)) %>%
  .[, as.list(post_stats_list(value)),
    by = c("log10Load","Study")] %>% 
  .[, Study := as.character(Study)] %>% 
  .[, Study := gsub("Wölfel","Woelfel",Study)]
  
ggplot(pp,
       aes(x = log10Load,
           y = m,
           color = Study,
           fill = Study)) +
    geom_line() + 
    geom_ribbon(aes(ymin = q5,ymax = q95),
                    alpha = .25, color = NA) + 
  xlab(expression(log[10]~viral~load)) + 
  ylab("Culture probability")
rm(pp,culture_model)
```

The associations in the data from [@Wolfel2020-fu] and [@Perera2020-nc] are similar enough to warrant pooling the culture data. The data from [@Van_Kampen2020-mc will not be included, as it shows a different association between viral load and culture probability (see discussion in the manuscript for why this is plausible / to be expected).

# Analysis

## Viral load and infectiousness at the first positive test by age

We use a Bayesian thin-plate spline regression [@Wood2003] as implemented in the brms package [@brms1; @brms2] to estimate the association between age and viral load. Following specifications account for structure in the data:

- We model differences in viral load between sexes, samples measured on different PCR systems, samples from the B.1.1.7 variant, and samples from different test centre categories (see Table \@ref(tab:centreTable))
- We allow the association between age and viral load to vary, dependent on whether subjects fall into the PAMS, Hospitalized, or Other group
- We allow for variation of residual variance, dependent on age group and test centre category  
- We implement a robust regression approach by using a student-t distributed error term.

As described earlier, cases are categorized in the groups (see also Table \@ref(tab:centreTable)):

- PAMS
- Hospitalized
- Other
 
The brms model is

     bf(log10Load ~ Group + B117 + PCR + Male + s(Age, by = Group) + (1 | TestCentreCategory/Hospitalized) ,
        family = student(),
        sigma ~ PCR + (1 | fAgeGroup) + (1 | TestCentreCategory))

wherein

-   `~ Group` models the population-level effect of being  part of the "PAMS", "Hospitalized", or "Other" group
-   `B117 + PCR + Male` model effects of B.1.1.7 type, PCR system and gender
-   `+ (1 | TestCentreCategory/Hospitalized)` models differences between test centre categories and hospitalized and non-hospitalized subjects within test centre categories with random effects. 
-   `+ s(Age, by = Group)` implements a thin-plate spline model for the effect of `Age`, with separate spline coefficients for groups defined by clinical status.
-   `family = student()` uses student-t distributed error variance which implements a robust regression that reduces the influence of outliers,
-   `sigma ~ PCR + (1 | fAgeGroup) + (1 | TestCentreCategory)` models age-group specific error variances.

The following code describes the model estimation, including specification of weakly informative priors. The analysis uses default values of 1000 warm-up samples, 1000 post warm-up samples, and 4 independent chains.

```{r estimate_model, eval = T}
fn = here("FPT/splines_TP+.Rdata")
if (file.exists(fn)) {
  load(fn)
} else {
  # get data
  bdata = 
    get_log10Load_data() %>%
    .[, PCR_Gender_Group := factor(paste0(PCR,"_",Gender,"_",Group))] %>%
    .[, PCR_Group := factor(paste0(PCR,"_",Group))] %>%
    .[, fAgeGroup := factor(AgeGroup, ordered = F)] %>% 
    .[, Male := ifelse(Gender == "M",1,ifelse(Gender == "F",0,.5))]


  model_formula = 
    bf(log10Load ~ B117 + PCR + Male + Group + s(Age, by = Group) + (1 | TestCentreCategory/Hospitalized) ,
       family = student(),
       sigma ~ PCR + (1 | fAgeGroup) + (1 | TestCentreCategory)) 

  # Specify weakly informative priors
  prior = 
    c(prior(normal(6, 3), class = Intercept),
      prior(normal(0, 2), class = b),
      prior(normal(0, 2), class = sd),
      prior(normal(0, 1), class = b, dpar = "sigma"),
      prior(normal(0, 1), class = Intercept, dpar = "sigma"),
      prior(normal(0, 1), class = sd, dpar = "sigma"),
      prior(normal(0, 1), class = sds)
    )

  # make output-skeleton to get parameter dimensions 
  # in a convenient format to be used to set initial 
  # parameter values
  bfit = brm(model_formula,
             data = bdata,
             chains = 1,
             iter = 10,
             prior = prior,
             backend = "cmdstanr")

  ############ fit modified model ###########
  my_inits = lapply(1:4,function(x) make_age_fit_inits(bfit))
  bfit = brm(model_formula,
             data = bdata,
             chains = 4,
             iter = 2000,
             prior = prior,
             inits = my_inits,
             backend = "cmdstanr")

  sampler_params = 
    nuts_params(bfit) %>% 
    data.table() %>% 
    dcast(Chain + Iteration ~ Parameter, value.var = "Value")

  draws = as_draws(bfit$fit)
  save(bfit,draws,sampler_params,file = fn)
}
```

### Check successful estimation

To verify a successful model estimation, we check R-hat [@Vehtari2020-fj] and the number of divergent iterations [@Betancourt2016-gt].

```{r AgeModelChecks, fig.cap= "R-hat values for viral load and age models", eval = T}
bfitdata = 
  data.table(bfit$data) %>% 
  .[, Age_rounded := round(Age)] %>% 
  .[, ID := 1:nrow(bfit$data)] %>% 
  setkeyv("ID")
data.table(rhat = rhat(bfit)) %>% 
  ggplot(aes(x = rhat)) + 
  geom_vline(xintercept = 1.1, col = "red") + 
  geom_vline(xintercept = 1.01, col = "red", lty = 3) + 
  geom_histogram(bins = 50)
divergen_iterations = sampler_params$divergent__
```

The maximal R-hat value is `r round(max(rhat(bfit)),3)` and there are `r sum(divergen_iterations)` divergent iterations out of a total of 4000 iterations, which indicates that the model converged.

### Posterior predictive check

To check if the current analysis describes the observed data well, we use a visual posterior predictive check. We examine whether the observed means and standard deviations of group-wise viral loads are within the 90% credible interval of the posterior predictive distribution. Figure \@ref(fig:ppcAge) shows observed and estimated viral load means and standard deviations by age group.

```{r ppcAge, fig.cap = "Observed (points and vertical lines) and estimated (horizontal line and confidence band) age-wise mean viral loads with confidence and credible intervals, respectively."}
if (file.exists("pdata/yhat_age.Rdata")) {
  load("pdata/yhat_age.Rdata")
} else {
  yhat = posterior_predict(bfit)
  dt.yhat = 
    data.table(ID = 1:nrow(bfitdata), t(yhat)) %>% 
    melt(id.var = "ID") %>% 
    .[, .draw := as.numeric(gsub("V","",variable))] %>% 
    .[, variable := NULL] %>% 
    setkeyv("ID") %>% 
    .[bfitdata, `:=`(Age_rounded = Age_rounded,
                     Group = Group)]
  yhat_by_age = 
    dt.yhat[, .(log10Load = collapse::fmean(value)),
            by = .(Age_rounded,.draw)] %>% 
    get_stats(var = "log10Load", by = "Age_rounded") %>% 
    setnames("mean","log10Load") %>% 
    .[, `Test result` := factor("modeled",levels = c("observed","modeled"))]
  save(dt.yhat,yhat,yhat_by_age,file = "pdata/yhat_age.Rdata")
}

obs_by_age = 
  bfitdata[, list(log10Load = mean(log10Load),
               lower = mean(log10Load) - 1.96 * sd(log10Load)/sqrt(.N),
               upper = mean(log10Load) + 1.96 * sd(log10Load)/sqrt(.N),
               N = .N),
               by = c("Age_rounded")] %>% 
  .[, `Test result` := factor("observed",levels = c("observed","modeled"))] 

ppc_VL_by_age = 
  yhat_by_age %>% 
  ggplot(aes(x = Age_rounded, y = log10Load)) + 
  geom_line() + 
  conf_ribbon(data = yhat_by_age, fill ="black") +
  geom_linerange(data = obs_by_age,
                 aes(ymin = lower, ymax = upper),
                 alpha = .5,
                 show.legend = F) + 
  geom_point(data = obs_by_age, aes(size = N,shape = Ns), shape = 21, fill = "white") + 
  scale_x_continuous(expand = expansion(.001,0.999)) + 
  coord_cartesian(ylim = c(4,9)) +
  xlab("Age (rounded to the year)") + 
  ylab(expression(log[10]~viral~load)) +
  theme(legend.position = c(.2,.8)) + 
  scale_size(range = c(0, 4),guide = guide_legend(nrow = 1),breaks = c(0,25,50,100,250,500))

ppc_VL_by_age

```


```{r echo=F}
# alternative figure for reviewer
obs_by_age = 
  bfitdata[, list(log10Load = mean(log10Load),
               lower = mean(log10Load) - 1.96 * sd(log10Load)/sqrt(.N),
               upper = mean(log10Load) + 1.96 * sd(log10Load)/sqrt(.N),
               N = .N),
               by = c("Age_rounded")] %>% 
  .[, `Test result` := factor("observed",levels = c("observed","modeled"))] %>% 
  .[, Ns := cut(N, breaks = c(0,100,200,300,400,500,600))]

tmp_plot = 
  yhat_by_age %>% 
  ggplot(aes(x = Age_rounded, y = log10Load)) + 
  geom_line() + 
  conf_ribbon(data = yhat_by_age, fill ="black") +
  geom_linerange(data = obs_by_age,
                 aes(ymin = lower, ymax = upper),
                 alpha = .5,
                 show.legend = F) + 
  geom_point(data = obs_by_age, aes(size = N,shape = Ns), fill = "white") + 
  scale_shape_manual(values = c(21:25,21), breaks = waiver(),guide = guide_legend(nrow = 1,title = "N")) +
  scale_x_continuous(expand = expansion(.001,0.999)) + 
  coord_cartesian(ylim = c(4,9)) +
  xlab("Age (rounded to the year)") + 
  ylab(expression(log[10]~viral~load)) +
  theme(legend.position = c(.3,.8)) + 
  scale_size(range = c(0, 3),guide = guide_legend(nrow = 1),breaks = c(0,25,50,100,250,500))
```


```{r ppcAgePAMSChildren, fig.cap= "Observed and estimated viral loads for subjects younger than 26 years stratified by clinical status."}
yhat_by_age = 
  dt.yhat[Age_rounded < 26] %>% 
  .[, .(log10Load = collapse::fmean(value)),
          by = .(Age_rounded,Group,.draw)] %>% 
  get_stats(var = "log10Load", by = c("Age_rounded","Group")) %>% 
  setnames("mean","log10Load") %>% 
  .[, `Test result` := factor("modeled",levels = c("observed","modeled"))]


obs_by_age = 
  bfitdata[Age_rounded < 26] %>% 
  .[, list(log10Load = mean(log10Load),
           lower = mean(log10Load) - 1.96 * sd(log10Load)/sqrt(.N),
           upper = mean(log10Load) + 1.96 * sd(log10Load)/sqrt(.N),
           N = .N),
    by = .(Age_rounded,Group)] %>% 
  .[, `Test result` := factor("observed",levels = c("observed","modeled"))] %>%
  .[, lower := ifelse(is.na(lower), log10Load, lower)] %>%
  .[, upper := ifelse(is.na(upper), log10Load, upper)]

obs_by_age_all = 
  bfitdata[Age_rounded < 26] %>% 
  .[, list(log10Load = mean(log10Load)),
    by = .(Age_rounded)]

ppc_VL_by_age_PAMS = 
  yhat_by_age %>% 
  ggplot(aes(x = Age_rounded, y = log10Load)) + 
  geom_line(show.legend = F, aes(color= Group)) + 
  conf_ribbon(data = yhat_by_age, fill = "Group") +
  geom_linerange(data = obs_by_age,
                 aes(ymin = lower, ymax = upper, color = Group)) + 
  geom_point(data = obs_by_age, aes(size = N,color= Group, fill = Group), shape = 21, fill = "white") +
  scale_x_continuous(expand = expansion(.001,0.999)) + 
  coord_cartesian(xlim = c(0,25)) +
  geom_text(data = obs_by_age,aes(label = N, y = upper+.2), 
            color = "black", size = 3) + 
  xlab("Age (rounded to the year)") + 
  ylab(expression(log[10]~viral~load)) +
    facet_wrap(. ~ Group, ncol = 1) + 
  red_blue(1:3) + 
  scale_size(range = c(0, 5)) + 
  geom_point(data = obs_by_age_all, size = 1) +
  theme(legend.position = "none")
ppc_VL_by_age_PAMS
ggsave("figures/S1_ppc_age.png",ppc_VL_by_age_PAMS, width = 15, height = 20, units = "cm")
ggsave("figures/S1_ppc_age.pdf",ppc_VL_by_age_PAMS, width = 15, height = 20, units = "cm")
rm(dt.yhat)
tmp = gc()
```

The next plots compare directly-estimated and observed mean and standard deviations for age groups (see Figure \@ref(fig:ppcAge2)) clinical status (see Figure \@ref(fig:ppcSymptomSubsample)) and test centre category (see Figure \@ref(fig:ppcCenter)).

```{r ppcAge2, fig.cap =  "Observed (red dots) and estimated means and variances of viral load by age group."}
bfitdata[,AgeGroup :=  cut(Age,c(seq(0,90,10),101))]
ppc_5i = 
  ppc_2d(bfitdata,yhat, "AgeGroup") + 
  ggtitle("Posterior prediction by age group")
ppc_5i
```

```{r ppcSymptomSubsample, fig.cap =  "Observed (red dots) and estimated means and variances of viral load by sub-sample"}
ppc_2d(bfitdata,yhat, "Group") + ggtitle("Posterior prediction by sub-sample")
```

```{r ppcCenter, fig.cap =  "Observed (red dots) and estimated means and variances of viral load by test centre group"}
ppc_2d(bfitdata,yhat, "TestCentreCategory") + ggtitle("Posterior prediction by TestCentreCategory group")
rm(yhat)
tmp = gc(verbose = F)
```

`r ifelse(show_code == T,"### Null hypothesis significance testing","")`

`r ifelse(show_code == T,"As a first approach, we can use null hypothesis significance tests to compare viral loads of different age groups. The following code implements Welch's t-test to compare group means.","")`

```{r sigtests}
agl = levels(bdata$AgeGroup)
contr_idx = list(
  `0-5 vs 20-65`   = list(young = bdata$AgeGroup %in% agl[1],
                           adult = bdata$AgeGroup %in% agl[5:9]),
  `5-10 vs 20-65` = list(young = bdata$AgeGroup %in% agl[2],
                          adult = bdata$AgeGroup %in% agl[5:9]),
  `10-15 vs 20-65`  = list(young = bdata$AgeGroup %in% agl[3],
                            adult = bdata$AgeGroup %in% agl[5:9]),
  `15-20 vs 20-65`   = list(young = bdata$AgeGroup %in% agl[4],
                             adult = bdata$AgeGroup %in% agl[5:9])
)

contr_names = names(contr_idx)

NHST_stats = c()
NHST_Groups = c("PAMS","Hospitalized","Other","All")
for (contr in 1:4) {
  for (s in NHST_Groups) {
    if (s == "All") {
      s_idx = bdata$Group %in% unique(bdata$Group)
    } else {
      s_idx = bdata$Group == s
    }
    
    young_idx = contr_idx[[contr]]$young
    adult_idx = contr_idx[[contr]]$adult
    cdata = rbind(
      data.table(log10Load = bdata$log10Load[s_idx & young_idx],Group = "Y"),
      data.table(log10Load = bdata$log10Load[s_idx & adult_idx],Group = "A")
    )
    
    if (min(table(cdata$Group)) > 5) {
      welch_test = 
        t.test(cdata[Group == "Y",log10Load],
               cdata[Group == "A",log10Load],
               var.equal = F)
      
      MWU_test = wilcox.test(log10Load~Group,cdata)
    } else {
      welch_test = data.frame(conf.int = NA, p.value = NA, statistic = NA, parameter = NA)
      MWU_test = data.frame(p.value = NA, statistic = NA)
    }
    
    delta = round(mean(cdata[Group == "Y", log10Load]) - 
                    mean(cdata[Group == "A", log10Load]),digits = 2)
    tmp = 
      data.table(Sample = factor(s,levels = c("PAMS","Hospitalized","Other","All")),
                 Comparison = names(contr_idx)[contr],
                 Difference = paste0(delta," (",paste0(round(welch_test$conf.int,2),collapse = ", "),")"),
                 `p~Welch~` = welch_test$p.value,
                 `t-stat` = welch_test$statistic,
                 `t df` = welch_test$parameter,
                 `p~MW~` = MWU_test$p.value)
    NHST_stats =  rbind(NHST_stats,tmp)
  }
}
rm(welch_test)

NHST_stats = 
  NHST_stats[order(Sample)]

footnote_text = 
  "The difference is given with 95% confidende intervals, p = p-value,
   t = t-test, df = degrees of freedom, MW = Mann-Whitney U test"
tbl_NHST = 
  kable(NHST_stats,
      digits = c(0,0,2,2,2,2,2),
      format = table_format) %>%
  kable_styling(full_width = F) %>%
  add_footnote(footnote_text, notation = "none")
tbl_NHST
```

## Association of viral load and probability of a positive culture

To estimate the association between viral load and culture probability, we estimate a logistic regression in brms. Based on the preliminary analysis described above, this analysis uses only the data from from [@Wolfel2020-fu] and [@Perera2020-nc].

```{r CPfromVL}
culture_data = culture_data[Study != "van Kampen (2021)"]

CP_results_file = "CPfit.Rdata"
 if (file.exists(CP_results_file)) {
  load(CP_results_file)
} else {
  CP.fit = brm(culture_positive ~ log10Load,
               family = bernoulli(),
               backend = "cmdstanr",
               data = culture_data)
  save(CP.fit,file = CP_results_file)
}
```


## B.1.1.7 viral load at the first positive test

The B.1.1.7 cases in this sample are from a restricted time period (starting January 2021) and from small number of test locations. Because the appearance of B.1.1.7 cases can have led to changing testing strategies, this analysis restricts the comparison of B.1.1.7 and non-B.1.1.7 cases to test results that were obtained either one day prior, the same day, or one day after a positive B.1.1.7 cases from the same location. For instance, if test centre A had only one positive test on January 15th, and centre B had only one positive test on January 20th, the analysis would only use positive test results from January 14th-16th from test centre A and test results from January 19th-21st from test centre B. Further, this analysis adjusts for age, PCR system, gender, and models effects of test centres as random effects.

To examine the sensitivity of results to different analysis strategies, we estimate the B.1.1.7 with different data (c.f. \@ref(tab:Table1TC))

- the full data set
- B.1.1.7 cases and non-B.1.1.7 cases within +/- 5 days of the B.1.1.7 cases
- B.1.1.7 cases and non-B.1.1.7 cases within +/- 1 day of the B.1.1.7 cases
- non-B.1.1.7 cases within +/- 1 day of the B.1.1.7 cases, and B.1.1.7 cases only from test centres/locations that also reported non-B.1.1.7 cases within +/- 1 day of the B.1.1.7 cases

and with different regression model

- unadjusted regression
- uanadjusted regression with random effects for test centres/locations
- adjustment for gender, age, PCR system, and clinical status with random effects for test centres/locations

`r ifelse(show_code == T,"The following code implements these analyses and shows R-hat values for the final analysis, i.e., the fully adjsuted analysis with the most restrictive data set, which also permits the most direct comparison of B.1.1.7 and non-B.1.1.7 cases.","")`


```{r estB117Difference}
bdata.B117 = 
  bdata %>%
  .[, B117 := factor(B117, labels = c("non-B117","B117"))] %>% 
  .[, Sex := ifelse(Gender == "U",.5,ifelse(Gender == "M",1,0))]

B117model.unadjusted =
  bf(log10Load ~ B117,
     sigma ~ B117 + (1 | TestCentre))

B117model.re =
  bf(log10Load ~ B117 + (1 | TestCentre),
     sigma ~ B117 + PAMS + (1 | TestCentre))

B117model.re.adjusted =
  bf(log10Load ~ B117 + Group + Sex + PCR + s(Age) + (1 | TestCentre),
     sigma ~ B117 + PAMS + (1 | TestCentre))


######### all, unadjusted #########
B117data = 
  bdata.B117 
Bfit = fit_B117_model(B117model.unadjusted,B117data,"B117model_unadjusted_all",adapt_delta = .8)
B117_model_stats = get_B117_stats(Bfit,"unadjusted",Inf)
Bfit = fit_B117_model(B117model.re,B117data,"B117model_re_all",adapt_delta = .8)
B117_model_stats = rbind(B117_model_stats,get_B117_stats(Bfit,"RE, unadjusted",Inf))
B117_model_stats = rbind(B117_model_stats,get_B117_stats(Bfit,"RE, adjusted",Inf))
########### +/- 5 days ########### 
B117data = 
  bdata.B117 %>%
  .[B117CentreDay5 == 1] 
### with adjustment ####
Bfit = fit_B117_model(B117model.unadjusted,B117data,"B117model_unadjusted_5",adapt_delta = .99)
B117_model_stats = rbind(B117_model_stats,get_B117_stats(Bfit,"unadjusted",5))
Bfit = fit_B117_model(B117model.re,B117data,"B117model_re_5",adapt_delta = .99)
B117_model_stats = rbind(B117_model_stats,get_B117_stats(Bfit,"RE, unadjusted",5))
Bfit = fit_B117_model(B117model.re.adjusted,B117data,"B117model_re_adjusted_5",adapt_delta = .99)
B117_model_stats = rbind(B117_model_stats,get_B117_stats(Bfit,"RE, adjusted",5))
########### +/- 1 day ########### 
B117data = 
  bdata.B117 %>%
  .[B117CentreDay1 == 1] 
####  no adjustment ####
Bfit = fit_B117_model(B117model.unadjusted,B117data,"B117model_unadjusted_1",adapt_delta = .99)
B117_model_stats = rbind(B117_model_stats,get_B117_stats(Bfit,"unadjusted",1))
Bfit = fit_B117_model(B117model.re,B117data,"B117model_re_1",adapt_delta = .99)
B117_model_stats = rbind(B117_model_stats,get_B117_stats(Bfit,"RE, unadjusted",1))
Bfit = fit_B117_model(B117model.re.adjusted,B117data,"B117model_re_adjusted_1",adapt_delta = .99)
B117_model_stats = rbind(B117_model_stats,get_B117_stats(Bfit,"RE, adjusted",1))
### with adjustment, non-B117 & B117 in centre ####
CentresWithMin2Cases = 
  B117data[,.(N = .N), by = .(TestCentre)][N > 1,TestCentre]
B117data = 
  B117data[TestCentre %in% CentresWithMin2Cases]
Bfit = fit_B117_model(B117model.re.adjusted,B117data,"B117model_re_adjusted_1wcc",adapt_delta = .99)
B117_model_stats = rbind(B117_model_stats,get_B117_stats(Bfit,"RE, adjusted, (paired)",1,"Yes"))
data.table(rhat = rhat(Bfit)) %>% 
  ggplot(aes(x = rhat)) + 
  geom_histogram(bins = 100) + 
  geom_vline(xintercept = 1.1, color = "red")+ 
  geom_vline(xintercept = 1.01, color = "red", lty = 3)
B117fit = Bfit
rm(Bfit)
```


## Viral load and infectiousness time course

### A model for estimating viral load time course without knowledge of day of infection or peak viral load

In this analysis, we use the time course data described above to estimate how viral load and infectiousness, indexed by culture probability, evolve over time. Because the day of infection is not known, we estimate it simultaneously with the viral load time course. The model has following basic properties:

-   log~10~ viral load is assumed to increase linearly up to the maximum viral load and thereafter decreases linearly.
-   day zero is the day of peak viral load, which is modeled with a parameter `intercept`
-   the linear increase of log~10~ viral load from the start of shedding to peak viral load is modeled with a slope parameter `slope_up`
-   the linear decrease has a slope parameter `slope_down`
-   we use a logistic weighting function (`weight_down = inv_logit(day*b)`) to calculate log~10~ viral load at any point in time as the average of the up and down slopes: `yhat = load_up * (1-weight_down) + load_down * weight_down`. This implements a smooth transition from increasing to declining viral load.

To obtain subject-level parameter estimates,  we use random effects models for intercept, slope_up, and slope_down. In short, subject-level parameters $p_i$ are estimated as

$$log(p_i) = \alpha + \beta X_i + \gamma s(age) + \rho_gZ_i$$

where $\alpha$ is the population mean (see below for priors) the vector $\beta$ has weights for the fixed effects of gender, PAMS, B.1.1.7, and hospitalization  status in vector $X_i$. $\gamma s(age)$ represents the non-linear effect of age, modeled with restricted cubic splines. $Z_i$ is a vector with random effects variables and $\rho_g$ are the associated weights for group $g$ and $\rho_g\sim N(0,\sigma)$, with $\sigma$ being the random effects standard deviation. To obtained the negative slopes for the viral load decay, $log(p_i)$ is multiplied by -1. We estimate, for all model parameters, subject-level random effects. In addition, we estimate for the intercept the effect of the centre in which the first test was taken and for intercept and slopes the effect of the primary centre, that is that centre with the longest distance between consecutive tests from the same centre (as a proxy for duration of stay). These two latter effects are also estimated as random effects.

To align observed viral loads with with estimated viral load time courses, we estimate for each subject a "shift" parameter, which captures the number of days between peak viral load and the first test. We use a uniform prior from -10 to 20 days for the subject-level shift. Additionally, we model differences in shifts between participants that had their first test in different centres as random effects.

For small subset of subjects we also had the day of the reported symptom onset. To incorporate this data, the model calculated the time from peak viral load to symptom onset and employed a skew-normal prior distribution on this distance. To further account for noise in this data (some subjects reported symptom onset more than three weeks after their first positive test), we model the reported onset as a mixture between a normally-distributed component with a large variance error and the skew normal.

```{r modelPriors}
model = "TC_APGHB117_simple_shiftw25o"
tcmp = list(
  # mean, sd, random effects sigma of peak viral load
  log_int_mu = 2.1, log_int_sigma = .15,  log_int_reff_sigma = 1,
  # mean, sd, random effects sigma of the log up-slope
  log_up_mu = .6, log_up_sigma = .25, log_up_reff_a = 4, log_up_reff_b = 15,
  # mean and sd of the log down-slope
  log_down_mu = -1.75, log_down_sigma = .5, log_down_reff_a = 4, log_down_reff_b = 15,
  b_mu = 10, b_sigma = 1
)

descr_dist = function(mu,sigma,digits = 1) {
  m = round(exp(mu+sigma^2/2),digits)
  qs =  round(qlnorm(c(.1,.9),mu,sigma),digits)
  return(
    paste0(
      m, ", a 10% quantile of ", qs[1], ", and a 90% quantile of ",qs[2]
    )
  )
}
```

We use following priors for population-level means ($alpha$ above):

- $log(intercept)$ (peak viral load): $N(`r tcmp$log_int_mu`,`r tcmp$log_int_sigma`)$. This prior distribution has a mean `r descr_dist(tcmp$log_int_mu,tcmp$log_int_sigma)`.
- $log(slope_{up})$ (attack rate): $N(`r tcmp$log_up_mu`,`r tcmp$log_up_sigma`)$. This prior distribution has a mean `r descr_dist(tcmp$log_up_mu,tcmp$log_up_sigma)`,
- $-log(slope_{down})$ (decay rate): $N(`r tcmp$log_down_mu`,`r tcmp$log_down_sigma`)$. This prior distribution has a mean `r descr_dist(tcmp$log_down_mu,tcmp$log_down_sigma,2)`.


Priors for random effects variances ($\sigma$ above) are $gamma(4,20)$ for log~10~ load model parameters, $half-normal(0,1)$ for shifts. Random effects for viral load parameters are added on the log scale. Priors for fixed effects, which are added on the log scale ($\beta$ above) are $N(0,.125)$ [^2].

The prior for onset is $skewN(\xi = -2.5, \omega = 10, \alpha = 10)$, the prior for the error component is $N(0,50)$, and the prior probability for a reported onset coming from the error component is $uniform(0,1)$.

[^2]: i.e., 95% of the mass of the posterior are below `r round(qnorm(.95,0,.125),2)`, where a one unit increase corresponds to an increase of the estimated parameters by the factor `r round(exp(qnorm(.95,0,.125)),2)`

The statistical model was implemented in Stan [@Carpenter2017-gd]. `r ifelse(show_code == T, "The complete Stan model can be found at the end of this document.","")`

### Data for the Stan model

We use utility-scripts to generate the data for the Stan model.

```{r CorrCovariates, results = T}
make_time_course_standata(
  max_diff_load_12perday = 5,
  ub_log_slope_up_mu = Inf) %>% 
  list2env(.GlobalEnv)

caption_text = 
  "Correlation matrix of regressors for model paramerers
   slope_up, intercept, and slope_down"
cor(cbind(Age = datalist$Age,
          datalist$X_PGH)) %>% 
 kable(digits = 2, 
        format = table_format,
        caption = caption_text) %>%
  kable_styling(full_width = F)
```

### Model priors and prior predictions

A first step of the modelling workflow is to examine the prior predictive distributions of the model. Here, we check if the model predictions are roughly in line with the prior information about the time course of a SARS-CoV-2 infection, namely a duration between 3 and 7 days from infection to peak viral load, a peak viral load of around 8, and decay rate of around 0.15. To obtain prior predictive distributions, we sample from the Stan model without conditioning on the data.

```{r priorpredictive, results=F, message=F}
pp_file = paste0("CP/prior_predict_",model,".Rdata")
if (file.exists(pp_file)) {
  load(pp_file)
} else {
  make_time_course_standata(
    selection = 3,
    samples = 500,
    max_diff_load_12perday = 5) %>% 
    list2env(.GlobalEnv)
  sm = cmdstan_model(here(paste0("CP/stan/",model,".stan")))
  datalist$condition_on_data = 0
  my_inits = lapply(1:4, function(x) make_TC_inits(datalist))
  priorpred = 
    sm$sample(data = datalist,
              iter_warmup = 250,
              iter_sampling = 500,
              chains = 4,
              init = my_inits,
              seed = 123)
  draws = priorpred$draws()
  save(draws, datalist, day_data, file = pp_file)
  datalist$condition_on_data = 1
}

```

Figure \@ref(fig:plotTwoSlopesModel) illustrates the model and describes key model parameters.

```{r plotTwoSlopesModel, fig.width=10, fig.height=12, fig.cap = "Components of the two-slopes model used to estimate viral load time courses. Top: Priors for population-level means. The (implied) prior for time to peak viral load is the ratio of the priors for slope up and intercept.  Second row: Components of exemplary viral load trajectories. Each line is generated from the prior distribution of group-level means in the top row. Third row: Weighting function for the combination of up- and down-slopes. Bottom: Exemplary viral load trajectories. In the full model, subject-level parameters also depend on random effects, subject age, gender, clinical status, and PCR system effects."}

par(mar=c(2,1,0,1), mgp=c(1,.25,0), tck=-.01)
layout(t(matrix(c(1:4,rep(5,8),rep(6,4),rep(7,8)), nrow = 4)))

## prior distributions for group-level means
curve(dlnorm(x,tcmp$log_up_mu,tcmp$log_up_sigma),1,3,
      xlab = "slope_up", ylab = "", yaxt = "n", bty = "n", col = "red")
curve(dlnorm(x,tcmp$log_int_mu,tcmp$log_int_sigma),4,12,
      xlab = "intercept", ylab = "", yaxt = "n", bty = "n")
curve(dlnorm(x,tcmp$log_down_mu,tcmp$log_down_sigma),0,.9,
      xlab = "-slope_down", ylab = "", yaxt = "n", bty = "n", col = "blue")
p_intup = density(abs(rlnorm(1000000,tcmp$log_int_mu,tcmp$log_int_sigma)) / 
                    rlnorm(1000000,tcmp$log_up_mu,tcmp$log_up_sigma))
plot(p_intup, xlab = "time2peak", ylab = "", yaxt = "n",
     bty = "n", main = "", xlim = c(1,10))

model_pars = 
  draws %>% 
  subset_draws("slope_up_mu") %>% 
  as_draws_dt() %>% 
  merge(draws %>%  subset_draws("slope_down_mu") %>% as_draws_dt(), by = ".draw") %>% 
  merge(draws %>%  subset_draws("intercept_mu") %>% as_draws_dt(), by = ".draw") %>% 
  merge(draws %>%  subset_draws("beta_sweight_mu") %>% as_draws_dt(), by = ".draw")

## prior predictions from group-level means
par(mar=c(0,3,2,1))
plot(0,
     type = "n", ylim = c(0,12), xlim = c(-10,40),
     ylab = expression(log[10]~viral~load), xaxt = "n")
tmp = 
  lapply(1:1000, function(d) {
  abline(a = model_pars$intercept_mu[d],
         b = model_pars$slope_up_mu[d],
         col = adjustcolor("blue",alpha = .01))
  abline(a = model_pars$intercept_mu[d],
         b = -model_pars$slope_down_mu[d],
         col = adjustcolor("red",alpha = .02))
})
abline(v = 0, lty = 3, col = "grey")

## weights
par(mar=c(0,3,0,1))
days = seq(-10,40,by = .1)
w = inv.logit(matrix(days,ncol = 1)  %*% 
                matrix(model_pars$beta_sweight_mu[1:250],nrow = 1))
matplot(days,w,type = "l", 
        col = adjustcolor("black",alpha = .025),
        lty = 1, ylab = "weight down", xaxt = "n")

## full trajectory
par(mar=c(3,3,0,1))
plot(0, type = "n", ylim = c(0,12), xlim = c(-10,40),
     ylab = expression(log[10]~viral~load),
     xlab = "Days form peak viral load")
tmp = 
  lapply(1:250, function(d) {
  w_down = inv.logit(days * model_pars$beta_sweight_mu[d])
  est_up = model_pars$intercept_mu[d] + model_pars$slope_up_mu[d]*days
  est_do = model_pars$intercept_mu[d] + -model_pars$slope_down_mu[d]*days
  yhat = est_do * w_down + est_up * (1-w_down)
  lines(days,yhat, col = adjustcolor("black",alpha = .1))
})

```


Figure \@ref(fig:PriorPredIndividuals) shows that the subject-level parameters, which in addition to population-level means shown in Figure \@ref(fig:plotTwoSlopesModel) also depend on additional fixed and random effects, have wider prior distributions than the priors for population-level means. As a result, the model can also capture extreme subject-level parameters, if the data strongly indicate such extreme values. ^[Given that subject data is sparse, this is, however, unlikely to happen.]

```{r PriorPredIndividuals, fig.cap = "Prior distributions for group-level means and prior predictive distributions of subject-level parameters. Dotted lines show the prior distributions of group-level means, which are also shown in the previous plot. Solid lines show prior distributions of subject-level parameters, which are obtained by adding random effects and effects of covariates (age, gender, PAMS), to the group-level means."}

prior_sample_densities = vector(mode = "list",length = 4)
names(prior_sample_densities) = 
  c("slope_down","slope_up","intercept","time2peak")
for (p in names(prior_sample_densities))
  prior_sample_densities[[p]] = draws %>% 
  draws_by_id(p) %>% 
  setnames(p,"par") %>% 
  .[par > min(0,quantile(par,.005)) & par < max(0,quantile(par,.995))] %>% 
  .[,par] %>% 
  density()

par(mfrow = c(2,2),mar=c(2,1,0,.25), mgp=c(1,.25,0), tck=-.01)
curve(dlnorm(x,tcmp$log_up_mu,tcmp$log_up_sigma),0,6, 
      xlab = "slope_up", ylab = "", yaxt = "n", bty = "n", col = "red", lty = 2)
lines(prior_sample_densities[["slope_up"]], col = "red")
curve(dlnorm(x,tcmp$log_int_mu,tcmp$log_int_sigma),2,14, 
      xlab = "intercept", ylab = "", yaxt = "n", bty = "n", lty = 2)
lines(prior_sample_densities[["intercept"]])
curve(dlnorm(x,tcmp$log_down_mu,tcmp$log_down_sigma),0,1, 
      xlab = "-slope_down", ylab = "", yaxt = "n", bty = "n", col = "blue", lty = 2)
lines(-prior_sample_densities[["slope_down"]]$x,
      prior_sample_densities[["slope_down"]]$y, col = "blue")
plot(p_intup, xlab = "time2peak", ylab = "", yaxt = "n", 
     bty = "n", main = "", xlim = c(0,15), lty = 2)
lines(prior_sample_densities[["time2peak"]])
```

### Model estimation

`r ifelse(show_code == T,"Data for the Stan model are generated in a custom function (see utils.R).","")` To estimate model parameters, we used 4 independent chains, each with 1000 warm-up and 1000 post warm-up samples. Prior analysis showed that 4000 post-warm-up samples produced sufficient effective samples to reliably estimate 90% credible intervals for parameters of interest. Analysis of the full date set takes around 6 hours with 4 parallel chains on an Amazon EC2 c5d.2xlarge instance.

```{r estimate_time_model, eval = T}
fn = here(paste0("CP/fits/w25o/",model,"_sel3.Rdata"))

if (!file.exists(fn)) {
  # minimum number of data points per subjects
  my_selections = 3:9

  # run analyses for subjects with different
  # minimum number of data points per subjects
  for (selection in my_selections) {
    make_time_course_standata(
      selection = selection,      # minimum number of data points per participants
      max_diff_load_12perday = 5, # maximum allowed per day viral load increases
      imputation_limit = 3) %>%   # maximum value of imputed viral load for negative tests
      list2env(.GlobalEnv)
  
    sm = cmdstan_model(here(paste0("CP/stan/",model,".stan")))
  
    csf = sm$sample(
      data = datalist,
      iter_warmup = 1000,
      iter_sampling = 1000,
      adapt_delta = .8,
      max_treedepth = 10,
      init = lapply(1:4, function(x) make_TC_inits(datalist)),
      seed = 123)
  
    draws = csf$draws()
  
    ss =
      draws %>%
      summarise_draws() %>%
      data.table()
    sampler_diags =
      csf$sampler_diagnostics() %>%
      as_draws_df() %>%
      data.table()
    inits = csf$init()
    basic_filename =
      here(
        paste0("CP/fits/w25o/",
               model,
               "_sel",selection))
    save(csf, ss, day_data, datalist, sampler_diags, inits,
         file = paste0(basic_filename,".Rdata"))
  }
}
```

```{r load_time_model, echo=F}
load(here(paste0("CP/fits/w25o/",model,"_sel3.Rdata")))
draws = csf$draws()
if (testing == T) draws = draws %>% thin_draws(test_thin)
```

### Check successful estimation

Next, we check R-hat and number of divergent iterations to verify successful model estimation. R-hat values should be below 1.1, or even better below 1.01.

```{r TimecourceModelCheck, fig.cap= "R-hat values and number of effective samples sizes (ESS) for model parameters. Top row: population-level parameters. Bottom row: Subject-level parameters."}

grep_string = "a0|slope_down_ld_centre|int_centre1|shift_centre1|_sigma|_mu|beta"

p_rhat = ggplot(ss[grepl(grep_string,variable)], aes(x = rhat)) + 
  geom_vline(xintercept = 1.01, color = "red", lty = 3) + 
  geom_vline(xintercept = 1.1, color = "red") + 
  geom_histogram(bins = 30) + 
  xlab("R-hat")
p_ess_bulk = ggplot(ss[grepl(grep_string,variable)], aes(x = ess_bulk)) + 
  geom_vline(xintercept = 100, color = "red", lty = 3) + 
  geom_histogram(bins = 30) + 
  xlab("ESS posterior bulk") +
  scale_x_log10()
p_ess_tail = ggplot(ss[grepl(grep_string,variable)], aes(x = ess_tail)) + 
  geom_vline(xintercept = 100, color = "red", lty = 3) + 
  geom_histogram(bins = 30) + 
  xlab("ESS posterior tail") +
  scale_x_log10()

p_rhat_i = ggplot(ss[!grepl(grep_string,variable)], aes(x = rhat)) + 
  geom_vline(xintercept = 1.01, color = "red", lty = 3) + 
  geom_vline(xintercept = 1.1, color = "red") + 
  geom_histogram(bins = 30) + 
  xlab("R-hat")
p_ess_bulk_i = ggplot(ss[!grepl(grep_string,variable)], aes(x = ess_bulk)) + 
  geom_vline(xintercept = 100, color = "red", lty = 3) + 
  geom_histogram(bins = 30) + 
  xlab("ESS posterior bulk") +
  scale_x_log10()
p_ess_tail_i = ggplot(ss[!grepl(grep_string,variable)], aes(x = ess_tail)) + 
  geom_vline(xintercept = 100, color = "red", lty = 3) + 
  geom_histogram(bins = 30) + 
  xlab("ESS posterior tail") +
  scale_x_log10()

divergent_proportion = 
  mean(sampler_diags$divergent__)

(p_rhat + p_ess_bulk + p_ess_tail) /
  (p_rhat_i + p_ess_bulk_i + p_ess_tail_i)
rm(p_rhat,p_ess_bulk,p_ess_tail,p_rhat_i,p_ess_bulk_i,p_ess_tail_i)

is.difficult = 
  ss %>% 
  .[!grepl("b_shift|time2peak",variable) & rhat > 1.1,] %>%
  .[, tmp_id := as.numeric(gsub("[^0-9.]","",variable))] %>% 
  .[, ID := unique(day_data$ID)[tmp_id]]
day_data[log10Load <= 2, idx := 1:sum(day_data$log10Load <= 2)]
for (id in is.difficult[grepl("imp_neg",variable),tmp_id]) 
  is.difficult[tmp_id == id, ID := day_data[idx == id,ID]]
is.difficult = 
  is.difficult %>% 
  .[, parameter := tstrsplit(variable,"\\[")[[1]]] %>% 
  .[, parameter := paste0(parameter," (", round(rhat,1),")")] %>% 
  .[, mean_rhat := mean(rhat), by = .(ID)] %>% 
  .[, parameters := paste(parameter,collapse = ", "), by = .(ID)] %>% 
  .[, parameter_lb := paste(parameter,collapse = "\n"), by = .(ID)] %>% 
  .[, n_pars := .N, by = .(ID)] %>% 
  .[, .(ID,parameters,n_pars,parameter_lb,mean_rhat)] %>% 
  unique() %>% 
  setkeyv("ID") %>% 
  .[order(-mean_rhat)]
day_data[, is.difficult := ifelse(ID %in% is.difficult$ID,T,F)]
```

```{r Energy, fig.cap="Energy and Bayesian fraction of missing information. Each subplot shows the results for one mcmc-chain. The overlap of the of the (centered) marginal energy distribution and the first-differenced distribution indicates good exploration of the tail of the posterior distribution."}
nuts_params(csf) %>% 
  mcmc_nuts_energy()
```


The R-hat values indicate that all population-level parameters converged. However, a small number of subject-level parameters have R-hat values above 1.1. Inspection of the `r nrow(is.difficult)` relevant subjects shows that this is due to viral load times courses that could be at the onset or later in the infection, resulting in bimodal distributions of these subjects' shift-parameters (see Figure \@ref(fig:ppcTimeModelDifficult)).

The estimation resulted in `r round(divergent_proportion*100,digits = 5)`% divergent iterations. Optimally, there should be no divergent iterations, though this is still a matter of current research and a small number of divergent iteration is not generally seen as problematic.

### Posterior predictive check

To check that the model adequately describes the data, we plot observed data together with model predictions as a posterior predictive check [@Gabry2019-ab]. Figure \@ref(fig:ppcTimeModel) shows subject-level expected linear upwards and downwards slope of viral load given data, model, and estimated parameters. Note that the observed data points do not need to be and are not typically enveloped by the 90% credible interval of the expected viral load time course.

```{r ppcTimeModel, fig.height=9, fig.width=9, fig.cap = "Posterior predictive check for the estimated 2-slopes time course. Blue lines are expected viral load time courses, i.e., the average over all time courses calulated from the posterior distribution of a subject's parameters. The shaded blue region indicates the 90% credible interval of the expection. x are observed measurements. Red points are observed measurements after shifting them for alignment in time and imputation of viral loads for negative tests."}

if (file.exists("pdata/VLCP_by_day_draws.Rdata")) {
  load("pdata/VLCP_by_day_draws.Rdata")
} else {
  VLCP_by_day_draws = 
    make_VLCP_by_draw_ID(draws,
                         days = tc_days,
                         thin = thin)
  setkeyv(VLCP_by_day_draws,c("ID",".draw"))
  
  
  # calculate posterior expectation of viral load
  # by ID and day
  VLCP_by_dayID = 
    VLCP_by_day_draws %>%
    .[, list(CP = collapse::fmean(CP),
             log10Load = collapse::fmean(log10Load)),
      by = c("ID","day_shifted")]
  
  # select sub-set of cases for plotting
  ids = sample(unique(VLCP_by_dayID$ID),81)
  
  VL_by_dayID = 
    VLCP_by_day_draws[ID %in% ids] %>%
    summarise_draws_dt_by(by = c("day_shifted","ID"),
                          target.var = "log10Load",
                          varname = "log10Load")
  
  save(VLCP_by_day_draws, VLCP_by_dayID, VL_by_dayID, ids, file = "pdata/VLCP_by_day_draws.Rdata")
}

setkeyv(day_data,"ID")
tmp = gc(verbose = F)


shift_draws = 
  draws_by_id(draws, c("shift"), thin = thin)
setkeyv(shift_draws,c("ID",".draw"))

# get imputed loads by component
day_data[log10Load <= 2, idx := 1:sum(day_data$log10Load <= 2)]
imputed_loads = 
  subset_draws(draws,"imp_neg") %>%
  thin_draws(thin = thin) %>% 
  as_draws_dt() %>%
  melt(id.var = ".draw",
       variable.name = "par",
       value.name = "log10Load") %>%
  .[, idx := as.numeric(gsub("[^0-9]","",par))] %>%
  .[, par := NULL] %>%
  merge(day_data[!is.na(idx), .(ID,day,idx)],
        by = "idx", all.x = T, all.y = F) %>%
  .[,idx := NULL] %>% 
  .[, imputed := "Yes"] %>% 
  setkeyv("ID")

setkeyv(day_data,"ID")

# assign imputed loads to correct ID and day
imputed_day_data_by_draw_ID = 
  shift_draws %>%
  .[, .(ID,.draw)] %>%
  unique() %>%
  merge(
    day_data[log10Load > 2,.(ID,day,log10Load)] %>% 
      .[, imputed := "No"], 
    by = "ID",
    allow.cartesian = T,
    all = T) %>%
  rbind(imputed_loads) %>%
  setkeyv(c("ID",".draw","day"))

setkeyv(imputed_day_data_by_draw_ID,c("ID",".draw","day"))

# combined imputed and observed loads
shifted_data_by_draw_day_ID = 
  shift_draws %>% 
  merge(day_data[,.(day,ID)], by = "ID",
        allow.cartesian = T) %>%
  .[, day_shifted := day + shift] %>%
  .[, c("shift") := NULL] %>%
  setkeyv(c("ID",".draw","day")) %>% 
  .[imputed_day_data_by_draw_ID, log10Load := log10Load] %>% 
  .[imputed_day_data_by_draw_ID, imputed := imputed] 

rm(imputed_loads,shift_draws,imputed_day_data_by_draw_ID)
tmp = gc(verbose = F)

day_data[log10Load <= 2, log10Load := 0]

draw_samples = sample(max(shifted_data_by_draw_day_ID$.draw),250)

ppc_timecourse = 
  ggplot(VL_by_dayID[ID %in% ids], aes(x = day_shifted, y = log10Load)) + 
  geom_ribbon(aes(ymin = q5, ymax = q95), fill = "blue", alpha = .3) + 
  geom_line(col = "blue") + 
  coord_cartesian(xlim = c(-10,40), ylim = c(0,10)) + 
  facet_wrap(~ID, ncol = 9) + 
  geom_text(aes(x = 27, y = 8, label = ID)) + 
  geom_jitter(data = shifted_data_by_draw_day_ID[ID %in% ids & .draw %in% draw_samples],
              height = .05, alpha = .01, color = "red",
              aes(x = day_shifted, y = log10Load)) + 
  geom_point(data = day_data[ID %in% ids], aes(x = day),
             col = "black", pch = "x", size = 4) + 
  theme(
    strip.background = element_blank(),
    strip.text.x = element_blank(),
    legend.position = "top"
  ) + 
  xlab("Day") + 
  ylab(expression(log[10]~viral~load)) 
ppc_timecourse
ggsave(ppc_timecourse,
       file = "figures/S16_ppc_timecourse.png",
       width = 30, height = 40,units = "cm", dpi = 300,
       type = "cairo")
ggsave(ppc_timecourse,
       file = "figures/S16_ppc_timecourse.pdf",
       width = 30, height = 40,units = "cm")
```

```{r ppcTimeModelDifficult, fig.height=9, fig.width=9, fig.cap = "Posterior predictive check for subjects with at least one subject-level parameter with an R-hat value larger than 1.1. Parameters for which R-hat values are larger than 1.1 are shown in the top right corner. imp_neg is the imputed viral load for negative tests, intercept_raw is the subject-level random effect for peak load, intercept is the subject's peak load (the sum of population average, population effects of age, PAMS, etc, and subject-level random effect.)"}

difficult.ID = is.difficult$ID[1:49]

VL_by_dayID = 
  VLCP_by_day_draws[ID %in% difficult.ID] %>%
  summarise_draws_dt_by(by = c("day_shifted","ID"),
                        target.var = "log10Load",
                        varname = "log10Load")

ppc_timecourse = 
  ggplot(VL_by_dayID[ID %in% difficult.ID], aes(x = day_shifted, y = log10Load)) + 
  geom_ribbon(aes(ymin = q5, ymax = q95), fill = "blue", alpha = .3) + 
  geom_line(col = "blue") + 
  coord_cartesian(xlim = c(-10,45), ylim = c(0,10)) + 
  facet_wrap(~ID, ncol = 7) + 
  geom_jitter(data = shifted_data_by_draw_day_ID[ID %in% difficult.ID & .draw %in% draw_samples],
              height = .05, alpha = .01, color = "red",
              aes(x = day_shifted, y = log10Load)) + 
  geom_point(data = day_data[ID %in% difficult.ID], aes(x = day),
             pch = "x", size = 4)  + 
  theme(
    strip.background = element_blank(),
    strip.text.x = element_blank(),
    legend.position = "top"
  ) + 
  xlab("Day") + 
  ylab(expression(log[10]~viral~load)) + 
  scale_alpha(range = c(.01,.5)) + 
  geom_text(data = is.difficult[ID %in% difficult.ID], size = 3,
            aes(x = 40, y = 8, label = parameter_lb),hjust = 1) + 
  geom_text(data = is.difficult[ID %in% difficult.ID], size = 3,
            aes(x = 1, y = 10, label = ID),hjust = 1) + 
  geom_line(data = day_data[ID %in% difficult.ID & is.difficult == T], aes(x = day),
            col = "black")
ggsave(ppc_timecourse,
       file = "figures/S17_ppc_difficult.png",
       width = 30, height = 30,units = "cm", dpi = 300,
       type = "cairo")
ggsave(ppc_timecourse,
       file = "figures/S17_ppc_difficult.png",
       width = 30, height = 30,units = "cm", dpi = 300,
       type = "cairo")
ppc_timecourse

```

Figure \@ref(fig:ppcTimeModel2) shows the data together with posterior predictions, i.e., posterior expectations plus error variance and their 90% credible intervals. Here we can see that the observed data are typically within the credible interval of posterior predictions.

```{r ppcTimeModel2, fig.height=9, fig.width=9, fig.cap = "Posterior predictive plot with 90% prediction intervals."}
sigma = 
  draws_by_id(draws,"sigma", thin = thin)

VLhat_by_day_draws = 
  VLCP_by_day_draws[ID %in% ids] %>%
  .[, CP := NULL] %>%
  merge(sigma[ID %in% ids],
        by = c("ID",".draw"),
        allow.cartesian = T) %>%
  .[, log10Load := log10Load + rnorm(1,sd = sigma),
    by = c(".draw","ID","day_shifted")] %>%
  .[, sigma := NULL]
tmp = gc(verbose = F)

VLhat_by_dayID = 
  VLhat_by_day_draws[ID %in% ids] %>%
  summarise_draws_dt_by(by = c("day_shifted","ID"),
                     target.var = "log10Load",
                     varname = "log10Load")

ppc_timecourse_sigma = 
  ggplot(VLhat_by_dayID[ID %in% ids], aes(x = day_shifted, y = log10Load)) + 
  geom_ribbon(aes(ymin = q5, ymax = q95), fill = "blue", alpha = .3) + 
  geom_line(col = "blue") + 
  coord_cartesian(xlim = c(-10,30), ylim = c(0,10)) + 
  facet_wrap(~ID, ncol = 9) + 
  geom_text(aes(x = 27, y = 8, label = ID)) + 
  geom_jitter(data = shifted_data_by_draw_day_ID[ID %in% ids & .draw %in% draw_samples],
              height = .05, alpha = .01, color = "red",
              aes(x = day_shifted, y = log10Load)) + 
  geom_point(data = day_data[ID %in% ids], aes(x = day),
             pch = "x", size = 4)  + 
  theme(
    strip.background = element_blank(),
    strip.text.x = element_blank(),
    legend.position = "top"
  ) + 
  xlab("Day") + 
  ylab(expression(log[10]~viral~load)) 
rm(VLhat_by_dayID, sigma, VLhat_by_day_draws, VL_by_dayID)
VLCP_by_day_draws = VLCP_by_day_draws[day_shifted >= -5 & day_shifted <= 25]
ppc_timecourse_sigma
```


### Priors and posteriors for key model parameters

To verify that the priors for key parameters, i.e., grand mean for intercept, slope_up, slope_down, and time_to_peak load do not determine the results, figure  \@ref(fig:plotPriorPosteriorTimemodel) shows the posterior distribution of these parameters together with the prior distributions. The relatively wide prior for slope_up reflects uncertainty about the start of viral shedding (i.e. uncertainty of the estimated shift parameters).

```{r plotPriorPosteriorTimemodel, fig.cap="Priors and posteriors for key model parameters. The prior density is shown as a black outline. The posterior density is filled blue."}

prior_posterior_intercept = 
  plot_prior_posterior("intercept_mu",draws,
                       tcmp$log_int_mu,tcmp$log_int_sigma,
                       "log-normal", xlim = c(4,12))
    
  
  prior_posterior_slope_up = 
    plot_prior_posterior("slope_up_mu",draws,
                       tcmp$log_up_mu,tcmp$log_up_sigma,
                       "log-normal", xlim = c(0,4))
  
  
  ttp_prior = 
    data.table(d = p_intup$y, time2peak = p_intup$x) %>% 
    .[time2peak < 12]
  prior_posterior_time2peak = 
    draws %>% 
    draws_by_id("time2peak") %>% 
    .[,.(time2peak = mean(time2peak)), by = ".draw"] %>%
    ggplot(aes(x = time2peak)) + 
    geom_density(fill = adjustcolor("blue", alpha = .5), color = NA) + 
    geom_line(data = ttp_prior, aes(y = d)) + 
    ggtitle("Prior: implicit") + 
    gg_expand() + 
    theme(plot.title  = element_text(size = 10))
  
  prior_posterior_slope_down = 
    plot_prior_posterior("slope_down_mu",draws,
                       tcmp$log_down_mu,tcmp$log_down_sigma,
                       "log-normal", xlim = c(0,.5))
    


prior_posterior_params = 
  prior_posterior_slope_up +
  prior_posterior_intercept + 
  prior_posterior_time2peak +
  prior_posterior_slope_down

prior_posterior_params
rm(prior_posterior_slope_up,
   prior_posterior_intercept,
   prior_posterior_time2peak,
   prior_posterior_slope_down,
   prior_posterior_params)
```

### Estimated shifts

Figure \@ref(fig:ShiftEstimates) indicates that relatively few first-positive tests were estimated to be done at time of peak viral load.

```{r ShiftEstimates, fig.cap = "Posterior distribution of shift estimates. Each line represents the outline of the histogram over subjects from one posterior sample. The prior for shift was a uniform distribution from -10 to 25."}
draws %>% 
  draws_by_id("shift") %>% 
  ggplot(aes(x = shift, group = .draw)) + 
  stat_bin(aes(y=..count..),
           geom="step", alpha = .01, 
           position = "identity", bins = 50) + 
  xlab("Days shifted") +
  coord_cartesian(xlim = c(-10,25)) + 
  ylab("Number of subjects") + 
  gg_expand()
```

Participants with a negative first test were typically assumed to have had the first test prior to peak load, whereas participants whose first test was positive received shifts such that the lower the maximal observed load for the participant was, the later in the infection time course the first test was assumed to be taken.

```{r ShiftByMaxLoad, fig.cap = "Association between estimated shift (mean) and maximum observed load for participants. Colour indicates if a participant had a leading negative test, and if viral load increased or decreased over the first two tests."}
day_data[, `First tests` := 
           ifelse(first_test_negative == T,
                  "Negative-increasing",
                  ifelse(Test1_positive_increasing == T,
                         "Positive-increasing",
                         "Positive-decreasing"))] 

draws %>% 
  draws_by_id("shift") %>% 
  .[, .(shift = mean(shift)), by = .(ID)] %>% 
  setkeyv("ID") %>% 
  .[day_data, max_load := max_load] %>% 
  .[day_data, `First tests` := `First tests`] %>% 
  ggplot(aes(x = shift, y = max_load, color = `First tests`)) +
  ylab("Maximum observed load") +
  geom_point(alpha = .5)

```


Finally, we show the shifted and imputed data points for all participants:

```{r PlotShiftedPoints, fig.cap = "The plot shows the placement in time of RT-PCR viral load values from subjects with at least three RT-PCR results. Points with central black dots indicate the first test of a subject. Because RT-PCR tests have a limit of detection of around 2 log10 copies (when dilution is accounted for) and false negatives are more likely when the true viral load is low, we imputed viral load values of negative tests (shown in red, with observed positive-test viral loads in blue). The permissible range of imputed values is -Inf to +3. Note that choosing a lower upper limit for trailing negative tests would lead to slightly steeper decrease in viral load. Negative imputed values are allowed to capture situations in which a leading negative test is followed several days later by low, increasing viral loads. In this scenario the onset of shedding happened between the leading negative test and the first positive test. The inset in the bottom-right corner shows that, in this situation, fitting a line through the first positive tests means that the estimated log10 viral load at the time of the leading negative test has to be negative. The negative values for imputed log10 viral loads should not be interpreted as suggesting the presence of a fractional virus particle. Instead, by allowing imputation of negative log10 viral loads, we calculate a more accurate estimation of increasing viral loads at the beginning of the infection, based on these negative tests that may miss small viral concentrations that are below the limit of detection."}

tmp_shifted_data = 
  shifted_data_by_draw_day_ID %>% 
  .[,.(day_shifted = mean(day_shifted), 
       log10Load = mean(log10Load)), by = .(ID,day,imputed)] 

mi = median(ss[grepl("intercept\\[",variable),mean])
msd = median(ss[grepl("slope_down\\[",variable),mean])
msu = median(ss[grepl("slope_up\\[",variable),mean])

lmdata = 
  data.table(day_shifted = c(-10,0,50),
           log10Load = c(mi-10*msu,mi,mi+50*msd), 
           ID = tmp_shifted_data$ID[1],
           day = 0,
           imputed = "No")

p_shifted_data = 
  tmp_shifted_data %>% 
  ggplot(aes(x = day_shifted, y = log10Load, group = ID, label = day, fill = imputed)) + 
  geom_hline(yintercept = 0, lty = 3) +
  geom_point(alpha = .15, shape = 21, stroke = 0, size = 1) + 
  ylab(expression(log[10] ~ "load")) +
  xlab("Days since peak load (estimated)") +
  gg_add_grid() + 
  red_blue(c(3,2)) +
  geom_point(data = tmp_shifted_data[day == 0], shape = 16, size = 0.0005) +
  geom_line(data = lmdata) +
  theme(legend.position = "none",axis.line.x = element_blank()) +
  coord_cartesian(ylim = c(-5,10.5), xlim = c(-7.5,40)) 

pdat = 
  data.table(x = c(0,5,7,9)) %>% 
  .[, yl := (x-4)*2] %>% 
  .[, yp := if_else(x == 0,0, yl)]
  
inlay = 
  pdat %>% 
  ggplot(aes(x = x)) + 
  geom_hline(yintercept = 0, lty = 3) +
  geom_line(aes(y = yl)) + 
  geom_point(aes(y = yp), col = "red") + 
  xlab("Days since first test") + 
  ylab(expression(log[10] ~ "load")) + 
  expand_limits(y = 0) + 
  theme(axis.line.x = element_blank(),
        axis.text = element_text(size = 6),
        axis.title = element_text(size = 6)) 

p_shifted_data = 
  p_shifted_data + 
  inset_element(inlay,.6,0,1,.3)

ggsave("figures/S7_TC_shifted.png",plot = p_shifted_data, width = 6, height = 6,dpi = 300)
ggsave("figures/S7_TC_shifted.pdf",plot = p_shifted_data, width = 6, height = 6)
p_shifted_data
rm(shifted_data_by_draw_day_ID,p_shifted_data)
tmp = gc(verbose = F)
```

### Key model parameters

The following figure shows estimated population-level means for slope_up, intercept, and slope_down and their correlations:

```{r plot2slopesParameters, fig.height=9, fig.width=9, fig.cap="Posterior distribution and covariations of population means for key model parameters."}
subset_draws(draws,c("slope_up_mu","slope_down_mu", "intercept_mu")) %>% 
  mcmc_pairs()
```


# Results

## Viral load across age

### Null hypothesis significance testing

Here we show the results of the Hypothesis significance tests, split by sub-sample (PAMS vs. hospitalized).

```{r NHST_results}
tbl_NHST
```

### Viral load across age: Bayesian analysis

To compute estimates of age- and subject-groupwise viral loads and viral load differences, we generate a new articifial data set `r ifelse(show_code == T,"(newdata in the code below)","")`, with which we can obtain posterior predictions for hypothetical subjects stratified by, age and test centre, and clinical status. Note that we set the value for PCR system to the more frequently used cobas system (`r round(mean(bdata$PCR == "cobas")*100)`%) and set the value for `Male` to 0.5. By marginalizing over co-variates (in particular test centre) and comparing groups, we later calculate statistics of interest.

```{r new_stratified_data}
bfitdata %>% 
  .[,TestCentre.Group := paste0(TestCentreCategory,Group)] 

newdata =
  expand.grid(Group = unique(bfitdata$Group),
              Age = seq(0,100,1),
              TestCentreCategory = unique(bfitdata$TestCentreCategory),
              Male = 0.5,
              PCR = "cobas") %>%
  data.table() %>%
  .[, B117 := 0] %>% 
  .[, TestCentre.Group := paste0(TestCentreCategory,Group)] %>% 
  .[TestCentre.Group %in% unique(bfitdata$TestCentre.Group)] %>% 
  .[, Hospitalized := ifelse(Group == "Hospitalized", 1L,0L)]

newdata = 
  newdata %>% 
  merge(bfitdata[, .(Age, fAgeGroup)][Age > 100, Age := 100][, Age := ceiling(Age)] %>% unique(),by = "Age")

newdata_load = cbind(rep(1,50),seq(2,10,length.out = 50))
```

Next we generate weights for the calculation of result-statistics that accurately reflect the sample. Test centres `r ifelse(show_code == T,"(TestCentreCategory)","")` with more test samples should have a greater weight when calculating viral load or culture probability averages by age, and when calculating averages for age groups, age years with many participants should receive a greater weight than age years with fewer patients.

```{r weights, fig.cap = "Weights of test centres by age when calculating age-wise viral load for the complete sample.", fig.height=5.5}
# Weights for correct weighting of test-centre categories
c_weights_Other =
  table(bfitdata[Group == "Other",TestCentre.Group]) %>%
  prop.table() %>%
  data.table() %>%
  setnames(c("V1","N"),c("TestCentre.Group","weight")) 

c_weights_PAMS =
  table(bfitdata[Group == "PAMS",TestCentre.Group]) %>%
  prop.table() %>%
  data.table() %>%
  setnames(c("V1","N"),c("TestCentre.Group","weight")) 

c_weights_Hosp =
  table(bfitdata[Group == "Hospitalized",TestCentre.Group]) %>%
  prop.table() %>%
  data.table() %>%
  setnames(c("V1","N"),c("TestCentre.Group","weight")) 

c_weights_all =
  table(bfitdata[,TestCentre.Group]) %>%
  prop.table() %>%
  data.table() %>%
  setnames(c("V1","N"),c("TestCentre.Group","weight")) 


group_weights =
  expand.grid(Age = 1:100,
              Group = c("PAMS","Hospitalized","Other","All")) %>% 
  data.table() %>% 
  .[, w_All := ifelse(Group == "All",1,0)] %>% 
  .[, w_Other := ifelse(Group == "Other",1,0)] %>% 
  .[, w_PAMS := ifelse(Group == "PAMS",1,0)] %>% 
  .[, w_Hosp := ifelse(Group == "Hospitalized",1,0)]

all_weights_Age_TestCentre = 
    bfitdata %>% 
      .[, .(Age,TestCentre.Group)] %>% 
      .[Age > 100, Age := 100] %>% 
      .[, Age := ceiling(Age)] %>% 
      xtabs(~TestCentre.Group + Age, .) %>% 
      data.table() %>% 
      .[, weight := N/sum(N), by = .(Age)] %>% 
      .[is.na(weight), weight := 0] %>% 
      .[, Group := "All"] %>% 
  .[, Age := as.numeric(Age)] %>% 
  setkeyv(c("Group","Age","TestCentre.Group"))


all_weights_Age_TestCentre %>% 
  copy() %>% 
  .[N > 0] %>%
  ggplot(aes(y = TestCentre.Group, x = weight, group = Age, color = Age)) + 
  geom_point() + 
  theme(legend.position= "top")

# Weights for correct weighting of ages in age years in age groups
age_group_N_comp = make_age_group_N(bfitdata,breaks = c(seq(0,20,5),65,101))
age_group_N_comp.PAMS = make_age_group_N(bfitdata,breaks = c(seq(0,20,5),65,101), my_group = "PAMS")
age_group_N_comp.Hosp = make_age_group_N(bfitdata,breaks = c(seq(0,20,5),65,101), my_group = "Hospitalized")
```

#### Calculating posterior predictions

Here we calculate linear posterior predictions of viral load $\hat{Y}_{load|Age}$ for ages 0:100, separately for the three subject groups PAMS, Hospitalized, and Other.  We calculate all posterior predictions on the level of posterior draws, but we omit indexing for posterior draws for better readability. The expected viral load given a specific age and clinical status is calculated as

$$
\hat{Y}_{load|age,group} = \alpha_{load} + \beta_{load} X + \sigma_{g} B + \rho Z
$$

where $\alpha$ is the intercept, $\beta$ are regression weights for co-variates (including clinical status), $B$ is the design matrix for spline-smoothed age, $\sigma_g$ are group-specific spline coefficients, and $Z$ and $\rho$ are design matrix and coefficients for test-centre random effects.

We calculate culture probability for the complete sample based on the association of viral load and percent positive culture estimated with the data from Wölfel at al and Perera et el. The posterior predictions of culture probability are calculated as

$$
\hat{Y}_{CP|load} = logit(\alpha_{CP} + \beta_{CP} load)
$$

where $load$ are measured viral loads of samples used in culture isolation trials. Figure \@ref(fig:plotCPbyLoad) shows the estimated association between viral load and culture probability.

```{r plotCPbyLoad, fig.cap= "Estimated association between viral load and culture probability based on data from Wölfel et al (2020) and Perera et al (2020)."}
## posterior predictions of positive culture
CPpars =
  CP.fit$fit %>% 
  as_draws() %>% 
  subset_draws(c("b_Intercept","b_log10Load")) %>% 
  as_draws_dt()


CP_by_load =
  data.table(log10Load = newdata_load[,2]) %>%
  cbind(inv.logit(newdata_load %*% t(as.matrix(CPpars[,c("b_Intercept","b_log10Load")])))) %>%
  melt(id.vars = "log10Load", variable.name = ".draw") %>%
  .[, .draw := as.numeric(gsub("V","",.draw, perl = T))] %>%
  .[, value := value] %>%
  get_stats(var = "value", by = c("log10Load"))

p_CP_by_load =
  ggplot(CP_by_load,
         aes(x = log10Load,
             y = mean)) +
  geom_hline(yintercept = 100, lty = 3, col = "grey") + 
  conf_ribbon(CP_by_load, fill = "black") +
  geom_line() +
  coord_cartesian(ylim = c(0,1), xlim = c(2.5,10)) + 
  xlab(expression(log[10]~viral~load)) +
  ylab("Culture probability") +
  gg_expand() 
  
p_CP_by_load

p_CP_by_load = 
  p_CP_by_load + 
  gg_expand() + 
  gg_text_size()
```

One can then calculate the expected culture probability given age and group as 

$$
\hat{Y}_{CP|\hat{Y}_{load|age,group}} = logit(\alpha_{CP} + \beta_{CP} \hat{Y}_{load|age,group})
$$

The parameters $\alpha_{CP}$  and  $\beta_{CP}$ are obtained independently from the model and parameters used to calculate $\hat{Y}_{load|age,group}$. To properly combine the uncertainty of parameter estimates from both models, $\hat{Y}_{CP|\hat{Y}_{load|age,group}}$ is calculated with individual posterior distribution draws from the two analyses. That is, 4000 posterior predictions from the age model are paired randomly with 4000 posterior draws from the culture probability model to calculate 4000 draws that make up the posterior distribution of the estimated age and groupwise culture probabilities $\hat{Y}_{CP|\hat{Y}_{load|age,group}}$.

$\hat{Y}_{CP|\hat{Y}_{load|age,group}}$ is an estimate of culture probability at the expected (mean) viral load for a specific group of subjects. Because the variation of viral load within age groups is larger than the variation between age groups, an estimate of culture probability should use subject-level predictions of viral load as its basis. We use the posterior predictions calculated as 

$$
\hat{Y}^i_{load|age,group} = \hat{Y}_{load|age,group} + \epsilon_{age,centre}
$$
where $\epsilon_{age,centre}$ are age group and test-centre specific error terms. We use the posterior predictions $\hat{Y}^i_{load|age,group}$ to calculate estimates for culture probability by age and group.


$$
\hat{Y}^i_{CP|\hat{Y}_{load|age,group}} = logit(\alpha_{CP} + \beta_{CP} \hat{Y}^i_{load|age,group})
$$
the expected (mean) culture probabilities by age and group calculated from posterior predictions will be identical to those calculated from the posterior expectations $\hat{Y}_{CP|age,group}$, but only culture probability estimates calculated from posterior predictions reflect the variability of culture probability in the population.

The regression analysis accurately models mean and standard deviations of age-wise viral load across sub-groups (clinical status), but not the bimodal distribution of log~10~ viral loads. We tried to implement modeling of log~10~viral load distributions using different strategies, but models that captured the bimodal structure well did not adequately capture variations of mean and standard deviations of age-wise viral load across sub-groups. Hence, we used an additional post-processing step to obtain bimodal posterior predictions.  The post-processing step involves estimating parameters for a mixture of two normal distributions (means, standard deviations, weight) which, for each age-year and subject-group combination, has the same mean as the model-estimated mean viral load and matches the bimodal distribution of viral load values observed in that sub-group. The post-processing is implemented in the functions `calc_post_lin_pred()` and `add_mix()` and use the model `mix_s_all.stan` to estimate parameters of the mixture distribution with the ADVI variational inference algorithm [@Kucukelbir2015-tj].

```{r posterior_predictions}
if (file.exists("pdata/pp_1st_pos_load+.Rdata")) {
  load("pdata/pp_1st_pos_load+.Rdata")
} else {
  post_lin_pred = 
    rbind(
      calc_post_lin_pred(bfit, CPpars, newdata, c_weights_Other),
      calc_post_lin_pred(bfit, CPpars, newdata, c_weights_PAMS),
      calc_post_lin_pred(bfit, CPpars, newdata, c_weights_Hosp),
      calc_post_lin_pred(bfit, CPpars, newdata, all_weights_Age_TestCentre[Group == "All"], sum.Group = NULL) %>% .[,Group := "All"]
    ) %>% 
    .[, Age := as.integer(Age)] %>% 
    .[, .draw := as.integer(.draw)]
  post_pred = 
    rbind(
      calc_post_lin_pred(bfit, CPpars, newdata, c_weights_Other, epred = F),
      calc_post_lin_pred(bfit, CPpars, newdata, c_weights_PAMS, epred = F),
      calc_post_lin_pred(bfit, CPpars, newdata, c_weights_Hosp, epred = F)
    ) %>% 
    .[, Age := as.integer(Age)] %>% 
    .[, .draw := as.integer(.draw)] 
  save(post_lin_pred,post_pred, file = "pdata/pp_1st_pos_load+.Rdata")
}
```


```{r PPPP, fig.cap = "Calculating posterior predictions. Top: Posterior distribution of the expected (mean) viral load for a 25 year old subject from the Other group. Bottom: Distribution of observed viral loads (black outline) and posterior predictions for the same group. The distribution of posterior predictions (green) obtained from the basic analysis model implemented in brms is unimodal and underestimates the proportion of subjects with log10 viral loads larger than 9. Adding the post-processing step recovers the bimodal distribution of viral loads and more accurately estimates the proportion of subjects with very high viral loads.", Eval = T}
Ages = 25
grp = "Other"

simple_posterior_predict = 
  posterior_predict(bfit, newdata = newdata[Age %in% Ages & Group == grp]) %>% 
  as.numeric() 

hdata = 
  rbind(
  data.table(log10Load = bfitdata[round(Age) %in% Ages & Group == grp,log10Load], Estimand = "Observed"),
  data.table(log10Load = post_lin_pred[Age %in% Ages & Group == grp,log10Load], Estimand = "Expectation"),
  data.table(log10Load = simple_posterior_predict, Estimand = "Posterior prediction"),
  data.table(log10Load = post_pred[Age %in% Ages & Group == grp,log10Load], Estimand = "Posterior prediction with post processing")
) %>% 
  .[, Value := ifelse(Estimand == "Expectation","Expectation","Prediction")]

means = hdata[, .(m = mean(log10Load), sd = sd(log10Load)), by = .(Estimand)][, Value := "Prediction"]

hdata %>% 
    ggplot(aes(x = log10Load, fill = Estimand)) + 
    geom_density(data = hdata[Estimand != "Observed"], alpha = .25, color = NA) + 
    geom_density(data = hdata[Estimand == "Observed"],fill = NA, color = "black") + 
    facet_wrap(~Value, scales = "free_y", ncol = 1) + 
    theme(legend.position = "top") +
  geom_vline(xintercept = 9, lty = 3, col = "grey") + 
  xlab(expression(log[10]~viral~load)) +
  gg_expand()
```

In addition to calculating the expected culture probability given the estimated viral load by age and clinical status, we can also calculate the expected culture probability given the observed viral loads as $\hat{Y}_{CP|Y_{load|age,group}} = logit(\alpha_{CP} + \beta_{CP} Y_{load|age,group})$. The following code calculates expected culture probability given the _observed_ viral loads of 20-65 year olds.

```{r CP4obs}
Obs_load_by_age = 
  rbind(
    bfitdata %>% 
      .[, .(log10Load = mean(log10Load)),
        by = .(fAgeGroup, Group)] %>% 
      .[, fAgeGroup := as.character(fAgeGroup)],
    bfitdata %>% 
      .[Age > 20 & Age < 65,
        .(log10Load = mean(log10Load)),
        by = .(Group)] %>% 
      .[,fAgeGroup := "20-65"]
  ) 

CP4obs = c()
for (k in 1:nrow(Obs_load_by_age)) {
  CP4obs = 
    rbind(CP4obs,
        data.table(CP = inv.logit(CPpars$b_log10Load*Obs_load_by_age[k,log10Load] + CPpars$b_Intercept),
                   AgeGroup = Obs_load_by_age[k,fAgeGroup],
                   Group = Obs_load_by_age[k,Group])
  )
}

CP4obs_stats = 
  get_stats(CP4obs, var = "CP",by = c("AgeGroup","Group")) %>% 
  .[, tbl := paste0(round(mean,2), 
                    " (",round(lower90,2),
                    ", ", round(upper90,2),
                    ")")]


CP4obs_tbl = 
  CP4obs_stats %>% dcast(AgeGroup ~ Group, value.var = "tbl") %>% 
  kable(caption = "Culture probability for observed viral loads by age group and clinical status.",
        format = table_format) %>% 
  kable_styling(full_width = F) %>%
  add_footnote("Estimates are based on the average observed viral load in age groups, whereas figures and comparisons reported later are based on estimated viral loads.",
               notation = "none")

CP4obs_tbl
```

Here we calculate the posterior distribution of the average culture probability stratified by clinical status.

```{r}
global_weights = 
  merge(
    expand.grid(
      Age = 0:100,
      Group = unique(bfitdata$Group)) %>% 
      data.table(),
    bfitdata[,.(Age,Group)] %>% 
      .[Age > 100, Age := 100] %>% 
      .[, Age := ceiling(Age)] %>% 
      .[, .(N = .N), by = .(Group, Age)],
    by = c("Group", "Age"), all = T) %>% 
  .[is.na(N), N := 0] %>% 
  .[, w_age := N/sum(N), by = .(Group)] %>% 
  .[, Group := as.character(Group)] %>% 
  .[, c("N") := NULL]

global_weights = 
  rbind(
    global_weights,
    bfitdata[,.(Age,Group)] %>% 
      .[Age > 100, Age := 100] %>% 
      .[, Age := ceiling(Age)] %>% 
      .[, .(w_age = .N), by = .(Age)] %>% 
      .[, w_age := w_age / nrow(bfitdata)] %>% 
      .[, Group := "All"]
  )

setkeyv(post_lin_pred,c("Age","Group"))
setkeyv(global_weights,c("Age","Group"))
global_CP = 
  post_lin_pred %>% 
  .[global_weights, w_CP := CP * w_age] %>%
  .[, .(CP = sum(w_CP)), by = .(.draw,Group)]
```


#### Viral load by age

We start the preparation of results by calculating mean and credible intervals for age- and group-wise viral load. From this we can plot age-wise viral load, stratified by clinical status.

```{r plotLoadByAge, fig.cap= "Estimated viral load by age. Confidence bands indicate 90% credible intervals."}
Group_levels = c("PAMS","Hospitalized","Other","All")

###  culture probability from posterior predictions
stats_by_age = rbind(
  stats_VLCP_by_Age(post_lin_pred,"All"),
  stats_VLCP_by_Age(post_lin_pred,"Other"),
  stats_VLCP_by_Age(post_lin_pred,"PAMS"),
  stats_VLCP_by_Age(post_lin_pred,"Hospitalized")
) %>%
  .[, sample := factor(sample, levels = Group_levels)]

### for culture probability from posterior expectations 
stats_by_age.e = rbind(
  stats_VLCP_by_Age(post_lin_pred,"All",CP.var = "e.CP"),
  stats_VLCP_by_Age(post_lin_pred,"Other",CP.var = "e.CP"),
  stats_VLCP_by_Age(post_lin_pred,"PAMS",CP.var = "e.CP"),
  stats_VLCP_by_Age(post_lin_pred,"Hospitalized",CP.var = "e.CP")
) %>%
  .[, sample := factor(sample, levels = Group_levels)]

p_load_by_age =
  stats_by_age[outcome == "log10Load" & sample != "All"] %>% 
  ggplot(aes(x = Age, y = mean, color = sample, fill = sample)) +
  red_blue_black() +
  conf_ribbon(stats_by_age[outcome == "log10Load" & sample != "All"], fill = "sample") + 
  geom_line() +
  coord_cartesian(ylim = c(2,10)) +
  scale_x_continuous(expand = expansion(0,0)) +
  ylab(expression(Mean~log[10]~viral~load)) +
  guides(color = "none")

p_load_by_age
p_load_by_age = 
  p_load_by_age + 
  theme(legend.position = my_legend_position)  + 
  gg_legend_size(1) +
  gg_expand() + 
  gg_text_size() +
  guides(color = "none")
```

Because we are primarily interested in differences between sub _groups_ of the population, we calculate credible intervals based on the expected viral load (and culture probability). This could however give a false impression about the accuracy of viral load predictions on the subject-level, which should take the error variance into account. 


#### Culture probability by age and differences between age

Age-wise culture probability and derived differences were calculated above. Here we only plot the results of these calculations.

```{r plotCPAgeDifferences, fig.width=10, fig.cap= "Estimated culture probability calculated from posterior expectations (left) and from posterior predictions (right)."}
p_CP_by_age =
  ggplot(stats_by_age[outcome == "CP" & sample != "All"],
         aes(x = Age,
             y = mean,
             color = sample, fill = sample)) +
  red_blue_black() +
  conf_ribbon(stats_by_age[outcome == "CP" & sample != "All"], fill = "sample",conf_levels = seq(50,90,5)) + 
  geom_line() +
  coord_cartesian(ylim = c(0,1)) +
  scale_x_continuous(expand = expansion(0,0)) +
  ylab("Culture probability") +
  guides(color = "none")

p_CP_by_age.e =
  ggplot(stats_by_age.e[outcome == "e.CP" & sample != "All"],
         aes(x = Age,
             y = mean,
             color = sample, fill = sample)) +
  red_blue_black() +
  conf_ribbon(stats_by_age.e[outcome == "CP" & sample != "All"], fill = "sample",conf_levels = seq(50,90,5)) + 
  geom_line() +
  coord_cartesian(ylim = c(0,1)) +
  scale_x_continuous(expand = expansion(0,0)) +
  ylab("Culture probability") +
  guides(color = "none")

p_CP_by_age = 
  p_CP_by_age + 
  theme(legend.position = my_legend_position)  + 
  gg_legend_size(1) +
  gg_expand() + 
  gg_text_size() +
  guides(color = "none")

p_CP_by_age.e = 
  p_CP_by_age.e + 
  theme(legend.position = my_legend_position)  + 
  gg_legend_size(1) +
  gg_expand() + 
  gg_text_size() +
  guides(color = "none")

p_CP_by_age.e + p_CP_by_age + facet_grid(sample~.) + theme(legend.position = "none")
```


Credible intervals have difficulties in portraying uncertainty in multi-modal distributions. Hence, we use highest-density regions to display the uncertainty of posterior predictions obtained after post-processing.

```{r postpredictHDI, fig.cap= "Highest-density regions for posterior predictions of log10 viral load and culture probability by age. The posterior predictions here take the error variance into account and used post-processing to also account for bimodal viral load distributions. The credible intervals indicate certainty of posterior predictions for individual cases (e.g., one 20 year old PAMS subject). In comparison, the credible intervals of posterior expectations used in the paper indicate the certainty of perditions for groups of subjects (e.g., the group of 20 year old PAMS subjects). The highest-density region for culture probability in the PAMS group is bimodal, because viral load is on average higher in this group, which means that a relatively larger share of subject have viral loads in a range that leads with high certainty to positive culturing results.", fig.height=9.5, fig.width=8}

if (file.exists("pdata/HDR_FPT.Rdata")) {
  load("pdata/HDR_FPT.Rdata")
} else {
  VLP9CP_by_Age.hdi = 
  rbind(
    post_pred[, as.list(fast.hdi(CP)),
              by = .(Age, Group)] %>% 
      .[,outcome := "Culture positvity"],
    post_pred[, as.list(fast.hdi(log10Load, 
                                 posterior.dist = "norm")),
              by = .(Age, Group)] %>% 
      .[,outcome := "log10 viral load"],
    post_pred[, as.list(fast.hdi(p9)),
              by = .(Age, Group)] %>% 
      .[,outcome := "P(log10 viral load > 9)"]
  )  %>% 
  .[, outcome := factor(outcome,
                        levels = c("log10 viral load",
                                   "Culture positvity",
                                   "P(log10 viral load > 9)"))] %>% 
    .[, Group := factor(Group, levels = c("PAMS","Hospitalized","Other"))]
  save(VLP9CP_by_Age.hdi,file = "pdata/HDR_FPT.Rdata")
}

p_VL_by_Age.hdi = 
  VLP9CP_by_Age.hdi[outcome == "log10 viral load"] %>% 
  ggplot(aes(x = Age, y = mean, color = Group)) + 
  geom_line() + 
  conf_linerange(color = "Group", size = .770) + 
  facet_wrap(~ Group) + 
  red_blue_black() + 
  theme(legend.position = "none") +
  ylab(expression(log[10]~viral~load)) + 
  geom_hline(yintercept = 9, col = "white", lty = 3) + 
  coord_cartesian(ylim = c(2,10)) + 
  gg_expand(x1 = .025, x2 = .025)

p_high_load = 
  VLP9CP_by_Age.hdi[outcome == "P(log10 viral load > 9)"] %>% 
    ggplot(aes(x = Age, y = mean, color = Group)) + 
    geom_line() + 
    conf_linerange(color = "Group", size = .770) + 
    facet_wrap( ~ Group) + 
    red_blue_black() + 
    theme(legend.position = "none") + 
    ylab(expression(Proportion~log[10]~viral~load>9)) + 
    coord_cartesian(ylim = c(0,.20)) + 
  gg_expand(x1 = .025, x2 = .025)

p_CP_by_Age.hdi = 
  VLP9CP_by_Age.hdi[outcome == "Culture positvity"] %>% 
  ggplot(aes(x = Age, y = mean, color = Group)) + 
  geom_line() + 
  conf_linerange(color = "Group", size = .770) + 
  facet_wrap(~Group) +
  red_blue_black() + 
  theme(legend.position = "none") +
  ylab("Culture probability") + 
  gg_expand(x1 = .025, x2 = .025)

hdi.plot = 
  (p_VL_by_Age.hdi + theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.line.x = element_blank())) / 
  (p_high_load +     theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.line.x = element_blank(), strip.text.x = element_blank())) / 
  (p_CP_by_Age.hdi + theme(strip.text.x = element_blank()))

hdi.plot

ggsave(hdi.plot,file = "figures/S2_HDIpostpredict_1st_pos.png",width = 20, height = 21, units = "cm",dpi = 600)
ggsave(hdi.plot,file = "figures/S2_HDIpostpredict_1st_pos.pdf",width = 20, height = 21, units = "cm")

```

```{r postpredictHDInopostprocessing, fig.cap= "Highest-density regions for posterior predictions of log10 viral load and culture probability by age obtained without post-processing.", fig.height=9.5, fig.width=8}
if (file.exists("pdata/HDR_FPT_no_post_processing.Rdata")) {
  load("pdata/HDR_FPT_no_post_processing.Rdata")
} else {
  VLP9CP_by_Age.hdi = 
  rbind(
    post_lin_pred[, as.list(fast.hdi(CP)),
              by = .(Age, Group)] %>% 
      .[,outcome := "Culture positvity"],
    post_lin_pred[, as.list(fast.hdi(log10Load.p, 
                                 posterior.dist = "norm")),
              by = .(Age, Group)] %>% 
      .[,outcome := "log10 viral load"],
    post_lin_pred[, as.list(fast.hdi(p9)),
              by = .(Age, Group)] %>% 
      .[,outcome := "P(log10 viral load > 9)"]
  )  %>% 
  .[, outcome := factor(outcome,
                        levels = c("log10 viral load",
                                   "Culture positvity",
                                   "P(log10 viral load > 9)"))] %>% 
    .[, Group := factor(Group, levels = c("PAMS","Hospitalized","Other","All"))]
  save(VLP9CP_by_Age.hdi,file = "pdata/HDR_FPT_no_post_processing.Rdata")
}

p_VL_by_Age.hdi = 
  VLP9CP_by_Age.hdi[outcome == "log10 viral load" & Group != "All"] %>% 
  ggplot(aes(x = Age, y = mean, color = Group)) + 
  geom_line() + 
  conf_ribbon(VLP9CP_by_Age.hdi[outcome == "log10 viral load" & Group != "All"], fill = "Group") + 
  facet_wrap(~ Group) + 
  red_blue_black()+ 
  theme(legend.position = "none") +
  ylab(expression(log[10]~viral~load)) + 
  geom_hline(yintercept = 9, col = "white", lty = 3) + 
  coord_cartesian(ylim = c(2,10)) + 
  gg_expand(x1 = .025, x2 = .025)

p_high_load = 
  VLP9CP_by_Age.hdi[outcome == "P(log10 viral load > 9)"& Group != "All"] %>% 
    ggplot(aes(x = Age, y = mean, color = Group)) + 
    geom_line() + 
    conf_ribbon(VLP9CP_by_Age.hdi[outcome == "P(log10 viral load > 9)" & Group != "All"], fill = "Group") +
    facet_wrap( ~ Group) + 
    red_blue_black() + 
    theme(legend.position = "none") + 
    ylab(expression(Proportion~log[10]~viral~load>9)) + 
    coord_cartesian(ylim = c(0,.20)) + 
  gg_expand(x1 = .025, x2 = .025)


p_CP_by_Age.hdi.no.postproc = 
  VLP9CP_by_Age.hdi[outcome == "Culture positvity" & Group != "All"] %>% 
  ggplot(aes(x = Age, y = mean, color = Group)) + 
  geom_line() + 
  conf_ribbon.hdi( VLP9CP_by_Age.hdi[outcome == "Culture positvity" & Group != "All"],fill = "Group") + 
  facet_wrap(~Group) +
  red_blue_black() + 
  theme(legend.position = "none") +
  ylab("Culture probability") + 
  gg_expand(x1 = .025, x2 = .025)


hdi.plot = 
  (p_VL_by_Age.hdi + theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.line.x = element_blank())) / 
  (p_high_load +     theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.line.x = element_blank(), strip.text.x = element_blank())) / 
  (p_CP_by_Age.hdi.no.postproc + theme(strip.text.x = element_blank()))

hdi.plot

ggsave(hdi.plot,file = "figures/S2_HDIpostpredict_1st_pos_no_post_processing.png",width = 20, height = 21, units = "cm",dpi = 600)
ggsave(hdi.plot,file = "figures/S2_HDIpostpredict_1st_pos_no_post_processing.pdf",width = 20, height = 21, units = "cm")
```

#### Group comparisons

Using the above-calculated posterior predictions (without post-processing) by clinical status and age, we next compare PAMS and hospitalized subjects.

```{r PAMSvsnonPAMSVL, fig.cap="Viral load differences between PAMS and non-PAMS subjects by age"}
tmp = 
 post_lin_pred %>%
  .[Group %in% c("PAMS","Hospitalized")] %>% 
  setkeyv(c(".draw","Age","Group")) %>% 
  .[, .(diffPAMS = -diff(log10Load)), by = c("Age",".draw")] %>% 
  .[, as.list(my_stats_list_long(diffPAMS,quantiles = seq(.5,.95,by = .05))), by = "Age"] 

p_VL_PAMSvsHosp = 
  tmp %>% 
  ggplot(aes(x = Age, y = mean)) +
  geom_hline(yintercept = 0, lty = 2, col = "grey") + 
  conf_ribbon(data = tmp,fill = "black") + 
  geom_line() + 
  gg_expand() +
  coord_cartesian(xlim = c(0,101)) +
  ylab(expression(log[10]~viral~load~difference~PAMS~-Hospitalized))

tmp = 
 post_lin_pred %>%
  .[Group != "Other"] %>% 
  setkeyv(c(".draw","Age","Group")) %>% 
  .[, .(diffPAMS = -diff(CP)), by = c("Age",".draw")] %>% 
  .[, as.list(my_stats_list_long(diffPAMS,quantiles = seq(.5,.95,by = .05))), by = "Age"] 

p_CP_PAMSvsHosp = 
  tmp %>% 
  ggplot(aes(x = Age, y = mean)) +
  geom_hline(yintercept = 0, lty = 2, col = "grey") + 
  conf_ribbon(data = tmp,fill = "black") + 
  geom_line() + 
  gg_expand() +
  coord_cartesian(xlim = c(0,101)) +
  ylab("Culture probability difference difference PAMS-Hospitalized")

p_VL_PAMSvsHosp | p_CP_PAMSvsHosp
rm(tmp)
```

#### Age differences

`r ifelse(show_code == T, "First, we calculate the average estimated viral load for the three age groups 0-20, 20-65, 65 and older without stratification by age group.","")`

```{r VLmainAgeGroups}

age_group3_PAMS =
  copy(bfitdata) %>%
  .[Age > 100, Age := 100] %>% 
  .[, Age := ceiling(Age)] %>%
  .[, age_group := cut(Age, breaks = c(0,20,65,101), right = F)] %>%
  .[, list(N_Age = sum(.N)), by = c("age_group","Age")] %>% 
  .[, w := N_Age/sum(N_Age), by = "age_group"] %>% 
  .[, N_Age := NULL]

post_lin_pred_all = post_lin_pred[Group == "All"]
setkeyv(post_lin_pred_all,"Age")
setkeyv(age_group3_PAMS,"Age")
tmp = 
  post_lin_pred_all %>% 
  .[age_group3_PAMS,`:=`(wVL = w*log10Load, age_group = age_group)] %>% 
  .[, .(log10Load = sum(wVL)), by = .(age_group,.draw)] %>% 
  .[, .(load_stats = sprint_stat(log10Load,2)), by = .(age_group)]

load_3_age_groups = tmp$load_stats
names(load_3_age_groups) = tmp$age_group

rm(tmp,post_lin_pred_all)
tmp = gc()
```


`r ifelse(show_code == T, "Next we look at age differences in viral load by comparing younger subjects group against adults aged 20-65.","")`

```{r plotLoadAgeDifferences, fig.cap= "Estimated viral load age differences. Confidence bands indicate 90% credible intervals"}
stats_agegroup_diff =
  rbind(
    stats_VLCP_by_Age(post_lin_pred, "All", get.stats = F) %>%
      calc_diff(age_group_N_comp) %>%
      get_stats(var = "value", by = c("comparison", "outcome")) %>%
      .[, sample := "All"],
    stats_VLCP_by_Age(post_lin_pred, "Other", get.stats = F) %>%
      calc_diff(age_group_N_comp) %>%
      get_stats(var = "value", by = c("comparison", "outcome")) %>%
      .[, sample := "Other"],
    stats_VLCP_by_Age(post_lin_pred,"PAMS", get.stats = F) %>%
      calc_diff(age_group_N_comp.PAMS) %>%
      get_stats(var = "value", by = c("comparison", "outcome")) %>%
      .[, sample := "PAMS"],
    stats_VLCP_by_Age(post_lin_pred,"Hospitalized", get.stats = F) %>%
      calc_diff(age_group_N_comp.Hosp) %>%
      get_stats(var = "value", by = c("comparison", "outcome")) %>%
      .[, sample := "Hospitalized"]
  ) %>%
  .[, sample := factor(sample, levels = Group_levels)]

stats_agegroup_diff[, 
  tbl := paste0(round(mean,digits = ifelse(outcome == "log10Load",2,3)), 
                " (",
                paste0(round(
                        c(lower90,upper90),
                        digits = ifelse(outcome == "log10Load",2,3)),
                       collapse = ", "),
                ")"),
  by = 1:nrow(stats_agegroup_diff)]

bfitdata[,age_group := cut(Age, breaks = c(0,5,10,15,20,65,80,101), right = F)]

N_table = 
  rbind(data.table(table(bfitdata[,age_group])) %>%
        .[, sample := "All"],
        data.table(table(bfitdata[Group == "Other",age_group])) %>%
        .[, sample := "Other"],
      data.table(table(bfitdata[Group == "PAMS",age_group])) %>%
        .[, sample := "PAMS"],
      data.table(table(bfitdata[Group == "Hospitalized",age_group])) %>%
        .[, sample := "Hospitalized"]) %>%
  setnames("V1","age_group") %>%
  .[,age_group := gsub("\\[|\\)","",age_group)] %>%
  .[,age_group := gsub(",","-",age_group)]

for (s in unique(N_table$sample)) {
  for (ag in N_table$age_group[1:4]) {
    stats_agegroup_diff[grepl(ag,comparison) & sample == s,
                        N := N_table[age_group == ag & sample == s,N]]
  }
}


age_group_diff_tbl = 
  dcast(outcome + sample ~ comparison, 
        data = stats_agegroup_diff,
        value.var = "tbl") 

age_group_diff_tbl_print = 
  age_group_diff_tbl %>%
  setnames(names(age_group_diff_tbl),
           gsub("\\[|)","",names(age_group_diff_tbl)) %>% gsub(",","-",.)) %>% 
  kable(format = table_format,
        caption = "Viral load and culture probability by age and age difference") %>%
  kable_styling(full_width = F)
age_group_diff_tbl_print

clvls = c("0-5 vs\n20-65","5-10 vs\n20-65","10-15 vs\n20-65","15-20 vs\n20-65")
stats_agegroup_diff[, comparison := gsub("vs ","vs\n", comparison, perl = T)] %>%
  .[, comparison := factor(comparison, levels = clvls)]
stats_agegroup_diff = stats_agegroup_diff[!is.na(comparison)]


p_load_diff =
  ggplot(stats_agegroup_diff[outcome == "log10Load" & sample != "All" & (grepl("-",comparison))],
         aes(x = comparison, y = mean, color = sample, label = N)) +
  geom_hline(yintercept = 0, color = "grey") +
  geom_point(position = position_dodge(width = dodge_with)) +
  red_blue_black () +
  conf_linerange(stats_agegroup_diff[outcome == "log10Load" & sample != "All" & (grepl("-",comparison))], color = "sample") + 
  ylab(expression(log[10]~viral~load~difference))  +
  guides(color = guide_legend(nrow = 1, byrow = TRUE)) +
  xlab("Age group comparison") +
  theme(legend.position = "top")

p_CP_diff =
  ggplot(stats_agegroup_diff[outcome == "CP" & sample != "All" & (grepl("-",comparison))],
         aes(x = comparison, y = mean, color = sample, label = N)) +
  geom_hline(yintercept = 0, color = "grey") +
  geom_point(position = position_dodge(width = dodge_with)) +
  red_blue_black() +
  conf_linerange(stats_agegroup_diff[outcome == "CP" & sample != "All" & (grepl("-",comparison))],color = "sample") +
  ylab("Culture probability difference")  +
  guides(color = guide_legend(nrow = 1, byrow = TRUE)) +
  xlab("Age group comparison") +
  theme(legend.position = "top")

p_load_diff | p_CP_diff

N_lable =  
  N_table[age_group == "20-65"] %>% 
  .[,label := paste0(sample, " (",N,")")]
  
p_load_diff = 
  p_load_diff +
  geom_text(aes(y = upper90), size = 1.5,
            position = position_dodge(width = dodge_with)) + 
  gg_legend_size(1) +
  gg_text_size() +
  scale_color_manual(name = "Sample (N for 20-65)",
                     labels = N_lable$label,
                     values = c("black","red","blue")) + 
  theme(legend.position = c(.7,.25))

tmp = gc(verbose = F)
```

A more fine-grained comparison compares each age year against 50 year old adults.

```{r plotLoadAgeDifferencesB, fig.cap= "Estimated viral load age differences. Confidence bands indicate 90% credible intervals"}

if (file.exists("pdata/AgeCompFPT.Rdata")) {
  load("pdata/AgeCompFPT.Rdata")
} else {
  age_comps = c()
  for (age in 1:100) {
    for (g in c("PAMS","Hospitalized","Other")) {
      tmp = data.table(
        load_diff = post_lin_pred[Age == age & Group == g, log10Load] - post_lin_pred[Age == 50 & Group == g, log10Load],
        CP_diff = post_lin_pred[Age == age & Group == g, CP] - post_lin_pred[Age == 50 & Group == g, CP]
      )
      age_comps = 
        rbind(
          age_comps,
          tmp %>% 
            get_stats(var = "load_diff") %>% 
            .[, Group :=  g] %>% 
            .[, Age := age] %>% 
            .[, outcome := "load_diff"],
          tmp %>% 
            get_stats(var = "CP_diff") %>% 
            .[, Group :=  g] %>% 
            .[, Age := age] %>% 
            .[, outcome := "CP_diff"]
        )
    }
  }
  age_comps[, Group := factor(Group,levels(stats_by_age$sample))]
  save(age_comps,file = "pdata/AgeCompFPT.Rdata") 
}


p_age_comp_VL = 
  age_comps %>% 
  .[outcome == "load_diff"] %>% 
  ggplot(aes(x = Age, y = mean, color = Group, group = Group)) + 
  geom_hline(yintercept = 0, color ="grey", lty = 2) +
  conf_ribbon(age_comps,fill = "Group") +
  geom_line(show.legend = F) + 
  red_blue_black() + 
  gg_expand() + 
  ylab("Viral load difference to 50 year olds") + 
  gg_add_grid() +
  coord_cartesian(ylim = c(-1.5,1.5)) +
  theme(legend.position = c(.2,.9)) + 
  guides(color = guide_legend(nrow = 1),fill = guide_legend(nrow = 1))

p_age_comp_CP = 
  age_comps %>% 
  .[outcome == "CP_diff"] %>% 
  ggplot(aes(x = Age, y = mean, color = Group, group = Group)) + 
  geom_hline(yintercept = 0, color ="grey", lty = 2) +
  conf_ribbon(age_comps,fill = "Group") +
  geom_line(show.legend = F) + 
  red_blue_black() + 
  gg_expand() + 
  ylab("Culture probability difference to 50 year olds") + 
  gg_add_grid() + 
  coord_cartesian(ylim = c(-.5,.5)) +
  theme(legend.position = c(.25,.97), strip.text.y = element_blank()) + 
  guides(color = guide_legend(nrow = 1, title.position = "left", title = "Group:"),
         fill = guide_legend(nrow = 1, title.position = "left", title = "Group:"))


p_age_comp_VL
```

To collect all age comparisons in one place and thus facilitate comparisons, we compose a table with estimated age differences for viral load and culture probability and unadjusted age differences calculated directly from the raw data. This is table 2 of the paper.

```{r jointDiffTable}
clvls = c("0-5 vs 20-65","5-10 vs 20-65","10-15 vs 20-65","15-20 vs 20-65")
tmp_tbl = 
  stats_agegroup_diff[, .(comparison, sample, tbl,outcome)] %>% 
  dcast(comparison + sample ~ outcome,
        value.var = "tbl") %>% 
  .[, comparison := gsub("\n"," ", comparison)] %>%
  setnames(c("sample","comparison","CP","log10Load"),
           c("Sample","Comparison", "model-diff CP", "model-diff load")) %>%
  .[, Sample := factor(Sample, levels = levels(NHST_stats$Sample))] 

diff_table = 
  merge(tmp_tbl,
        NHST_stats[, .(Sample,Comparison,Difference,`p~MW~`)],
        by = c("Sample","Comparison")) %>%
  .[order(Sample,Comparison)] %>%
  .[, `p~MW~` := ifelse(`p~MW~` < .001,"<.001",as.character(round(`p~MW~`,3)))] %>%
  .[, Comparison := factor(Comparison, levels = clvls)] %>%
  setkeyv(c("Sample","Comparison"))

table_2_caption = "Differences of culture probabilities between age groups."

tbl_age_diff = 
  kable(diff_table[,setdiff(names(diff_table),c("t-stat","t df")),with = F],
      digits = c(0,0,0,0,0,2),
      caption = table_2_caption, 
      format = table_format) %>%
  kable_styling(full_width = F) %>%
  add_footnote("model-diff = model-based difference, CP = culture probability, load = log10viral load, difference = raw difference with 95% confidende intervals, p = p-value, MW = Mann-Whitney U test", notation = "none")

tbl_age_diff

ftdiff = 
  flextable(diff_table) %>%
  autofit() %>%
  set_caption(caption = table_2_caption) %>%
  footnote(i = 1,
           j = c(1,3,4,5,6),
           value = as_paragraph(
             c("PAMS: Pre and asymptomatic subjects",
               "Mean difference and 90% credible interval based on regression analysis. CP = culture positicity",
               "Load = log(10) viral load",
               "Difference and confidence interval based on raw data",
               "p-value from Mann–Whitney U test")),
           ref_symbols = c("a", "b", "c", "d","e"),
           part = "header",
           inline = TRUE)


table_doc <- table_doc %>%
  body_add_flextable(ftdiff) %>%
  body_end_section_landscape()


```


Next we calculate and plot the difference and ratio of culture probability for PAMS and hospitalized subjects, stratified by age in full years.

```{r PAMSvsnonPAMSCP, fig.cap="Viral load differences between PAMS and hospitalized subjects by age. Because ratios have heavy tails, we show median and 25%-50% credible intervals for the ratio of culture probabilities in the right-hand side panel."}

ObsLoad_20_65 = 
  bdata[Age > 20 & Age < 65, .(mean_load = mean(log10Load)), by = .(Group)]

EstCP_20_65_by_PAMS = 
  data.table(
    PAMS = inv.logit(CPpars$b_Intercept + CPpars$b_log10Load * ObsLoad_20_65[Group == "PAMS", mean_load]),
    Other = inv.logit(CPpars$b_Intercept + CPpars$b_log10Load * ObsLoad_20_65[Group == "Other", mean_load]),
    Hospitalized = inv.logit(CPpars$b_Intercept + CPpars$b_log10Load * ObsLoad_20_65[Group == "Hospitalized", mean_load])) %>% 
  .[, delta := PAMS - Hospitalized] %>% 
  .[, ratio := PAMS  / Hospitalized]

pdata = 
  rbind(
    data.table(
      x = c(2.5, rep(ObsLoad_20_65[Group == "Hospitalized", mean_load],2)),
      y = c(rep(mean(EstCP_20_65_by_PAMS$Hospitalized),2),0)) %>% 
      .[, Group := "Hospitalized"],
    data.table(
      x = c(2.5, rep(ObsLoad_20_65[Group == "Other", mean_load],2)),
      y = c(rep(mean(EstCP_20_65_by_PAMS$Other),2),0)) %>% 
      .[, Group := "Other"],
    data.table(
      x = c(2.5, rep(ObsLoad_20_65[Group == "PAMS", mean_load],2)),
      y = c(rep(mean(EstCP_20_65_by_PAMS$PAMS),2),0)) %>%
      .[, Group := "PAMS"]
  ) %>% 
  .[, Group := ordered(Group, levels = c("PAMS","Hospitalized","Other"))]

p_CP_by_load = 
  p_CP_by_load + 
  geom_line(data = pdata, aes(x = x, y = y, color = Group)) + 
  red_blue_black() + 
  theme(legend.position = c(.2,.9))
  
tmp = 
 post_lin_pred %>% 
  .[Group %in% c("PAMS","Hospitalized")] %>% 
  setkeyv(c(".draw","Age","Group")) %>% 
  .[, .(diffPAMS = -diff(CP),
        rrPAMS = 1/exp(diff(log(CP)))),
    by = c("Age",".draw")]
  
  
PAMSvsnonPMASCP.dt = 
  tmp %>% 
  .[, as.list(my_stats_list_long(diffPAMS,quantiles = seq(.5,.95,by = .05))), by = "Age"] 

p_PAMSvsnonPMASCP = 
  PAMSvsnonPMASCP.dt %>% 
  ggplot(aes(x = Age, y = mean)) +
  geom_hline(yintercept = 0, lty = 2, col = "grey") + 
  conf_ribbon(data = PAMSvsnonPMASCP.dt,fill = "black") + 
  geom_line() + 
  gg_expand() +
  ylab("Culture probability difference PAMS - Hospitalized")


PAMSvsnonPMASCPRR.dt = 
  tmp %>% 
  .[, as.list(my_stats_list_long(rrPAMS,quantiles = c(.01,seq(.25,.5,by = .05)))), by = "Age"] %>% 
  .[, median := (lower1 + upper1)/2]

p_PAMSvsnonPMASCPRR = 
  PAMSvsnonPMASCPRR.dt %>% 
  ggplot(aes(x = Age, y = median)) +
  geom_hline(yintercept = 1, lty = 2, col = "grey") + 
  conf_ribbon(data = PAMSvsnonPMASCPRR.dt,fill = "black",conf_levels = seq(25,50,by = 5)) + 
  geom_line() + 
  gg_expand() +
  ylab("Culture probability ratio PAMS / Hospitalized")
p_PAMSvsnonPMASCP | p_PAMSvsnonPMASCPRR
rm(post_lin_pred)
```

At the average viral load of 20-65 year old adults, PAMS, and hospitalized cases have an expected culture probability of `r sprint_stat(EstCP_20_65_by_PAMS$PAMS)` and `r sprint_stat(EstCP_20_65_by_PAMS$Hospitalized)`, respectively, resulting in a differences of `r sprint_stat(EstCP_20_65_by_PAMS$delta)` or a ratio of `r sprint_stat(EstCP_20_65_by_PAMS$ratio)`.

## B.1.1.7 Viral load and culture probability

To visualize the effect of B.1.1.7, we show posterior distributions of estimated viral loads and culture probabilities for B.1.1.7 and non-B.1.1.7 cases as well as for the difference between these two groups.

```{r B117results, fig.cap="Posterior distributions of viral load and culture probability for B.1.1.7 and non-B.1.1.7 cases. A posterior distribution of log10 viral load. B difference of average viral load between B.1.1.7 and non-B.1.1.7 cases. C posterior distribution of the probability of a positive culture load. D Difference of average culture probability between B.1.1.7 and non-B.1.1.7 cases."}
B117_sigmas = 
  B117fit$fit %>% 
  as_draws() %>% 
  subset_draws("b_sigma",regex = T) %>% 
  as_draws_dt() %>% 
  .[, r := rnorm(10000)] %>% 
  .[, r_B117 := exp(b_sigma_Intercept + b_sigma_B117B117) * r] %>% 
  .[, r_nonB117 := exp(b_sigma_Intercept) * r] %>% 
  .[, `:=` (b_sigma_Intercept = NULL , 
            b_sigma_B117B117 = NULL , 
            b_sigma_PAMS = NULL,
            r = NULL)] %>% 
  .[.draw < 4001] %>% 
  setkeyv(".draw")

B117.draws = 
  as_draws(B117fit$fit) %>% 
  subset_draws(c("b_Intercept","b_B117B117")) %>% 
  as_draws_dt() %>% 
  merge(CP.fit$fit %>% 
          as_draws() %>% 
          subset_draws(c("b_Intercept","b_log10Load")) %>% 
          as_draws_dt() %>% 
          setnames(c("b_Intercept","b_log10Load"),c("a_CP","b_CP"))) %>% 
  setkeyv(".draw") %>% 
  .[B117_sigmas, r_B117 := r_B117] %>% 
  .[B117_sigmas, r_nonB117 := r_nonB117] %>% 
  .[, `:=` (
    load.nonB117 = b_Intercept,
    load.B117 = b_Intercept + b_B117B117)] %>% 
  .[, `:=` (
    CP.nonB117 = inv.logit((load.nonB117 + r_nonB117)*b_CP + a_CP),
    CP.B117 = inv.logit((load.B117 + r_B117)*b_CP + a_CP))] %>%  
  .[, `:=` (
    r_nonB117 =  r_nonB117,
    r_B117 = r_B117)] %>% 
  .[, .(.draw, load.nonB117, load.B117, CP.nonB117,CP.B117)] %>% 
  .[, `:=`(load.deltaB117 = load.B117 - load.nonB117,
           CP.deltaB117 = CP.B117 - CP.nonB117,
           CP.RRB117 = CP.B117/CP.nonB117)] %>% 
  melt(id.vars = ".draw") %>% 
  .[, B117 := ifelse(grepl("RR",variable),"RRB117",
                     ifelse(grepl("delta",variable),"deltaB117",
                            ifelse(grepl("nonB117",variable),"nonB117","B117")))] %>% 
  .[, Outcome := ifelse(grepl("CP",variable),"culture positivity","log10Load")]


no_y_axis = theme(axis.title.y = element_blank(), axis.line.y = element_blank(), axis.text.y = element_blank())

p1 = 
  B117.draws[Outcome == "log10Load" & !(grepl("delta|RR",B117))] %>% 
  ggplot(aes(x = value, fill = B117)) +
  stat_histinterval(.width = c(.50, .80, .90), breaks = 25, alpha = .75, color = NA) + 
  scale_fill_manual(values = c("#00A087FF","#7E6148FF"),
                    name = "", labels = c("B.1.1.7","non-B.1.1.7")) +
  scale_color_manual(values = c("#00A087FF","#7E6148FF"),
                    name = "", labels = c("B.1.1.7","non-B.1.1.7")) +
  theme(axis.line.y = element_blank(), axis.text.y = element_blank()) +
  xlab(expression(log[10]~viral~load)) + 
  theme(legend.position = c(.2,.975)) + 
  ylab("Posterior density")

hdi.data = rbind(
  B117.draws[variable == "load.B117",value] %>% 
  fast.hdi(posterior.dist = "norm") %>% 
  .[,.(lower90,upper90)] %>% 
  .[, hdi.group := 1] %>% 
  melt(id.vars = "hdi.group") %>% 
  .[, B117 := "B117"] %>% 
  .[, y := 0],
  B117.draws[variable == "load.nonB117",value] %>% 
  fast.hdi(posterior.dist = "norm") %>% 
  .[,.(lower90,upper90)] %>% 
  .[, hdi.group := 1] %>% 
  melt(id.vars = "hdi.group") %>% 
  .[, B117 := "nonB117"] %>% 
  .[, y := 0])

p1 = 
  p1 +
  geom_line(data = hdi.data,
            aes(y = y, x = value, group = interaction(hdi.group,B117), color = B117),
            size = 1) + 
  gg_add_grid("x")

p2 = 
  B117.draws[Outcome == "log10Load" & (grepl("delta",B117))] %>% 
  ggplot(aes(x = value)) +
  stat_histinterval(.width = c(.50, .80, .90), breaks = 25, alpha = .5) + 
  theme(axis.line.y = element_blank(), axis.text.y = element_blank()) +
  xlab(expression(log[10]~load~B.1.1.7-`non-B.1.1.7`)) +
  coord_cartesian(xlim= c(0.5,1.5)) +
  ylab("") + 
  gg_add_grid("x")

pB117load = (p1 + ggtitle("A")| p2 + ggtitle("B")) + plot_layout(widths = c(1,1))

p1 = 
  B117.draws[Outcome == "culture positivity" & !(grepl("delta|RR",B117))] %>% 
  ggplot(aes(x = value, fill = B117)) +
  stat_histinterval(breaks = 25, alpha = .5, .width = c(), color = NA) + 
  stat_histinterval(.width = c(.50, .80, .90), breaks = 25, alpha = .5, color = NA) + 
  scale_fill_manual(values = c("#00A087FF","#7E6148FF"),
                    name = "", labels = c("B.1.1.7","non-B.1.1.7")) +
  scale_color_manual(values = c("#00A087FF","#7E6148FF"),
                    name = "", labels = c("B.1.1.7","non-B.1.1.7")) + 
  theme(axis.line.y = element_blank(), axis.text.y = element_blank()) +
  xlab("Culture probability") + 
  theme(legend.position = "none") + 
  ylab("Posterior density") 

hdi.data = rbind(
  B117.draws[variable == "CP.B117",value] %>% 
  fast.hdi() %>% 
  .[,.(lower90,upper90)] %>% 
  .[, hdi.group := 1:2] %>% 
  melt(id.vars = "hdi.group") %>% 
  .[, B117 := "B117"] %>% 
  .[, y := -.025],
  B117.draws[variable == "CP.nonB117",value] %>% 
  fast.hdi() %>% 
  .[,.(lower90,upper90)] %>% 
  .[, hdi.group := 1:2] %>% 
  melt(id.vars = "hdi.group") %>% 
  .[, B117 := "nonB117"] %>% 
  .[, y := 0])
p1 = 
  p1 + 
  geom_line(data = hdi.data,
            aes(y = y, x = value, group = interaction(hdi.group,B117), color = B117),
            size = 1) + 
  gg_add_grid("x")
p2 = 
  B117.draws[Outcome == "culture positivity" & (grepl("delta",B117))] %>% 
  ggplot(aes(x = value)) +
  stat_histinterval(breaks = 15, alpha = .5,.width = c(.50, .80, .90)) + 
  no_y_axis + 
  xlab(expression(Culture~prob.~B.1.1.7-`non-B.1.1.7`)) + 
  gg_add_grid("x")

pB117cp = (p1 + ggtitle("C") | p2 + ggtitle("D")) + plot_layout(widths = c(1,1))

pB117load / pB117cp
```

At `r B117.draws[B117 == "B117" & Outcome == "log10Load",value] %>% sprint_stat()` B.1.1.7 cases have on average a `r B117.draws[B117 == "deltaB117" & Outcome == "log10Load",value] %>% sprint_stat()` higher viral load than non-B.1.1.7 cases. Assuming that the association between culture probability is the same for the B.1.1.7 and non-B.1.1.7 variants of the virus, this implies an average probability of a positive culture of `r B117.draws[B117 == "B117" & Outcome == "culture positivity",value] %>% sprint_stat(2)` for B.1.1.7 cases, compared to `r B117.draws[B117 == "nonB117" & Outcome == "culture positivity",value] %>% sprint_stat(2)` for non-B.1.1.7 cases, that is a `r B117.draws[B117 == "RRB117" & Outcome == "culture positivity",value] %>% sprint_stat()` times higher culture probability for B.1.1.7.

The estimates of a mean `r B117.draws[B117 == "RRB117" & Outcome == "culture positivity",value] %>% sprint_stat()` times higher culture probability for B.1.1.7 can appear surprising given the mean culture probabilities of `r B117.draws[B117 == "B117" & Outcome == "culture positivity",value] %>% sprint_stat(2)` and `r B117.draws[B117 == "nonB117" & Outcome == "culture positivity",value] %>% sprint_stat(2)`. The following figure shows that this is explained by the fact that the estimated culture probability for B.1.1.7 is strictly higher, and that ratio distributions are generally heavily skewed. Due to the long-tailed nature of ratio distributions, we report median and 25th and 75th percentile to describe the ratio of culture probabilities: `r B117.draws[B117 == "RRB117" & Outcome == "culture positivity",value] %>% sprint_stat(my_quantiles = c(.25,.75), avg = "median")`.

```{r SkewedRatio, fig.cap="Posterior distribution of the ratio of B.1.1.7 and B.1.177 culture probabilities. Left: Each point is one posterior draw, for which we calculated culture probability. The same errror term is used in each draw for B.1.1.7 and non-B.1.1.7. When the error term is very low (< -2) we get a low viral load and culture probability for B.1.1.7 and non-B.1.1.7. When the error term is very high  (> 2) we get a high viral load and culture probability for both. Only when the error term is intermediate does the on average higher viral load of B.1.1.7 translate to a higher culture probability. Right: The ratio of culture probabilties has a heavy tail. (x-axis clipped at 30.)"}
scatter_plot = 
  B117.draws[B117 %in% c("B117","nonB117") & Outcome == "culture positivity",.(B117,value,.draw)] %>% 
  dcast(.draw~B117) %>% 
  ggplot(aes(x = B117, y = nonB117)) + 
  geom_point(alpha = .25, col = "blue", shape = 16) + 
  coord_cartesian(xlim = c(0,1), ylim = c(0,1)) +
  geom_abline(intercept = 0, slope = 1, col = "grey",lty = 3)  + 
  xlab("Estimated culture probability B.1.1.7") + 
  ylab("Estimated culture probability B.1.177") +
  gg_expand()

post_dens_ratio = 
  B117.draws[B117 == "RRB117" & Outcome == "culture positivity"] %>% 
  ggplot(aes(x = value)) + 
  stat_histinterval(fill = "blue", alpha = .5, breaks = 100, col = "red",.width = c(.50, .80, .90)) + 
  coord_cartesian(xlim = c(1,30)) + 
  xlab("Culture probability B.1.1.7 \n/ Culture probability B.1.177") +
  ylab("Posterior mass") +
  gg_expand()

scatter_plot | post_dens_ratio
```


To document the robustness of the result to different analysis approaches, we show the results of a number of alternative analyses. It should be kept in mind that the primary analysis with the most restricted data set has the relative cleanest design, i.e., the best matching of B.1.1.7 and non-B.1.1.7 cases.

```{r B117Table}
T_B117_caption = "Log10 viral load differences between B.1.1.7 and non-B.1.1.7 cases. Each row shows the estimated effect of B.1.1.7 in an alternative analysis."
T_B117_footnote = "Window: Number of days within which non-B.1.1.7 cases must occur in a test centre with B.1.1.7 cases to be included in the analysis. 5 = non-B.1.1.7 cases detected within +/-5 days of B.1.1.7 cases are included. Adjusted: Adjustment for age, PCR type, group (PAMS, Hospitalized, Other), and sex. Random effects: Modelling test centres as random effects. Paired: Yes if only test centres that report B.1.1.7 and non-B.1.1.7 centres are included. Effects are given with 90% credible intervals."

B117_ktbl = 
  B117_model_stats %>% 
  kable(format = table_format,
        caption = T_B117_caption) %>%
  kable_styling(full_width = F) %>%
  add_footnote(T_B117_footnote,
               notation = "none")

B117_ktbl

B117_ft = 
  flextable(B117_model_stats) %>%
  autofit() %>%
  set_caption(caption = T_B117_caption) %>%
  footnote(i = 1,
           j = 1,
           value = as_paragraph(T_B117_footnote),
           ref_symbols = "",
           part = "header",
           inline = TRUE)

table_doc <- table_doc %>%
  body_add_flextable(B117_ft) %>%
  body_end_section_landscape()


```


## Viral load and culture probability over time

### Basic model parameters: Peak day and slopes

The following plot shows population-level means and standard deviations of parameter estimates.

```{r plotParamsGroupLevel, fig.cap="Posterior distributions of means and standard deviations of population-level model parameters. Numbers in the plot are mean and the 90% credible interval. Top row: Posterior distribution for mean over cases. Bottom row: Posterior distribution for standard deviation over cases"}
rename_params = function(dt) {
  pars = c(expression(Slope~of~log[10]~load~increase),
           expression(Days~to~peak~load),
         expression(Peak~log[10]~viral~load),
         expression(Slope~of~log[10]~load~decrease))
  dt[, parameter := factor(parameter,
                           levels = c("slope_up",
                                      "time2peak",
                                      "intercept",
                                      "slope_down"),
                           labels = pars)]
  return(dt)
}

if (file.exists("pdata/r_model_pars_by_draw.Rdata")) {
  load("pdata/r_model_pars_by_draw.Rdata")
} else {
  r_model_pars_by_draw = 
  rbind(
    smrs_by_draw(draws, "intercept"),
    smrs_by_draw(draws, "slope_up"),
    smrs_by_draw(draws, "slope_down"),
    smrs_by_draw(draws, "time2peak")) %>% 
  rename_params()
  setnames(r_model_pars_by_draw,"parameter","variable")
  save(r_model_pars_by_draw,file = "pdata/r_model_pars_by_draw.Rdata")
}

param_means = 
  r_model_pars_by_draw %>% 
  plot_post_hists(value.var = "mean", labeller = label_parsed) +
  xlab("mean over cases") + 
  ggtitle("Group-level parameters")
param_sds = r_model_pars_by_draw %>% 
  plot_post_hists(value.var = "sd", labeller = label_parsed) +
  xlab("sd over cases")

paramplot = (param_means) / (param_sds)
paramplot

ggsave(paramplot,
       file = "figures/S5_TC_model_params_posterior_distribution.png",
       height = 15,
       width = 30,
       units = "cm",
       dpi = 300,
       type = "cairo")
ggsave(paramplot,
       file = "figures/S5_TC_model_params_posterior_distribution.pdf",
       height = 15,
       width = 30,
       units = "cm")

setnames(r_model_pars_by_draw,"variable", "parameter")

tmp = gc(verbose = F)

```

This model estimated the mean peak viral load to be `r sprint_stat(r_model_pars_by_draw[parameter == "Peak ~ log[10] ~ viral ~ load",mean])` at `r sprint_stat(r_model_pars_by_draw[parameter == "Days ~ to ~ peak ~ load",mean])` days after infections, and gradients of `r  sprint_stat(r_model_pars_by_draw[parameter == "Slope ~ of ~ log[10] ~ load ~ increase",mean])` and `r sprint_stat(r_model_pars_by_draw[parameter == "Slope ~ of ~ log[10] ~ load ~ decrease",mean], digits = 3)`. The corresponding standard deviations were `r sprint_stat(r_model_pars_by_draw[parameter == "Peak ~ log[10] ~ viral ~ load",sd], digits = 2)`, `r sprint_stat(r_model_pars_by_draw[parameter == "Days ~ to ~ peak ~ load",sd], digits = 2)`, `r  sprint_stat(r_model_pars_by_draw[parameter == "Slope ~ of ~ log[10] ~ load ~ increase",sd], digits = 2)` and `r sprint_stat(r_model_pars_by_draw[parameter == "Slope ~ of ~ log[10] ~ load ~ decrease",sd], digits = 3)`, respectively.

The following plot shows the distribution of the mean (expected) model parameter over subjects. The larger standard deviation for slope of viral load increase is due to using PAMS as a predictor for shift and growth gradient, which are two dependent parameters in the model. Related, the PAMS cases are also those with a lower peak viral load and fewer days to peak viral load.

```{r plotParamsPatientLevel, fig.cap="Distribution of expected subject-level model parameters. Expectations of subject-level parameters are simply averages of posterior samples for a parameter for a subject."}
if (file.exists("pdata/r_model_pars_by_ID.Rdata")) {
  load("pdata/r_model_pars_by_ID.Rdata")
} else {
  r_model_pars_by_ID = 
    rbind(
      smrs_by_ID(draws, "intercept"),
      smrs_by_ID(draws, "slope_up"),
      smrs_by_ID(draws, "slope_down"),
      smrs_by_ID(draws, "time2peak")) %>% 
    rename_params()
  setnames(r_model_pars_by_ID,"parameter","variable")
  save(r_model_pars_by_ID,file = "pdata/r_model_pars_by_ID.Rdata")
}

p_m = 
  r_model_pars_by_ID %>% 
  merge(day_data[day == 0, .(ID,PAMS1)], by = "ID") %>% 
  .[, PAMS := factor(PAMS1, labels = c("No","Yes"))] %>%
  plot_post_hists(value.var = "mean", fill = "PAMS", labeller = label_parsed) + 
  ggtitle("Subject-level expectations") + 
  ylab("count over subjects") + 
  xlab("posterior expectation") + 
  red_blue(3:2) +
  theme(legend.position = c(0.2,0.5))

p_sd = 
  r_model_pars_by_ID %>% 
  merge(day_data[day == 0, .(ID,PAMS1)], by = "ID") %>% 
  .[, PAMS := factor(PAMS1, labels = c("No","Yes"))] %>%
  plot_post_hists(value.var = "sd", fill = "PAMS", labeller = label_parsed) + 
  ggtitle("Subject-level standard deviations") + 
  ylab("count over subjects") + 
  xlab("posterior expectation") + 
  red_blue(3:2) +
  theme(legend.position = "none")

p_m / p_sd  

shift_by_ID = 
  draws_by_id(draws = draws,params = c("shift")) %>%
  .[, .(mean = collapse::fmean(shift),
        q5 = quantile(shift,.05, names = F),
        q95 = quantile(shift,.95, names = F),
        sd = collapse::fsd(shift)), by = c("ID")] %>%
  merge(day_data[day == 0, .(ID,day_first_positive)], by = "ID") %>% 
  .[, mean := mean + day_first_positive] %>% 
  .[, q5 := q5+day_first_positive] %>% 
  .[, q95 := q95 + day_first_positive]  %>% 
  .[, variable := "day_first_positive_shifted"] %>% 
  .[, day_first_positive := NULL]

r_model_pars_by_ID = rbind(
  r_model_pars_by_ID,
  shift_by_ID
)

r_model_pars_by_ID %>% 
  merge(day_data[day == 0, .(ID,personHash,PAMS1, Age, N_tests)], by = "ID") %>% 
fwrite(file = "figures/TC_model_parameters_by_participant.csv",
       sep = ",")
rm(r_model_pars_by_ID)
```

One limitation of the available data is that testing did not follow a pre-planned schedule. Instead, the number of tests a subject had most likely depended on factors like the severity and duration of the illness. Hence we also investigate how model parameters are associated with the number of tests performed for a subject:

```{r plotParamsGrpLevel, fig.cap="Means and credible intervals of model parameters split by cases with different numbers of tests.  Note that model parameters were estimated in one joint analyses."}
day_data[, N_tests_group := cut(N_tests,
                          breaks = c(2,3,4,5,7,20),
                          ordered_result = T,
                          labels = c("3","4","5","6-7",">7"))]

if (file.exists("pdata/r_model_pars_by_grp.Rdata")) {
  load("pdata/r_model_pars_by_grp.Rdata")
} else {
  r_model_pars_by_grp = 
  rbind(
    smrs_by_grp(draws, "time2peak", unique(day_data[,.(ID,N_tests_group)])),
    smrs_by_grp(draws, "intercept", unique(day_data[,.(ID,N_tests_group)])),
    smrs_by_grp(draws, "slope_down", unique(day_data[,.(ID,N_tests_group)])),
    smrs_by_grp(draws, "slope_up", unique(day_data[,.(ID,N_tests_group)]))) %>% 
  rename_params()
  save(r_model_pars_by_grp,file = "pdata/r_model_pars_by_grp.Rdata")
}

r_model_pars_by_grp[, N_tests_group := factor(N_tests_group,levels = levels(day_data$N_tests_group))]

tbl = 
  r_model_pars_by_grp %>%
  dcast(N_tests_group ~ parameter,value.var = "tbl") %>%
  setnames("N_tests_group","# tests")

pars1_caption = "Estimated model parameters for cases with different numbers of tests per subject."
ktbl = 
  clean_colnames(tbl) %>% 
  kable(format = table_format,
        caption = pars1_caption) %>%
  kable_styling(full_width = F) %>%
  add_footnote("Numbers are means and 90% credible intervals. Parameters were estimated in one joint model.",
               notation = "none")
ktbl

p_pars_by_group = 
  ggplot(r_model_pars_by_grp, aes(x = N_tests_group, y = mean)) + 
  geom_point() + 
  facet_wrap(~parameter, scale = "free", ncol = 4, labeller = label_parsed) + 
  conf_linerange() + 
  xlab("Number of tests per case") + 
  ylab("Parameter estimate")

ft_pars1 = 
  clean_colnames(tbl) %>% 
  flextable() %>%
  autofit() %>%
  set_caption(caption = pars1_caption)
table_doc <- table_doc %>%
  body_add_flextable(ft_pars1) %>%
  body_end_section_landscape() 
rm(r_model_pars_by_grp)
p_pars_by_group
```

The clear association between number of tests, with the peak viral load (intercept) and the down slope is expected, if one assumes that cases with a more severe illness have a higher peak viral load which is also declines more slowly. This analysis does not show clear differences in the attack rate (slope up) between subjects with different numbers of tests.

As a further test, we also estimated model parameters with different subset of cases, i.e., with at least 3, at least 4, ... at least 9 tests. Figure \@ref(fig:plotParamsSubsamplesLevel) shows the estimated parameters for these data subsets.

```{r plotParamsSubsamplesLevel, fig.cap="Means and credible intervals of model parameters split by sub-samples with different number of minimum tests per case. Note that model parameters were estimated in independent analyses.", eval = T}
my_vars = c("intercept","slope_up","slope_down","time2peak")

if (file.exists("pdata/model_pars_by_sub_sample.Rdata")) {
  load("pdata/model_pars_by_sub_sample.Rdata")
} else {
  model_pars_by_sub_sample = rbind(
    pars_min3 = 
      stats_over_draws(draws = draws,
                       vars = my_vars) %>%
      .[, min_N_tests := 3],
    do.call(rbind,
            lapply(4:9, function(x) {
              stats_over_draws(file = here(paste0("CP/fits/w25o/",model,"_sel",x,".Rdata")),
                               vars = my_vars) %>%
                .[, min_N_tests := x]
            })
    )
  ) %>% 
    rename_params()
  save(model_pars_by_sub_sample,file = "pdata/model_pars_by_sub_sample.Rdata")
}



tbl = 
  model_pars_by_sub_sample %>%
  .[, tbl := paste0(round(mean,2)," (",round(lower90,2),", ",round(upper90,2),")")] %>%
  dcast(min_N_tests ~ parameter,value.var = "tbl") %>%
  setnames("min_N_tests","min # tests") 


pars2_caption = "Estimated model parameters for sub-samples with different minimum number of tests per subject."
pars2_note = "Numbers are means and 90% credible intervals. Parameters were estimated separately for subjects with different number of tests."

ktbl = 
  kable(tbl,
        format = table_format,
        caption = pars2_caption) %>%
  kable_styling(full_width = F) %>%
  add_footnote(pars2_note,
               notation = "none")
ktbl


p_pars_by_sub_sample = 
  ggplot(model_pars_by_sub_sample, aes(x = min_N_tests, y = mean)) + 
  geom_point() + 
  facet_wrap(~parameter, scale = "free", ncol = 4, labeller = label_parsed) + 
  conf_linerange() + 
  xlab("Minimum number of tests in sub-sample.") + 
  ylab("Parameter estimate")
p_pars_by_sub_sample
rm(model_pars_by_sub_sample)
((p_pars_by_group + ggtitle("A"))/ 
         (p_pars_by_sub_sample + ggtitle("B"))) %>% 
  ggsave(file = "figures/S11_TC_model_params_by_subsample_group.png",
       width = 30,
       height = 20,
       units = "cm",
       type = "cairo")
ggsave(file = "figures/S11_TC_model_params_by_subsample_group.pdf",
       width = 30,
       height = 20,
       units = "cm")

ft_pars2= 
  flextable(tbl) %>%
  autofit() %>%
  set_caption(caption = pars2_caption)

table_doc <- table_doc %>%
  body_add_flextable(ft_pars2) %>%
  body_end_section_landscape() 
```


### Associations with adjustment variables

```{r plotPCReffectTimecourse, fig.cap="Posterior distribution of the association between PCR system and viral load."}
p = 
  draws %>% 
  subset_draws("intercept_PCR") %>%
  plot_post_hists()
p +  
  xlab("Regression weight for PCR system = cobas.") + 
  geom_vline(xintercept = 0, lty = 3, col = "red")
```

Figure \@ref(fig:plotCentreEffectTimecourse) shows associations between test centre category and test log~10~ viral load. For instance, *any tests* taken at C19 centres resulted on average in 0.28 higher log~10~ viral load, compared to the grand mean and after adjustment for the other variables in the model. These effects were obtained as random effects.

```{r plotCentreEffectTimecourse, fig.cap="Posterior distribution of random effects of test centre category on viral load. These random effects capture variations of average viral load measured in different test centre categories."}
centres = gsub("centreCategory",
               "",
               colnames(datalist$centre))
p = 
  draws %>% 
  subset_draws("int_centr") %>%
  plot_post_hists(labels = centres, nrow = 3)
p +  
  xlab("Regression weight of test centre category for viral load at any time")  + 
  geom_vline(xintercept = 0, lty = 3, col = "red")
```

Figure \@ref(fig:ReffCentr1Intercept) shows associations between the test centre category of the first test and peak viral load. For instance, participants with a first positive test obtained in a residence for the elderly (RES) had on average an estimated *peak* viral load of 7.9, compared to a value of 7.5 for subjects with a first positive test from an outpatient department (OD). These effects were obtained as random effects.

```{r ReffCentr1Intercept, fig.cap="Posterior distribution of random effects of test centre type for first test on peak viral load. Note that these associations are adjusted for age."}
tmp = 
  draws %>% 
  subset_draws("int_centre1_raw") %>% 
  as_draws_dt() %>% 
  melt(id.var = ".draw", value.name = "int_centre1_raw") %>% 
  .[, centr1 := factor(as.numeric(factor(variable)),
                          labels = names(table(day_data[day == 0,testCentreCategory])))] %>%
  merge(draws %>%
          subset_draws("int_centre1_sigma") %>%
          as_draws_dt(), by = ".draw") %>% 
  merge(draws %>%
          subset_draws("log_intercept_mu") %>%
          as_draws_dt(), by = ".draw") %>% 
  .[, intercept := exp(log_intercept_mu + int_centre1_raw * int_centre1_sigma )] 

tmp_stats = 
  tmp %>% 
  .[, .(m = mean(intercept), lower = quantile(intercept,.5), upper = quantile(intercept,.95)) , by = centr1] %>% 
  .[, label := paste0(round(m,1)," (",round(lower,1),", ",round(upper,1),")")]

p_reff_c1_int = 
  tmp %>% 
  ggplot(aes(x = intercept)) + 
  geom_vline(xintercept = ss[variable == "intercept_mu",mean], color = "grey", lty = 2) +
  geom_histogram(alpha = .5, fill = "blue", bins = 30) + 
  facet_wrap(~centr1) + 
  theme(axis.line.y = element_blank(), axis.text.y = element_blank()) +
  ylab("Effect of the first test centre on peak viral load")

p_reff_c1_int +
    geom_text(data = tmp_stats,
              aes(x = min(ggplot_build(p_reff_c1_int)$data[[2]][,"xmin"]),
                  y = .9*max(ggplot_build(p_reff_c1_int)$data[[2]][,"ymax"]),
                  label = label),
              hjust = 0, size = 3)
rm(tmp)
```

Figure \@ref(fig:ReffCentr1SlopeDown) shows associations between the test centre category with longest stay and decay gradient. The test centre with the longest stay is defined as the test centre catgeory with the longest period from the first to the last of consecutive tests from that test centre category.

```{r ReffCentr1SlopeDown, fig.cap="Posterior distribution of random effects of test centre type with longest stay on decay gradient. Stay is defined as the number of days between the first and the last of consecutive tests from a test centre category. Cases without a unique centre with the longest stay are labeled X. Note that these associations are adjusted for age."}
tmp = 
  draws %>% 
  subset_draws("slope_down_ld_centre_raw") %>% 
  as_draws_dt() %>% 
  melt(id.var = ".draw", value.name = "slope_down_ld_centre_raw") %>% 
  .[, ld_centre := factor(as.numeric(factor(variable)),
                          labels = names(table(day_data[day == 0,ld_centre])))] %>% 
  merge(draws %>%
          subset_draws("slope_down_ld_centre_sigma") %>%
          as_draws_dt(), by = ".draw") %>% 
  merge(draws %>%
          subset_draws("log_slope_down_mu") %>%
          as_draws_dt(), by = ".draw") %>% 
  .[, slope_down := -exp(log_slope_down_mu + slope_down_ld_centre_raw * slope_down_ld_centre_sigma )] 

tmp_stats = 
  tmp %>% 
  .[, .(m = mean(slope_down), lower = quantile(slope_down,.5), upper = quantile(slope_down,.95)) , by = ld_centre] %>% 
  .[, label := paste0(round(m,3)," (",round(lower,3),", ",round(upper,3),")")]
p_reff_ld_centre_int = 
  tmp %>% 
  ggplot(aes(x = slope_down)) + 
  geom_vline(xintercept = -ss[variable == "slope_down_mu",mean], color = "grey", lty = 2) +
  geom_histogram(alpha = .5, fill = "blue", bins = 30) + 
  facet_wrap(~ld_centre) + 
  theme(axis.line.y = element_blank(), axis.text.y = element_blank()) 

p_reff_ld_centre_int +
    geom_text(data = tmp_stats,
              aes(x = min(tmp$slope_down),
                  y = max(ggplot_build(p_reff_c1_int)$data[[2]][,"ymax"]),
                  label = label),
              hjust = 0, size = 3)
rm(tmp,ss)
```

```{r modelParsByPAMSHosp, fig.height= 30/2.54, fig.width=15/2.54, fig.cap= "Model parameters by clinical status and gender. Note that due to limitations of the available data, both presence and absence of group differences in these result remain associated with uncertainty."}

if (file.exists("pdata/model_pars_by_PAMS_HOSP.Rdata")) {
  load("pdata/model_pars_by_PAMS_HOSP.Rdata")
} else {
  model_pars_by_PAMS = 
  rbind(
    smrs_by_grp(draws, "slope_up",day_data[day == 0, .(ID,PAMS1)], calc.delta = T),
    smrs_by_grp(draws, "intercept",day_data[day == 0, .(ID,PAMS1)], calc.delta = T),
    smrs_by_grp(draws, "time2peak",day_data[day == 0, .(ID,PAMS1)], calc.delta = T),
    smrs_by_grp(draws, "slope_down",day_data[day == 0, .(ID,PAMS1)], calc.delta = T)
  ) %>% 
    setnames("PAMS1","group") %>% 
    .[, grouping.variable := "PAMS"] %>% 
    .[, group := gsub("FALSE-TRUE","diff",group)] %>% 
    .[, group := gsub("TRUE","PAMS",group)] %>%
    .[, group := gsub("FALSE","non-PAMS",group)] 

model_pars_by_hospitalized = 
  rbind(
    smrs_by_grp(draws, "slope_up",day_data[day == 0, .(ID,Hospitalized)], calc.delta = T),
    smrs_by_grp(draws, "intercept",day_data[day == 0, .(ID,Hospitalized)], calc.delta = T),
    smrs_by_grp(draws, "time2peak",day_data[day == 0, .(ID,Hospitalized)], calc.delta = T),
    smrs_by_grp(draws, "slope_down",day_data[day == 0, .(ID,Hospitalized)], calc.delta = T)
  )  %>% 
    .[, grouping.variable := "Hospitalized"] %>% 
    setnames("Hospitalized","group") %>% 
  .[, group := gsub("0-1","diff",group)] %>% 
  .[, group := gsub("0","non-hosp.",group)] %>% 
  .[, group := gsub("1","Hospitalised",group)]

# 5 subjects with missing gender
grp.dt = day_data[day == 0, .(ID,Gender)][, Gender := ifelse(is.na(Gender),sample(0:1,1),Gender), by = .(ID)]
model_pars_by_Gender = 
  rbind(
    smrs_by_grp(draws, "slope_up",grp.dt, calc.delta = T),
    smrs_by_grp(draws, "intercept",grp.dt, calc.delta = T),
    smrs_by_grp(draws, "time2peak",grp.dt, calc.delta = T),
    smrs_by_grp(draws, "slope_down",grp.dt, calc.delta = T)
  )  %>% 
    .[, grouping.variable := "Gender"] %>% 
    setnames("Gender","group") %>% 
  .[, group := gsub("0-1","diff",group)] %>% 
  .[, group := gsub("0","Female",group)] %>% 
  .[, group := gsub("1","Male",group)]

 save(model_pars_by_PAMS,
      model_pars_by_hospitalized,
      model_pars_by_Gender,
      file = "pdata/model_pars_by_PAMS_HOSP.Rdata")
}


tmp_lvls = rev(c("PAMS","non-PAMS","Hospitalised","non-hosp.","Female","Male","diff"))
model_pars_by = 
  rbind(
    model_pars_by_PAMS,
    model_pars_by_hospitalized,
    model_pars_by_Gender) %>% 
  rename_params() %>% 
  .[, value := ifelse(group == "diff","difference","estimate")] %>% 
  .[, value := factor(value, levels = c("estimate","difference"))] %>% 
  .[, group := factor(group, levels = tmp_lvls)] %>% 
  setnames("grouping.variable","Grouped_by")

plot_model_pars_by = 
  model_pars_by %>% 
  ggplot(aes(x = group, y = mean, ymin = lower90, ymax = upper90, color = Grouped_by)) + 
  geom_point(position = position_dodge(dodge_with)) + 
  conf_linerange(data = model_pars_by,color = "Grouped_by") + 
  facet_wrap(parameter ~ value, scale = "free", labeller = label_parsed, ncol = 2) + 
  ylab("parameter value") + 
  theme(legend.position = "top") + 
  geom_hline(data = model_pars_by[group == "diff"], aes(yintercept = 0), col = "grey", lty = 3) +
  coord_flip() + xlab("")

plot_model_pars_by
```

```{r modelParsByPAMSHospTable}
model_pars_by_tbl = 
  model_pars_by %>% 
  dcast(Grouped_by + group ~ parameter, value.var = "tbl") 

N_data = 
  rbind(day_data[day == 0, .(N = .N), by = .(Hospitalized)] %>% 
          .[, Grouped_by := "Hospitalized"] %>% 
          setnames("Hospitalized", "group") %>% 
          .[, group := ifelse(group == 0,"non-hosp.","Hospitalised" )],
        day_data[day == 0, .(N = .N), by = .(PAMS1)] %>% 
          .[, Grouped_by := "PAMS"] %>% 
          setnames("PAMS1", "group")%>% 
          .[, group := ifelse(group == 0,"non-PAMS","PAMS" )],
        day_data[day == 0, .(N = .N), by = .(Gender)] %>% 
          .[, Grouped_by := "Gender"] %>% 
          setnames("Gender", "group") %>% 
          .[!is.na(group)]  %>% 
          .[, group := ifelse(group == 0,"Female","Male" )]
  ) 

model_pars_by_tbl = 
  merge(model_pars_by_tbl,
        N_data,
        by = c("Grouped_by","group"),
        all.x = T) %>% 
  .[, group := factor(group, levels = rev(tmp_lvls))] %>% 
  setkeyv(c("Grouped_by", "group"))

gv = c("Grouped_by", "group", "N")
model_pars_by_tbl = 
  model_pars_by_tbl[, c(gv, 
                        setdiff(names(model_pars_by_tbl),gv)),
                    with = F]

model_pars_by_ktbl = 
  kable(model_pars_by_tbl,
        format = table_format,
        caption = "Model parameters by PAMS and hospitalisation.") %>%
  kable_styling(full_width = F)

model_pars_by_ktbl

model_pars_by_tbl_ft = 
  flextable(model_pars_by_tbl) %>%
  autofit() %>%
  set_caption(caption = "Model parameters by PAMS and hospitalisation.")
  
table_doc <- table_doc %>%
  body_add_flextable(model_pars_by_tbl_ft) %>%
  body_end_section_landscape()

```

### Viral load over time

Figure \@ref(fig:VLoverTime) shows estimated viral loads over time. The red line and shaded area are expected viral load and the 90% credible interval. The blue lines are estimated time courses for individual subjects.

```{r VLoverTime, fig.cap="Estimated viral load over time. Blue lines are posterior expectations (means) for subjects. The red line and shaded area are sample average and its 90% credible interval."}

if (file.exists("pdata/VL_by_day.Rdata")) {
  load("pdata/VL_by_day.Rdata")
} else {
  VL_by_key_days_draws = 
    VLCP_by_day_draws %>%
    .[day_shifted %in% c(0,5,8)] %>%
    .[, list(mean = mean(log10Load), sd = sd(log10Load)), by = c(".draw","day_shifted")] %>%
    melt(id.vars = c(".draw","day_shifted"), variable.name = "statistic") 
  VL_by_day = 
    VLCP_by_day_draws %>%
    .[, value := collapse::fmean(log10Load), by = .(day_shifted,.draw)] %>%
    get_stats(by = "day_shifted") %>%
    setnames("mean","log10Load") %>%
    .[, ID := 0]
  save(VL_by_day,VL_by_key_days_draws,file = "pdata/VL_by_day.Rdata")
}

plot_VL_by_day = 
  plot_by_day(VL_by_day,
              VLCP_by_dayID %>% as.data.frame(), y.var = "log10Load", ylim = c(0,10), xlim = c(-5,25)) +
    ylab(expression(log[10]~viral~load))  + 
    gg_text_size()

tmp = gc(verbose = F)
plot_VL_by_day
```

### Number of days from peak viral load to symptom onset

For `r sum(!is.na(day_data[day == 0,onset_day]))` participants with time course data we also had a self-reported date of symptoms onset. This data is shown in figure \@ref(fig:SOraw). The presence of a few unexpected very early self-reported symptom onsets (more than 10 days before the first positive test) motivated the employment of a mixture model to estimate the temporal distance between peak viral load and symptom onset, where a skew-normal prior with the parameters $\xi = -2.5$, $\omega = 10$, and $\tau=10$ modeled the prior expectation of the temporal distance, a normal distribution with $\mu=0$ and $\sigma=50$ modeled potential inaccurate recall, and a weight parameter $\theta \in[0,1]$ with a uniform prior modeled the weight of the two processes.

```{r SOraw, fig.cap = "Histogram of time between first test and self-reported symptom onset."}
day_data[day == 0 & !(is.na(onset_day))] %>% 
  ggplot(aes(x = onset_day)) +
  geom_histogram() + 
  xlab("Days since first test") + 
  ylab("Number subjects")
```

```{r OnsetResults}
theta = draws %>% subset_draws("theta") %>% as.numeric()

peak2onset =
  draws %>% 
  thin_draws(1) %>% 
  subset_draws("shifted_onset") %>% 
  as_draws_dt() %>% 
  melt(id.var = ".draw")

peak2onset_m = 
  peak2onset %>% 
  .[,.(m = median(value)), by = .(.draw)]
```

The estimated theta of `r sprint_stat(theta,2)` indicates that around 5% of the responses are ascribed to inaccurate recall. We estimate that symptom onset occurs around `r sprint_stat(peak2onset_m$m)` days after peak viral load. \@ref(fig:SOest) visualizes this result. 

```{r SOest, fig.cap="Estimated number of days from peak load to symptom onset. The main figure shows overlapping histograms (generated from the posterior distribution) of estimated symptom onsets, relative to peak viral load. A small number of participants reported a symptom onset prior to the first positive test in our data. The inset shows the posterior distribution of the mean estimated symptom onset over subjects with symptom onset data."}
p1 = 
  peak2onset %>% 
  ggplot(aes(x = value,group = .draw)) + 
  geom_histogram(position = "identity", alpha = .01, bins = 65) + 
  xlab("Days since peak viral load") + 
  theme(axis.line.y = element_blank(), 
        axis.title.y = element_blank(), 
        axis.text.y = element_blank())

tmp = as.matrix(peak2onset_m$m,ncol = 1) %>%
  as_draws() 
dimnames(tmp)$variable = "Mean"
p2 = 
  tmp %>% 
  as.matrix(peak2onset_m$m,ncol = 1) %>% 
  as_draws() %>% 
  plot_post_hists()  + 
  xlab("Days since peak load") + 
  gg_add_grid() + 
  geom_vline(xintercept = mean(peak2onset_m$m)) + 
  ylab("") 

px = 
  p1 + 
  inset_element(p2,-0.025,0.375,.55,1)
px

ggsave(px,filename = "figures/S15_peak2onset.png", width = 15, height = 12, units = "cm", dpi = 600)
ggsave(px,filename = "figures/S15_peak2onset.pdf", width = 15, height = 12, units = "cm")

rm(peak2onset,peak2onset_m,tmp,p1,p2,px)
```


### Number / percent of cases tested befor peak viral load

```{r PrepDetectionEstimation}

day_data %>% 
  .[log10Load> 2, day_first_positive := min(day), by = "ID"] %>%
  .[, day_first_positive := max(day_first_positive), by = "ID"] %>% 
  .[, Group := ifelse(Hospitalized == 1, "Hospitalized",ifelse(PAMS1 == 1,"PAMS","Other"))]

if (file.exists("pdata/DetectionTiming.Rdata")) {
  load("pdata/DetectionTiming.Rdata")
} else {
  shift_ttp = 
    draws_by_id(draws,c("shift","slope_up","intercept","time2peak"))
  setkeyv(day_data,"ID")
  positive_before_peak_load_by_ID_draw =
  merge(shift_ttp,
        day_data[day == 0,
                 .(ID,first_test_negative,day_first_positive,N_tests,Age,PAMS1,Group)],
        by = "ID",
        allow.cartesian = T)  %>%
  .[, shift := shift] %>%
  .[, day_first_positive_shifted := day_first_positive + shift] %>%
  .[, days_1stTest_to_peak := time2peak - day_first_positive_shifted] %>%
  .[, days_infection_to_1stPosTest := time2peak + day_first_positive_shifted] %>%
  .[, p_pos_test_before_peak := ((day_first_positive + shift) < 0) ] %>%
  .[, pos_test_before_peak := day_first_positive_shifted < 0] %>%
  .[, pos_test_before_peak_b := ifelse(p_pos_test_before_peak > runif(1),T,F), by = .(ID,.draw)]
  setkeyv(positive_before_peak_load_by_ID_draw,"ID")
  
day_first_post_test_by_draw = 
  positive_before_peak_load_by_ID_draw %>%
  .[, .(m_day_first_positive_shifted = mean(day_first_positive_shifted),
        sd_day_first_positive_shifted = sd(day_first_positive_shifted)),
    by = .(`.draw`, pos_test_before_peak)]

infection_to_first_post_test_by_draw = 
  positive_before_peak_load_by_ID_draw %>%
  .[, .(m_inf_to_first_positive_shifted = mean(days_infection_to_1stPosTest),
        sd_inf_to_first_positive_shifted = sd(days_infection_to_1stPosTest)),
    by = .(`.draw`, pos_test_before_peak)]

day_first_post_test_under70_PAMS = 
  positive_before_peak_load_by_ID_draw %>%
  .[Age < 70] %>% 
  .[, .(m_day_first_positive_shifted = mean(day_first_positive_shifted),
        sd_day_first_positive_shifted = sd(day_first_positive_shifted)),
    by = .(`.draw`, PAMS1)]

positive_before_peak_load_by_draw =
  positive_before_peak_load_by_ID_draw %>%
  .[, .(p_pos_test_before_peak = mean(p_pos_test_before_peak),
        n_pos_test_before_peak = sum(pos_test_before_peak_b),
        m_day_first_positive_shifted = mean(day_first_positive_shifted),
        sd_day_first_positive_shifted = sd(day_first_positive_shifted)),
   by = .(.draw)]
  
  save(positive_before_peak_load_by_ID_draw,
       day_first_post_test_by_draw,
       infection_to_first_post_test_by_draw,
       day_first_post_test_under70_PAMS,
       positive_before_peak_load_by_draw,
       file = "pdata/DetectionTiming.Rdata")
  rm(shift_ttp)
}

```

Figure \@ref(fig:Days2Detection) shows that our analysis estimates that it takes on average around `r round(mean(positive_before_peak_load_by_ID_draw[,days_infection_to_1stPosTest]),1)` days from the start of viral shedding to the first positive test, and that this average is is associated with considerable variation between subjects.

```{r Days2Detection, fig.cap="Histograms for number of days from infection to first positive test. The figure shows for each draw from the posterior sample a histogram of days from infection to first positive test across subjects."}
positive_before_peak_load_by_ID_draw %>% 
  ggplot(aes(x = days_infection_to_1stPosTest, group = .draw)) + 
  stat_bin(aes(y=..count..),
           geom="step", alpha = .01, 
           position = "identity", bins = 50) + 
  xlab("Number of days from infection to first positive test") +
  ylab("Number of subjects") + 
  gg_expand()
```


Here we calculate the expected proportion of people who had a first positive test result before peak viral load.

```{r TestsBeforePeakLoad, fig.cap="Estimated timing of first positive tests relative to peak viral load. The figure shows posterior distributions."}
positive_before_peak_load_by_draw %>% 
   setnames(c("p_pos_test_before_peak","n_pos_test_before_peak","m_day_first_positive_shifted","sd_day_first_positive_shifted"),
            c("% pos. tests before peak load","N pos. tests before peak load","mean day of 1st pos. test","sd day of 1st pos. test")) %>% 
  .[, `N pos. tests before peak load` := as.numeric(`N pos. tests before peak load`)] %>% 
  melt(id.var = ".draw") %>% 
  plot_post_hists() +
    ylab("Estimate")
```

The estimated average probability of having a positive test before peak viral load is `r sprint_stat(positive_before_peak_load_by_draw[["% pos. tests before peak load"]]*100, 1)`% (`r sprint_stat(positive_before_peak_load_by_draw[["N pos. tests before peak load"]], 0)` out of the `r length(unique(day_data$ID))` subjects). Over all subjects, the estimated day for the first positive test was `r sprint_stat(positive_before_peak_load_by_draw[["mean day of 1st pos. test"]] , 2)` after peak viral load, with a standard deviation of `r sprint_stat(positive_before_peak_load_by_draw[["sd day of 1st pos. test"]], 2)`. For those who had the first positive test before peak load, we estimated this to be `r sprint_stat(day_first_post_test_by_draw[pos_test_before_peak == T,m_day_first_positive_shifted])` before peak viral load, whereas it was estimated to be `r sprint_stat(day_first_post_test_by_draw[pos_test_before_peak == F,m_day_first_positive_shifted])` for the others (sd: `r sprint_stat(day_first_post_test_by_draw[pos_test_before_peak == F,sd_day_first_positive_shifted])`).

The mean estimated day of detection for PAMS subjects under 70 years is `r sprint_stat(day_first_post_test_under70_PAMS[PAMS1 == 1,m_day_first_positive_shifted])` days versus the non-PAMS mean of `r sprint_stat(day_first_post_test_under70_PAMS[PAMS1 == 0,m_day_first_positive_shifted])` days.

```{r clacDetectionByPAMS}
tmp = 
  positive_before_peak_load_by_ID_draw %>% 
  .[, .(day_first_positive_shifted = mean(day_first_positive_shifted)),
                                       by = .(.draw,PAMS1)] 


positive_before_peak_load_by_draw =
  positive_before_peak_load_by_ID_draw %>%
  .[, .(p_pos_test_before_peak = mean(p_pos_test_before_peak),
        n_pos_test_before_peak = sum(pos_test_before_peak_b),
        m_day_first_positive_shifted = mean(day_first_positive_shifted),
        sd_day_first_positive_shifted = sd(day_first_positive_shifted)),
   by = .(.draw)]

rm(positive_before_peak_load_by_ID_draw)
```


Next, we test investigate the hypothesis that PAMS cases are detected earlier than non-PAMS cases. Figure \@ref(fig:DetectionByPAMS) shows that among participants with time course data, PAMS cases were on average detected `r sprint_stat(tmp[PAMS1 == T,day_first_positive_shifted])` days after peak load, `r sprint_stat(tmp[PAMS1 == F,day_first_positive_shifted]-tmp[PAMS1 == T,day_first_positive_shifted])` days before non-PAMS cases, which were on average detected `r sprint_stat(tmp[PAMS1 == F,day_first_positive_shifted])` days after peak load.

```{r DetectionByPAMS, fig.cap="Posterior distribution of temporal distance from peak load to first positive test"}

tmp %>% 
  .[, PAMS := factor(if_else(PAMS1 == T,"PAMS","non-PAMS"),levels = c("PAMS","non-PAMS"))] %>% 
  ggplot(aes(x = day_first_positive_shifted, fill = PAMS)) + 
  geom_histogram(alpha = .5, position = "identity", bins = 75) + 
  red_blue() + 
  xlab("Mean number of days from peak load to first positive test") + 
  ylab("N posterior draws") + 
  theme(legend.position = c(.2,.8))
rm(tmp)
```

Note that the reliability of these results is linked to the reliability with which we could estimate when in the time course of the infection the tests were done, which remains somewhat uncertain.

### Days from non-infectiousness or detectable viral load to peak viral load

Here we calculate the number of days from barely non-detectable viral load or culture probability of only 2.5% to peak viral load and thus peak culture probability.

```{r daysdetectiontonpeak, fig.cap="Expected numbers of days from 2.5% to maximum culture probability (left). 90% credible interval in parentheses."}
plor_daysdetectiontonpeak_data = 
  draws %>% 
  subset_draws(c("intercept_mu","slope_up_mu","alpha_CP","beta_CP")) %>% 
  as_draws_dt() %>% 
  .[, maxCP := alpha_CP + `beta_CP[1]`*intercept_mu] %>% 
  .[, dayMax := -(alpha_CP - `beta_CP[1]`*intercept_mu + maxCP) / (`beta_CP[1]` * slope_up_mu)] %>% 
  .[, day25 := -(alpha_CP - `beta_CP[1]`*intercept_mu + logit(.01)) / (`beta_CP[1]` * slope_up_mu)] %>% 
  .[, days25toMax := day25-dayMax] %>% 
  .[,.(.draw,days25toMax)] %>% melt(id.var = ".draw")

plor_daysdetectiontonpeak_data %>% 
  plot_post_hists()
```

Note that (as above) the reliability of these results is linked to the reliability with which we could estimate when in the time course of the infection the tests was done, which is currently uncertain.

### Culture probability over time

Figure \@ref(fig:CPoverTime) shows estimated culture probability over time.

```{r CPoverTime, fig.cap="Estimated culture probability over time. Blue lines are posterior expectations (means) for subjects. The red line and shaded area are sample average and its 90% credible interval."}

if (file.exists("pdata/CP_by_day.Rdata")) {
  load("pdata/CP_by_day.Rdata")
} else {
  CP_by_key_days_draws = 
    VLCP_by_day_draws %>%
    .[day_shifted %in% c(-2, 0,5,10)] %>%
    .[, .(mean = mean(CP), sd = sd(CP)), by = c(".draw","day_shifted")] %>%
    melt(id.vars = c(".draw","day_shifted"), variable.name = "statistic")
  
  CP_by_day = 
    VLCP_by_day_draws %>%
    .[, value := collapse::fmean(CP), by = c("day_shifted",".draw")] %>%
    get_stats(by = "day_shifted") %>%
    setnames("mean","CP") %>%
    .[, ID := 0]
  save(CP_by_key_days_draws,CP_by_day,file = "pdata/CP_by_day.Rdata")
}


plot_CP_by_day = 
  plot_by_day(CP_by_day,
              VLCP_by_dayID %>% as.data.frame(), y.var = "CP", ylim = c(-.005,1), xlim = c(-5,25)) +
  ylab("Culture probability")  + 
  gg_text_size()
tmp = gc(verbose = F)
plot_CP_by_day
```

We estimate a peak viral load of `r sprint_stat(VL_by_key_days_draws[statistic == "mean" & day_shifted == 0,value])` at around `r sprint_stat(r_model_pars_by_draw[parameter == "Days ~ to ~ peak ~ load", mean])` days after the estimated start of viral shedding. Given the non-linear association between viral load and culture infectivity, the estimated culture infectivity shows greater changes over time, with a peak of `r sprint_stat(CP_by_key_days_draws[statistic == "mean" & day_shifted == 0,value],2)` (between participation standard deviation: `r sprint_stat(CP_by_key_days_draws[statistic == "sd" & day_shifted == 0,value],2)`), which declines to `r sprint_stat(CP_by_key_days_draws[statistic == "mean" & day_shifted == 5,value],2)` 5 days later, and `r sprint_stat(CP_by_key_days_draws[statistic == "mean" & day_shifted == 10,value],2)` 10 days after peak viral load.

### Conditional effects of age on model parameters

We used a spline model to estimate the association between age and peak viral load as well as viral loads slopes. 

```{r makeFigureX, fig.width=20/2.54, fig.height=30/2.54, fig.cap="Associations between age and subject-level model parameters. The left column shows conditional effects, that is the associations with age after marginalizing out variability due to clinical status and gender. Ribbons show 90% credible intervals. The histograms in the right column show posterior distributions for the average parameter estimate for the sample. The gray inset at the bottom of panel C shows the age distribution of the sample.", eval = T}
param_levels = 
  c("Growth gradient","Peak viral load","Decay gradient")

if (file.exists("pdata/TC_ConditionalEffectAge.Rdata")) {
  load("pdata/TC_ConditionalEffectAge.Rdata")
} else {
  px = 
    lapply(c("intercept","slope_up","slope_down"), 
           function(var, predictor = "Age") {
             cond_eff_contPGH(var,predictor)
           }
    ) %>% 
    do.call(rbind,.) %>% 
    .[, parameter := gsub("intercept","Peak viral load", parameter)] %>% 
    .[, parameter := gsub("slope_up","Growth gradient", parameter)] %>% 
    .[, parameter := gsub("slope_down","Decay gradient", parameter)] %>% 
    .[, parameter := factor(parameter, levels = param_levels)] %>% 
    get_stats(by = c("Age","parameter"))
  
  mus = 
    do.call(rbind,
            lapply(c("intercept","slope_up","slope_down"),
                   function(p) 
                     data.table(value = draws %>% 
                                  subset_draws(p) %>% 
                                  as_draws_matrix() %>% 
                                  as.vector(),
                                parameter = p))) %>% 
    .[, parameter := gsub("intercept","Peak viral load", parameter)] %>% 
    .[, parameter := gsub("slope_up","Growth gradient", parameter)] %>% 
    .[, parameter := gsub("slope_down","Decay gradient", parameter)] %>% 
    .[, parameter := factor(parameter, levels = param_levels)] 
  
  save(px,mus,file = "pdata/TC_ConditionalEffectAge.Rdata")
}


sub_plots = vector(length = 3,mode = "list")
names(sub_plots) = c("Growth gradient", "Peak viral load","Decay gradient")
k = 0
for (p in names(sub_plots)) {
  k = k+1
  lims = range(
    quantile(mus[parameter == p,value],c(.001,.999)),
    range(px[parameter == p, c("upper95","lower95"),with = F])
  )
  
  p1 =
    px[parameter == p] %>% 
    ggplot(aes(x = Age, y = mean)) + 
    conf_ribbon(px,fill = "black") + 
    geom_line() +
    coord_cartesian(xlim = c(-1,101)) + 
    ylab(p) + 
    gg_expand() + 
    gg_text_size() + 
    coord_cartesian(ylim = lims) + 
    theme(plot.margin = margin(-10,-5,-5,0, unit = "pt")) + 
    gg_add_grid() + 
    ggtitle(LETTERS[k])
  
  if (p != "Decay gradient")
    p1 = p1 + xlab("")

  
  p2 = 
    mus[parameter == p] %>% 
    ggplot(aes(x = value)) + 
    geom_histogram(fill = "blue",alpha = .5, bins = 30) +
    gg_expand() + 
    coord_flip(xlim = lims * c(.999,1.001)) + 
    ylab("") + 
    gg_text_size() +
    gg_add_grid("y") +
    theme_marginal()
  
  sub_plots[[p]] = (p1 | p2) + plot_layout(widths = c(3,1))
}

sub_plots[[3]][[2]] = 
  sub_plots[[3]][[2]] + 
  theme(axis.title.x = element_text()) + ylab("N")

Age_hist = 
  day_data[day == 0, .(Age)] %>% 
  ggplot(aes(x = Age)) + 
  geom_histogram(breaks = seq(0:100), alpha = .25) + 
  gg_expand() + theme_marginal()

layout = c(
  patchwork::area(t = 1,l = 1,b = 20, r = 20),
  patchwork::area(t = 1,l = 21,b = 20, r = 27),
  patchwork::area(t = 21,l = 1,b = 40, r = 20),
  patchwork::area(t = 21,l = 21,b = 40, r = 27),
  patchwork::area(t = 41,l = 1,b = 60, r = 20),
  patchwork::area(t = 41,l = 21,b = 60, r = 27),
  patchwork::area(t = 55,l = 1,b = 60, r = 20)
)

sub_plots[[1]][[1]] = sub_plots[[1]][[1]] + ylab(expression(Slope~of~log[10]~load~increase))
sub_plots[[2]][[1]] = sub_plots[[2]][[1]] + ylab(expression(Peak~log[10]~viral~load))
sub_plots[[3]][[1]] = sub_plots[[3]][[1]] + ylab(expression(Slope~of~log[10]~load~decline))

p_par_by_age = 
  sub_plots[[1]][[1]]  + sub_plots[[1]][[2]] + 
  sub_plots[[2]][[1]] + sub_plots[[2]][[2]] +   
  sub_plots[[3]][[1]] + sub_plots[[3]][[2]] + 
  Age_hist +
  plot_layout(design = layout) + 
  theme(plot.margin = margin(-10,-5,-5,0, unit = "pt"))

ggsave(p_par_by_age,
       file = "figures/S10_TC_params_by_age.png",
       width = 20, height = 30, units = "cm", dpi = 300)
ggsave(p_par_by_age,
       file = "figures/S10_TC_params_by_age.pdf",
       width = 20, height = 30, units = "cm")
p_par_by_age

rm(p_par_by_age,sub_plots,mus,p2)
tmp = gc()
```

### Posterior predictions of peak viral load and culture probability by age

Using a similar approach as above for associations of viral load and culture probability by age, we now calculate and show highest-density regions for viral load and culture probability by day since peak viral load. One difference to the calculation by age is that we use posterior expectations and not posterior predictions for this analysis. The reason for this choice is that the time course model already increases considerable intra-individual variance in the viral loads over time, and that the error variance for the time course model is much lower than for the age-model.

```{r, fig.cap="Highest posterior density region (HDR) for peak viral load and culture infectiousness over time by clinical status and age. Top row: 90% HDR for estimated peak viral load. The solid line in each plot indicates the mean. Middle row: 90% HDR for proportion of subjects with a peak log10 viral load higher than 9. Bottom row: 90% HDR for estimated peak culture infectivity. The HDR for the PAMS and Other groups shows a bimodal distribution of peak viral load for some age groups. For PAMS subjects younger than ~40 years, the results suggest that the majority of participants have a lower culture probability, whereas a minority of subjects have a high culture probability. For subjects aged around 45 years old, less than 10% have the estimated mean culture infectiousness.", fig.height=8.5, fig.width=8 }
if (file.exists("pdata/pp_peak_load_by_age_group.Rdata")) {
  load("pdata/pp_peak_load_by_age_group.Rdata")
} else {
  sigma = 
    draws %>% 
    subset_draws("sigma_mu") %>%
    as_draws_dt() %>%
    .[, sd := exp(sigma_mu)] %>%
    setkeyv(".draw")
  
  r = 
    data.table(.draw = 1:4000,
               r = rnorm(4000)) %>% 
    setkeyv(".draw") %>% 
    .[, r := r-mean(r)] %>% 
    .[, r := r/sd(r)] %>% 
    .[sigma, epsilon := sd*r]
  
  peak_loads = c()
  for (g in c("Other","Hospitalized","PAMS")) {
    setPGH = c(PAMS1 = 0, Gender = .5, Hospitalized = 0, B117 = 0)
    if (g == "Hospitalized")
      setPGH["Hospitalized"] = 1
    if (g == "PAMS")
      setPGH["PAMS1"] = 1
    
    peak_load =  
      cond_eff_contPGH("intercept", adjust = T, round_Age = 0, setPGH = setPGH) %>% 
      .[, .draw := as.integer(.draw)] %>% 
      setkeyv(".draw") %>% 
      .[, parameter := NULL] %>% 
      .[, Group := g]
    
    peak_load %>% 
      .[r, log10Load := value + epsilon] %>% 
      .[r, epsilon := epsilon] %>% 
      .[sigma, p9 := 1-pnorm(9,value,sd)] %>% 
      .[, value := NULL]
    
    peak_loads = 
      rbind(peak_loads,
            peak_load)
    
  }
  CPpars = draws %>% 
    subset_draws(c("alpha_CP","beta_CP[1]")) %>% 
    as_draws_dt() %>% 
    setnames("beta_CP[1]","beta_CP") %>% 
    setkeyv(".draw") 

  peak_loads %>% 
    setkeyv(".draw") %>% 
    .[CPpars, CP := inv.logit(alpha_CP + beta_CP*log10Load)]
  
  peak_load_hdi =
    peak_loads[,
               as.list(fast.hdi(log10Load,posterior.dist = "norm")),
               by = .(Age,Group)] %>% 
    .[, Group := factor(Group, levels = c("PAMS","Hospitalized","Other"))]
  
  peak_pload9_hdi =
    peak_loads[,
               as.list(fast.hdi(p9,posterior.dist = "beta")),
               by = .(Age,Group)] %>% 
    .[, Group := factor(Group, levels = c("PAMS","Hospitalized","Other"))]
  
  peak_CP_hdi =
    peak_loads[,
               as.list(fast.hdi(CP)),
               by = .(Age,Group)] %>% 
    .[, Group := factor(Group, levels = c("PAMS","Hospitalized","Other"))]
  
  save(peak_load_hdi,peak_pload9_hdi,peak_CP_hdi,file = "pdata/pp_peak_load_by_age_group.Rdata")
}
 
p1 =
  peak_load_hdi %>%
  ggplot(aes(x = Age, y = mean, color = Group)) +
  geom_line() +
  conf_linerange(peak_load_hdi, color = "Group", size = .770)   +
  facet_wrap(~Group) +
  red_blue(c(2,3,1)) +
  theme(legend.position = "none") +
  ylab(expression(Peak~log[10]~viral~load)) + 
  coord_cartesian(ylim = c(4.5,11)) + 
  geom_hline(yintercept = 9, col = "white", lty = 3) + 
  theme(axis.line.x = element_blank(), axis.text.x = element_blank(), axis.title.x = element_blank()) + 
  gg_expand(x1 = .025, x2 = .025)

p2 =
  peak_pload9_hdi %>%
  ggplot(aes(x = Age, y = mean, color = Group)) +
  geom_line() +
  conf_linerange(peak_pload9_hdi, color = "Group", size = .770)   +
  facet_wrap(~Group) +
  red_blue(c(2,3,1)) +
  theme(legend.position = "none") +
  ylab(expression(Prop.~peak~log[10]~viral~load~larger~9)) + 
  coord_cartesian(ylim = c(0,.5)) + 
  theme(axis.line.x = element_blank(), axis.text.x = element_blank(), axis.title.x = element_blank(), strip.text.x = element_blank()) + 
  gg_expand(x1 = .025, x2 = .025)

p3 = 
  peak_CP_hdi %>% 
  ggplot(aes(x = Age, y = mean, color = Group)) + 
  geom_line() +
  conf_linerange(peak_CP_hdi, color = "Group", size = .770)   + 
  facet_wrap(~Group) + 
  red_blue(c(2,3,1)) + 
  theme(legend.position = "none") + 
  ylab("Culture probability") + 
  theme(strip.text.x = element_blank()) + 
  gg_expand(x1 = .025, x2 = .025)

px = p1 / p2 / p3
ggsave(px,file = "figures/S6_HDI_posterior_predict_peak.png", width = 20, height = 21, units = "cm",dpi = 600)
ggsave(px,file = "figures/S6_HDI_posterior_predict_peak.pdf", width = 20, height = 21, units = "cm")

px

```


### Viral load and culture probability over time by group

The following plots show viral load and culture probability over time stratified by various grouping variables. All results are generated from posterior predictions from the same model.

```{r VLbyDayPrimaryCentre, fig.cap = "Viral load time course stratified by primary test centre category. The primary test centre category is the one with the longest duration between consecutive tests from the same test centre category. If there were categories with equal duration, a subject was assigned to the most severe one, i.e., in the order hospitalized, other, PAMS. If assignment to a unique category was not possible, a subject was assigned to a rest-category X. Hospitalized patients (e.g., WD, IDW, ICU) had the highest peak load,  followed by patients from the Other category (ED, OD, CP). Patients with COVID-19 test centres (C19) as primary test centres had the lowest peak viral load."}
grp.dt = unique(day_data[, .(ID,ld_centre)])
grp.var = grep("ID",names(grp.dt), value = T, invert = T)

if (file.exists("pdata/VLbyDayPrimaryCentre.Rdata")) {
  load("pdata/VLbyDayPrimaryCentre.Rdata")
} else {
  by_day_grp = 
    do.call(rbind,
            lapply(unique(grp.dt[[grp.var]]), 
                   function(x) {
                     idx = grp.dt[get(grp.var) == x,ID]
                     VLCP_by_day_draws[ID %in% idx,
                                       list(log10Load = collapse::fmean(log10Load)),
                                       by = .(.draw,day_shifted)] %>% 
                       melt(id.vars = c(".draw", "day_shifted")) %>% 
                       get_stats(by = c("variable","day_shifted")) %>% 
                       .[,(grp.var) := x]
                   })
    )
  
  mx = 
    by_day_grp %>% 
    .[, .(mean = mean(mean)), by = .(day_shifted,variable)]
  
  new_levels = by_day_grp[day_shifted == 0,][order(-mean),ld_centre]
  by_day_grp %>% 
    .[,ld_centre := factor(as.character(ld_centre),
                           levels = new_levels,ordered = T)]
  save(by_day_grp,mx,new_levels,file = "pdata/VLbyDayPrimaryCentre.Rdata")
}


N_table = 
  grp.dt[,.(N = .N),by = grp.var] %>%
  .[ N > 0] %>%
  .[, ld_centre := factor(ld_centre, levels = new_levels, ordered = T)] %>% 
  .[, label := paste0(ld_centre," (",N,")")] %>% 
  .[order(ld_centre)]

p_VL_by_ld_centre = 
  by_day_grp %>% 
  ggplot(aes(x = day_shifted,y = mean)) + 
  geom_line(aes(color = ld_centre)) + 
  conf_ribbon(by_day_grp, fill = "ld_centre") +
  geom_line(data = mx, lty = 2, col = "white") + 
  coord_cartesian(xlim = c(-5,25),ylim = c(0,9)) + 
  guides(fill=guide_legend(ncol=2),color=guide_legend(ncol=2)) + 
  ylab(expression(poportion~log[10]~viral~load)) + 
  xlab("Days from peak viral load") + 
  scale_color_ordinal(name = "Primary centre category", labels = N_table$label) + 
  scale_fill_ordinal(name = "Primary centre category", labels = N_table$label)

ggsave(p_VL_by_ld_centre, filename = "figures/S11_VL_by_ld_centre.png",width = 15, height = 10, units = "cm", dpi = 600)
ggsave(p_VL_by_ld_centre, filename = "figures/S11_VL_by_ld_centre.pdf",width = 15, height = 10, units = "cm")
p_VL_by_ld_centre
```


```{r CPVLbyDayAge, fig.cap="Viral load and culture positvity time courses by age group and differences in culture probability."}
day_data[, Age_group := cut(Age,
                          breaks = c(seq(0,20,5),45,55,65,101),
                          ordered_result = T,
                          labels = c("0-5","5-10","10-15","15-20","20-45","45-55","55-65","65+"))]

grp.dt = unique(day_data[,.(ID,Age_group)])
my_comparisons = 
  combn(levels(day_data$Age_group),2)
my_comparisons = my_comparisons[,grepl("45-55",my_comparisons[2,]) | 
                                  grepl("45-55",my_comparisons[1,])]
my_comparisons[,(ncol(my_comparisons)-1):ncol(my_comparisons)] = 
  my_comparisons[c(2,1),(ncol(my_comparisons)-1):ncol(my_comparisons)]
if (file.exists("pdata/TC_by_age_grp2.Rdata")) {
  load("pdata/TC_by_age_grp2.Rdata")
} else {
  TC_by_age_grp2 = 
  plot_by_day_grp_delta(VLCP_by_day_draws,
                      grp.dt = unique(day_data[!is.na(Age_group),.(ID,Age_group)]),
                      comparisons = my_comparisons)
  TC_by_age_grp2_peak_VLCB_tbl = 
  merge(
  TC_by_age_grp2[[1]]$data %>%
  .[day_shifted == 0] %>%
  .[,tbl := paste0(round(mean,2),
                " (", round(lower90,2),
                ", ", round(upper90,2),")")] %>%
  .[,.(Age_group,tbl)],
  TC_by_age_grp2[[2]]$data %>%
  .[day_shifted == 0] %>%
  .[,tbl := paste0(round(mean,2),
                " (", round(lower90,2),
                ", ", round(upper90,2),")")] %>%
  .[,.(Age_group,tbl)],
by = "Age_group") %>% 
  setnames(c("tbl.x","tbl.y"),c("Viral load","Culture probability"))

CP_RR_tbl = 
  plot_delta_grps(VLCP_by_day_draws,
                  grp.dt = grp.dt,
                  y.var = "CP",
                  stat = "RR",
                  comparisons = my_comparisons,
                  plot =  F) %>%
  .[,tbl := paste0(round(mean,2),
                   " (", round(lower90,2),
                   ",", round(upper90,2),")")] %>%
  .[,.(comparison,tbl)] %>% 
  .[, Age_group := tstrsplit(comparison,"/")[[1]]] %>% 
  .[, .(Age_group,tbl)] %>% 
  setnames("tbl","CP_RR") 

CP_RD_tbl = 
  plot_delta_grps(VLCP_by_day_draws,
                  grp.dt = grp.dt,
                  y.var = "CP",
                  comparisons = my_comparisons,
                  plot =  F) %>%
  .[,tbl := paste0(round(mean,2),
                   " (", round(lower90,2),
                   ",", round(upper90,2),")")] %>%
  .[,.(comparison,tbl)] %>% 
  .[, Age_group := tstrsplit(comparison,"–")[[1]]] %>% 
  .[, .(Age_group,tbl)] %>% 
  setnames("tbl","CP diff") 

VL_diff_tbl = 
  plot_delta_grps(VLCP_by_day_draws,
                  grp.dt = grp.dt,
                  comparisons = my_comparisons,
                  plot =  F) %>%
  .[,tbl := paste0(round(mean,2),
                   " (", round(lower90,2),
                   ",", round(upper90,2),")")] %>%
  .[,.(comparison,tbl)] %>% 
  .[, Age_group := tstrsplit(comparison,"–")[[1]]] %>% 
  .[, .(Age_group,tbl)] %>% 
  setnames("tbl","VL diff")
  save(TC_by_age_grp2,CP_RR_tbl,CP_RD_tbl,VL_diff_tbl,TC_by_age_grp2_peak_VLCB_tbl,file = "pdata/TC_by_age_grp2.Rdata")
}

 
a_lvls = c("0-5","5-10","10-15","15-20","20-45","45-55","55-65","65+")
TC_by_age_grp2_peak_VLCB_tbl =
  TC_by_age_grp2_peak_VLCB_tbl %>% 
  merge(VL_diff_tbl[, Age_group := gsub("–45-55","",Age_group)], by = "Age_group", all.x = T) %>% 
  merge(CP_RD_tbl[, Age_group := gsub("–45-55","",Age_group)], by = "Age_group", all.x = T) %>% 
  merge(CP_RR_tbl[, Age_group := gsub("–45-55","",Age_group)], by = "Age_group", all.x = T) %>% 
  .[, Age_group := factor(Age_group, levels = a_lvls)] %>% 
  .[order(Age_group)]

TC_by_age_grp2_peak_VLCB_ftbl = 
  flextable(TC_by_age_grp2_peak_VLCB_tbl) %>%
  autofit() %>%
  set_caption(caption = "Peak viral load and culture probability by age group. All differences and risk ratios are in comparison to the age group 45-45.")


save_as_docx(TC_by_age_grp2_peak_VLCB_ftbl,path = "figures/Table_S5.docx")

table_doc <- table_doc %>%
  body_add_flextable(TC_by_age_grp2_peak_VLCB_ftbl) %>%
  body_end_section_landscape() 

TC_by_age_grp2
rm(VL_diff_tbl,CP_RD_tbl,CP_RR_tbl)
tmp = gc(verbose = F)
```



```{r CPVLbyPAMS, fig.cap="Viral load and culture positvity time courses by clinical status at the first positive test and hospitalization", eval = T}
grp.dt.Group = 
  unique(day_data[,.(ID,PAMS1,Hospitalized)]) %>% 
  .[, Group := ifelse(PAMS1 == 1,
                      "PAMS",
                      ifelse(Hospitalized == 1,
                             "Hospitalized","Other"))] %>% 
  .[, Group := factor(Group,levels = c("Hospitalized","PAMS","Other"))] %>% 
  .[, PAMS1 := NULL] %>% 
  .[, Hospitalized := NULL]

if (file.exists("pdata/TC_by_PAMSHosp.Rdata")) {
  load("pdata/TC_by_PAMSHosp.Rdata")
} else {
  TC_by_PAMSHosp = 
  plot_by_day_grp_delta(VLCP_by_day_draws,
                      grp.dt = grp.dt.Group)
  TC_by_PAMSHosp[[1]] = TC_by_PAMSHosp[[1]] + red_blue(c(3,2,1))
  TC_by_PAMSHosp[[2]] = TC_by_PAMSHosp[[2]] + red_blue(c(3,2,1))
  save(TC_by_PAMSHosp,file = "pdata/TC_by_PAMSHosp.Rdata")
}

TC_by_PAMSHosp

p_PAMS_Hosp = (TC_by_PAMSHosp[[1]] + theme(legend.title = element_blank(), legend.position = c(.7, .9))) | (TC_by_PAMSHosp[[2]] + theme(legend.position = "none"))
ggsave(p_PAMS_Hosp,filename = "figures/S9_TC_PAMS_Hosp.png", width = 20, height = 10, units = "cm")
ggsave(p_PAMS_Hosp,filename = "figures/S9_TC_PAMS_Hosp.pdf", width = 20, height = 10, units = "cm")
rm(TC_by_PAMSHosp,p_PAMS_Hosp)
```

```{r PAMSHospbtyAge, fig.cap="Viral load time courses by clinical status and age group.", fig.height=8}

day_data %>% 
  .[, Age_group2 := cut(Age,
                          breaks = c(0,20,45,55,101),
                          ordered_result = T,
                          labels = c("0-20","20-45","45-55","55+"))] %>% 
  .[, Group := ifelse(PAMS1 == 1,
                      "PAMS",
                      ifelse(Hospitalized == 1,
                             "Hospitalized","Other"))] %>% 
  .[, Group := factor(Group,levels = c("Hospitalized","PAMS","Other"))] %>% 
  .[, Group_Age := paste0(Group,"_",Age_group2)]

grp.dt = unique(day_data[,.(ID,Group_Age)])
grp.var = "Group_Age"

if (file.exists("pdata/Group_Age.Rdata")) {
  load("pdata/Group_Age.Rdata")
} else {
  by_day_grp = 
    do.call(rbind,
            lapply(unique(grp.dt[[grp.var]]), 
                   function(x) {
                     idx = grp.dt[get(grp.var) == x,ID]
                     VLCP_by_day_draws[ID %in% idx,
                                  list(log10Load = collapse::fmean(log10Load)),
                                  by = .(.draw,day_shifted)] %>% 
                       melt(id.vars = c(".draw", "day_shifted")) %>% 
                       get_stats(by = c("variable","day_shifted")) %>% 
                       .[,(grp.var) := x]
                   })
    )
    by_day_grp %>% 
      .[, c("Group", "Age") := tstrsplit(Group_Age,"_")] %>% 
      .[, Age := ordered(Age,levels = c("0-20","20-45","45-55","55+"))]
    save(by_day_grp, file = "pdata/Group_Age.Rdata")
}


p_Group_Age = 
  by_day_grp %>% 
  ggplot(aes(x = day_shifted, y = mean, color = Group)) + 
  geom_line() + 
  conf_ribbon(by_day_grp, fill = "Group") + 
  facet_wrap(~Age) + 
  coord_cartesian(xlim = c(-5,25), ylim = c(0,9)) +
  theme(legend.position = c(.25,.6)) + 
  ylab(expression(log[10]~viral~load)) +
  xlab("Days from peak viral load") + 
  red_blue(c(3,1,2))

p_Group_Age1 = 
  by_day_grp %>% 
  ggplot(aes(x = day_shifted, y = mean, color = Group)) + 
  geom_line() + 
  conf_ribbon(by_day_grp, fill = "Group") + 
  facet_wrap(~Age, nrow = 1) + 
  coord_cartesian(xlim = c(-5,25), ylim = c(0,9)) +
  theme(legend.position = c(.125,.3)) + 
  ylab(expression(log[10]~viral~load)) +
  xlab("Days from peak viral load") + 
  red_blue(c(3,1,2)) + 
  theme(axis.title.x = element_blank())

p_Age_Group2 = 
  by_day_grp[!is.na(Age)] %>%
  ggplot(aes(x = day_shifted, y = mean, color = Age)) + 
  geom_line() + 
  conf_ribbon(by_day_grp, fill = "Age") + 
  facet_wrap(~Group,ncol = 4) + 
  coord_cartesian(xlim = c(-5,25), ylim = c(0,9)) +
  theme(legend.position = c(.125,.4)) + 
  ylab(expression(log[10]~viral~load)) +
  xlab("Days from peak viral load") 

p_Age_Group = p_Group_Age1 / p_Age_Group2

p_Group_Age
ggsave(p_Group_Age,filename = "figures/S13_Group_Age.png", width = 20, height = 20, units = "cm")
ggsave(p_Age_Group,filename = "figures/S13b_Group_Age.png", width = 20, height = 15, units = "cm")
ggsave(p_Group_Age,filename = "figures/S13_Group_Age.pdf", width = 20, height = 20, units = "cm")
ggsave(p_Age_Group,filename = "figures/S13b_Group_Age.pdf", width = 20, height = 15, units = "cm")
```



```{r CPVLbyPAMSB117, eval = T, fig.cap="Viral load and culture probability time courses by by B.1.1.7 and clinical status at the first positive test"}
day_data %>% 
  .[, PAMSf := factor(PAMS1,labels = c("non-PAMS","PAMS"))] %>% 
  .[, B117f := factor(B117,labels = c("non-B.1.1.7","B.1.1.7"))] %>% 
  .[, B117_PAMS := paste0(PAMSf,",",B117f)]

if (file.exists("pdata/TC_by_B117PAMS.Rdata")) {
  load("pdata/TC_by_B117PAMS.Rdata")
} else {
  TC_by_B117PAMS = 
  plot_by_day_grp_delta(VLCP_by_day_draws,
                      grp.dt = unique(day_data[,.(ID,B117_PAMS)]))
  save(TC_by_B117PAMS,file = "pdata/TC_by_B117PAMS.Rdata")
}

TC_by_B117PAMS
tmp = gc(verbose = F)
```

```{r CPVLbyB117, eval = T, fig.cap="Viral load and culture positvity time courses by by B.1.1.7 status"}
if (file.exists("pdata/TC_by_B117.Rdata")) {
  load("pdata/TC_by_B117.Rdata")
} else {
  TC_by_B117 = 
  plot_by_day_grp_delta(VLCP_by_day_draws,
                      grp.dt = unique(day_data[,.(ID,B117f)]))
  save(TC_by_B117,file = "pdata/TC_by_B117.Rdata")
}

TC_by_B117
tmp = gc(verbose = F)
```

```{r CPVLbyDayGender, fig.cap="Viral load and culture positivity time courses by gender and differences in culture probability"}
day_data[, Male := if_else(Gender == 0,1,0)][is.na(Male), Male := 0][, Male := factor(Male)]

if (file.exists("pdata/TC_by_Gender.Rdata")) {
  load("pdata/TC_by_Gender.Rdata")
} else {
  TC_by_Gender = 
    plot_by_day_grp_delta(VLCP_by_day_draws,
                          grp.dt = unique(day_data[,.(ID,Male)]))
  save(TC_by_Gender,file = "pdata/TC_by_Gender.Rdata")
}


TC_by_Gender
tmp = gc(verbose = F)
```


### Viral load and culture probability at -2, 0, 5, and 10 days from peak viral load

```{r VLbyKeyDayAge, fig.cap="Estimated viral load at key time points by age group. The shaded lines cover the 90% credible interval."}

VLCP_by_keydays_draws = 
  VLCP_by_day_draws %>% 
  .[day_shifted %in% c(-2,0,5,10)] %>% 
  .[unique(day_data[, .(ID,Age_group)]),Age_group := Age_group]

plot_VL_key_days_by_Age = 
  plot_key_days_by_age(VLCP_by_keydays_draws,
                       target.var = "log10Load",
                       var = "log10Load") + 
  ylab(expression(log[10]~viral~load)) + 
  coord_cartesian(ylim = c(0,10)) + 
  scale_y_continuous(expand = expansion(.01,0))
plot_VL_key_days_by_Age 
tmp = gc(verbose = F)
```

### Age differences in peak viral load and culture probability

Figure \@ref(fig:AgeCompVLday0) shows comparisons of all age groups with the age group 45-55 for the day of peak viral load.

```{r AgeCompVLday0, fig.cap="Age differences in maximal viral load. Adjusted refers to adjustment for clinical status."}

if (file.exists("pdata/peak_load_by_age_draws.Rdata")) {
  load("pdata/peak_load_by_age_draws.Rdata")
} else {
  CPpars = draws %>% 
    subset_draws(c("alpha_CP","beta_CP")) %>% 
    as_draws_dt() %>% 
    setkeyv(".draw")
  est_TC_PHG_by_Age()
  peak_load_by_age_draws_full = 
    do.call(rbind,
            lapply(c(T,F), 
                   function(adj) 
                     cond_eff_contPGH("intercept", round_Age = 2,adjust = adj) %>%
                     .[, parameter := NULL] %>% 
                     .[, .draw := as.integer(.draw)] %>% 
                     setkeyv(".draw") %>% 
                     setnames("value","VL") %>% 
                     .[CPpars, CP := inv.logit(alpha_CP + VL * `beta_CP[1]`)] %>% 
                     .[ , Adjusted := adj]
            )
    )
  
  peak_load_by_age_draws_full %>% 
    .[, Age_group := cut(Age,
                         breaks = c(seq(0,20,5),45,55,65,101),
                         ordered_result = T,
                         labels = c("0-5","5-10","10-15","15-20","20-45","45-55","55-65","65+"))] %>% 
    .[, Age := round(Age)]
  
  peak_load_by_age_draws = 
    peak_load_by_age_draws_full %>% 
    .[,.(VL = mean(VL), CP = mean(CP)), by = .(.draw,Age,Adjusted)]
  
  peak_load_by_age_group_draws = 
    peak_load_by_age_draws_full %>% 
    .[,.(VL = mean(VL), CP = mean(CP)), by = .(.draw,Age_group,Adjusted)]
  
  rm(peak_load_by_age_draws_full,draws,CPpars)
  
  save(peak_load_by_age_draws,peak_load_by_age_group_draws,file = "pdata/peak_load_by_age_draws.Rdata")
}



comp = peak_load_by_age_draws[Age > 44 & Age < 55 , .(m = mean(VL)), by = .(adjusted,.draw)]
setkeyv(comp,c(".draw","adjusted"))
setkeyv(peak_load_by_age_draws,c(".draw","adjusted"))
pdata = 
  peak_load_by_age_draws %>% 
  .[comp, delta := VL - m] %>% 
  get_stats(var = "delta",by = c("Age","adjusted")) %>% 
  .[,Adjustment := ifelse(adjusted == T,"Yes","No")]
delta_grand_mean = 
  peak_load_by_age_draws[,.(m = mean(VL)), by = .(adjusted)] %>% 
  merge(comp[,.(m = mean(m)), by = .(adjusted)], by = "adjusted") %>% 
  .[, delta := m.x - m.y] %>% 
  .[,Adjustment := ifelse(adjusted == T,"Yes","No")]
p_deltaVL_peak = 
  pdata %>% 
  ggplot(aes(x = Age, y = mean, color = Adjustment, fill = Adjustment, group = Adjustment)) +
  scale_fill_discrete_diverging("Blue-Red 2") +
  scale_color_discrete_diverging("Blue-Red 2") +
  geom_line() +
  conf_ribbon(pdata,fill = "Adjustment") + 
  geom_hline(yintercept = 0) + 
  coord_cartesian(ylim = c(-1,1), xlim = c(0,101)) +  
  ylab("Estimated peak viral load difference") + 
  geom_hline(data = delta_grand_mean,
             aes(yintercept = delta, color = Adjustment), lty = 3) + 
  theme(legend.position = c(.15,.9)) + 
  gg_expand() + 
  gg_add_grid()

comp = peak_load_by_age_draws[Age > 44 & Age < 55 , .(m = mean(CP)), by = .(adjusted,.draw)]
setkeyv(comp,c(".draw","adjusted"))
pdata = 
  peak_load_by_age_draws %>% 
  .[comp, delta := CP - m] %>% 
  get_stats(var = "delta",by = c("Age","adjusted")) %>% 
  .[,Adjustment := ifelse(adjusted == T,"Yes","No")]
delta_grand_mean = 
  peak_load_by_age_draws[,.(m = mean(CP)), by = .(adjusted)] %>% 
  merge(comp[,.(m = mean(m)), by = .(adjusted)], by = "adjusted") %>% 
  .[, delta := m.x - m.y] %>% 
  .[,Adjustment := ifelse(adjusted == T,"Yes","No")]
p_deltaCP_peak = 
  pdata %>% 
  ggplot(aes(x = Age, y = mean, color = Adjustment, fill = Adjustment, group = Adjustment)) +
  scale_fill_discrete_diverging("Blue-Red 2") +
  scale_color_discrete_diverging("Blue-Red 2") +
  geom_line() +
  conf_ribbon(pdata,fill = "Adjustment") + 
  geom_hline(yintercept = 0) + 
  coord_cartesian(ylim = c(-.4,.4), xlim = c(0,101)) +  
  ylab("Culture probability difference") + 
  geom_hline(data = delta_grand_mean,
             aes(yintercept = delta, color = Adjustment), lty = 3) + 
  theme(legend.position = c(.15,.9)) + 
  gg_expand() + 
  gg_add_grid()

p_deltaVL_peak | p_deltaCP_peak
```


```{r TBLpeakVLCPdiff}
comps = setdiff(levels(peak_load_by_age_group_draws$Age_group),"45-55")
setkeyv(peak_load_by_age_group_draws, c(".draw","adjusted","Age_group"))

peak_VLCP_diffs_tbl = 
  do.call(rbind,
        lapply(comps, 
               function(comp)
                 peak_load_by_age_group_draws %>% 
                 .[Age_group %in% c("45-55",comp)] %>% 
                 .[, .(deltaCP = diff(CP)*ifelse(comp %in% comps[1:5],-1,1), 
                       deltaVL = diff(VL)*ifelse(comp %in% comps[1:5],-1,1)), 
                   by = .(adjusted,.draw)] %>% 
                 .[, .(VL = sprint_stat(deltaVL),CP = sprint_stat(deltaCP,2)), by = .(adjusted)] %>% 
                 .[, `Age group` := comp])
) %>% 
  .[, .(`Age group`,adjusted,VL,CP)] %>% 
  .[, `Age group` := factor(`Age group`,levels = levels(peak_load_by_age_group_draws$Age_group))] %>% 
  setkeyv(c("adjusted","Age group"))


tbl_peak_VLCP_diffs_tbl = 
  kable(peak_VLCP_diffs_tbl,
        format = table_format,
        caption = "Differences in peak viral load between age groups") %>% 
  kable_styling(full_width = F)
tbl_peak_VLCP_diffs_tbl
```

Here are the age-specific results for results for culture probability.

```{r CPbyDayAge, fig.cap="Estimated culture probability at key time points by age group. The shaded lines cover the 90% credible interval."}
day_data[, Age_group := cut(Age,
                         breaks = c(seq(0,20,5),45,55,65,101),
                         ordered_result = T,
                         labels = c("0-5","5-10","10-15","15-20","20-45","45-55","55-65","65+"))]

plot_CP_key_days_by_Age = 
  plot_key_days_by_age(VLCP_by_keydays_draws,
                       target.var = "CP",
                       var = "CP") + 
  ylab("Culture probability") + 
  coord_cartesian(ylim = c(0,1)) +
  scale_y_continuous(expand = expansion(.01,0))
plot_CP_key_days_by_Age
```

The variation in culture infectiousness within age groups appear to be larger than the variation between age groups.

```{r save_word_tables}
table_doc %>%
  print( target = "figures/Tables.docx" )
```


```{r sampleDescripionResults, echo = F, eval = F}
dt = 
  get_full_data() %>% 
  .[log10Load < 0, log10Load := NA]
dt[, positive := ifelse(is.na(log10Load),F,T)]

N_time_course = format(length(unique(day_data$ID)),big.mark = ",")
num_subjects = format(length(unique(dt$personHash)),big.mark = ",")
min_date = min(dt$Date)
max_date = max(dt$Date)
num_positive = format(sum(dt$positive == T),big.mark = ",")
percent_positive = round(mean(dt$positive)*100,2)
num_PAMS = format(sum(dt[positive == T, Group]  == "PAMS"),big.mark = ",")
percent_PAMS = round(mean(dt[positive == T, Group]  == "PAMS")*100,2)
num_pub_test_centre = format(nrow(dt[TestCentreCategory %in% c("C19")]),big.mark = ",")
num_positive_pub_test_centre = format(
  nrow(dt[positive == T & TestCentreCategory == "C19",]),big.mark = ",")
percent_positive_pub_test_centre = 
  round(mean(dt[TestCentreCategory == "C19",positive])*100,2)
num_AIR = format(nrow(dt[TestCentreCategory %in% c("AIR")]),big.mark = ",")
num_positive_AIR = format(
  sum(dt[TestCentreCategory %in% c("AIR"), positive]),big.mark = ",")
percent_positive_AIR = 
  round(mean(dt[TestCentreCategory %in% c("AIR"), positive])*100,2)
num_hospitalized = format(sum(dt[positive == T,Hospitalized]),big.mark = ",")
percent_hospitalized = round(mean(dt[positive == T,Hospitalized])*100)
num_TinHosp = format(sum(bdata$TestCentreCategory %in% HOSPITAL_TEST_CENTRE),big.mark = ",")
percent_TinHosp = round(mean(bdata$TestCentreCategory %in% HOSPITAL_TEST_CENTRE)*100)
delta_load_children_adults = mean(bdata[Age > 20 & Age < 65 & PAMS1 == 1, log10Load])-mean(bdata[Age < 20 & PAMS1 == 1, log10Load])

tmp = 
  bfitdata %>% 
  .[,cAge := cut(Age, breaks = c(seq(0,80,5),90,101), ordered = T)] %>% 
  .[, .(m = mean(log10Load), N = .N), by = .(cAge, Group)] %>%
  .[Group != "Other"] %>% 
  setkeyv(c("cAge","Group")) %>% 
  .[, .(delta = diff(m), N = sum(N)), by = .(cAge)] %>% 
  .[, w := N/sum(N)]
delta_PAMS = round(-sum(tmp$delta * tmp$w),2)
delta_05_2065 = round(mean(bfitdata[age_group == "[20,65)",log10Load]) - mean(bfitdata[age_group == "[0,5)",log10Load]),2)
```


```{r tmpresults2, eval = F, echo = F}
CP_diffs_Hospitalized = 
  stats_agegroup_diff[sample == "Hospitalized" & outcome == "CP"] 
```

```{r B117stats, eval = F, echo = F}
deltaB117 = t.test(bdata[B117 == "B117",log10Load],bdata[B117 == "non-B117",log10Load])
deltaB117est = sprint_stat(B117fit$fit %>%  as_draws() %>% subset_draws("b_B117B117") %>% as.vector())
rm(B117fit)
```

# Figures

## Figure 1: First positive test - with raw data

The mean first-positive viral load for PAMS and Hospitalised subjects of age 50 are `r bfitdata[ceiling(Age) == 50 & Group == "PAMS", log10Load] %>% sprint_stat()` and `r bfitdata[ceiling(Age) == 50 & Group == "Hospitalized", log10Load] %>% sprint_stat()`, respectively.

```{r makeFigure1, fig.cap="Distribution of age and first-positive viral load in PAMS, Hospitalised, and Other subjects. A) Distribution of observed first-positive viral loads for 25,381 subjects according to clinical status (6110 PAMS, 9519 Hospitalised, 9752 Other) and age group. B) Age-viral load association with observed viral loads and confidence intervals as circles (with size indicating subject count) with vertical lines, and model-predicted viral loads and credible intervals as a black roughly-horizontal line with grey shading. C) Overlapping age histograms according to subject clinical status. Because inclusion in the study required a positive RT-PCR test result, and testing is in many cases symptom-dependent, the study may have a proportion of PAMS cases that differs from the proportion in the general population.", fig.width=30/2.54, fig.height=25/2.54}

ppc_VL_by_age = 
  ppc_VL_by_age + 
  guides(size = guide_legend(title.position = "left",nrow = 1),
         color = guide_legend(title.position = "left",nrow = 1)) +
  scale_size(range = c(0, 3),guide = guide_legend(nrow = 1),breaks = c(0,25,50,100,250,500)) +
  coord_cartesian(ylim = c(4,8)) +
  gg_add_grid()


F1 = 
  (beesPAMS + ggtitle("A")) /
  (ppc_VL_by_age + ggtitle("B")) / 
  (agehist_by_PAMS  + ggtitle("C")) +
  plot_layout(heights = c(1.5,1,.5))

ggsave(F1,filename = "figures/F1.png", width = 30, height = 25, units = "cm", dpi = 300) 
ggsave(F1,filename = "figures/F1.pdf", width = 30, height = 25, units = "cm") 
#save(F1,file = "figures/F1.Rdata")
F1
rm(ppc_VL_by_age,F1,agehist_by_PAMS)
tmp = gc(verbose = F)
```

## Figure 2: First positive test - age differences

```{r makeFigure2, fig.cap= "Estimated viral load and culture probability at time of first positive RT-PCR test. Shaded regions show 90% credible intervals in all panels. To indicate change within each 90% region, shading decreases in intensity from a narrow 50% credibility interval level to the full 90%. A) Estimated mean viral load in first-positive RT-PCR test according to age and status. The stacked histogram (right) shows the observed viral load distribution. Small age-year to age-year variations in the proportion of subjects groups cause the fluctuations in the estimated viral loads for the total sample. Because the shaded region shows the 90% credible interval for the mean, it does not include the higher values shown in the histogram on the right. B) Differences in estimated first-positive viral load according to age and status. Each coloured line is specific to a particular subset of subjects (PAMS, Hospitalised, Other). The line shows how viral load differs by age for subjects of the corresponding status from that of 50-year old (rounded age) subjects of the same status. The comparison against those of age 50 avoids comparing any subset of the subjects against a value (such as the overall mean) that is computed in part based on that subset, thereby partially comparing data to itself. The mean first-positive viral load for PAMS and Hospitalised subjects of age 50 are 7.2 and 6.2, respectively, allowing relative y-axis differences to be translated to approximate viral loads. C) Estimation of the association between viral load and cell culture isolation success rate based on data from our own laboratory (19) and the study of Perera et al. (20). Viral load differences in the range ~6 to ~9 have a large impact on culture probability, while the impact is negligible for differences outside that range. The vertical lines indicate the observed mean first-positive viral load for different subject groups and the horizontal lines the corresponding expected probability of a positive culture. D) Estimated culture probability at time of first-positive RT-PCR according to age and status, obtained by combining the results in panels A and C. Culture probability is calculated from posterior predictions, that is the posterior means shown in panel A plus error variance. The histogram on the right shows that mean culture probabilities calculated from observed log10 viral load values are not well-matched by credible intervals, which do not include the most-probable estimated culture probabilities. E) Same y-axis as D. Culture probability with highest posterior density regions, which do include the most-probable estimated culture probabilities and match the histograms in D well. F) Differences of estimated expected culture probability at time of first-positive RT-PCR for age groups, with plot elements as described for B.", fig.width=30/2.54, fig.height=24/2.54}

### F2A: load by age + marginal histogram 
## load by age ##
checks = c(mean(bdata$log10Load),0,10)
levels(bfitdata$Group) = Group_levels
my_VL_hist_age =
  ggplot(bdata, aes(x = log10Load, fill = Group)) + 
  red_blue_black() +
  geom_histogram(bins = 20, alpha = .5) + 
  gg_text_size() +
  gg_expand() + 
  theme_marginal() + 
  theme(legend.position = c(.5,.15))  +
  gg_add_grid(axis = "y") +  
  theme(axis.title = element_blank()) +
  coord_flip(xlim= c(2,11)) +
    theme(axis.title.y.left = element_blank(), legend.position = "none") 

p_load_by_age_hist = 
  wrap_plots(
    p_load_by_age + 
      theme(plot.margin = margin(0,-5,0,0, unit = "pt")) + 
      gg_add_grid() +
      coord_cartesian(ylim = c(2,11)) + 
      gg_expand(), 
    my_VL_hist_age, 
    widths = c(1,.3)
  )
p_load_by_age_hist[[1]] = p_load_by_age_hist[[1]] + ggtitle("A")

### F2B: Viral load differences between age groups
p_age_comp_VL = 
  p_age_comp_VL + 
  gg_add_grid("y") + 
  guides(color = guide_legend(ncol = 1, keywidth = .25, keyheight = .25)) + 
  theme(legend.position = my_legend_position) + 
  labs(fill = "Sample") +
  gg_legend_size(ncol = 1) + 
  gg_text_size() +
  coord_cartesian(ylim = c(-3,3)) + 
  ggtitle("B")

### F2C: Culture infectivity by viral load
culture_data[, Outcome := ifelse(culture_positive == 1,
                                 paste0("pos. (",sum(culture_data$culture_positive),")"),
                                 paste0("neg. (",sum(culture_data$culture_positive == 0),")"))]

p_CP_hist = 
  ggplot(culture_data, aes(x = log10Load, fill= Outcome)) + 
  geom_histogram(bins = 20) + 
  coord_cartesian(xlim = c(1,10)) +
  theme(legend.position = c(.0,.8)) +
  gg_legend_size(1) + 
  gg_expand() + 
  guides(fill = guide_legend(ncol = 1,
                             keywidth = .25,
                             keyheight = .25)) + 
  gg_text_size() +
  theme_marginal() + 
  ylab("") +  xlab("")

p_CP_by_load_hist = 
  wrap_plots(
    p_CP_hist,
    p_CP_by_load + 
      gg_add_grid() + 
      theme(plot.margin = margin(-5,0,0,0, unit = "pt")), 
    heights = c(.2,1)
  )
p_CP_by_load_hist[[1]] = p_CP_by_load_hist[[1]] + ggtitle("C")

### F2D: CP by age ###
CPpars =
  CP.fit$fit %>% 
  as_draws() %>% 
  subset_draws(c("b_Intercept","b_log10Load")) %>% 
  as_draws_dt()
CP_alpha = mean(CPpars$b_Intercept)
CP_beta = mean(CPpars$b_log10Load)

h_data_age = rbind(
  data.table(CP = inv.logit(CP_alpha + bfitdata[Group == "PAMS",log10Load]*CP_beta), sample = "PAMS"),
  data.table(CP = inv.logit(CP_alpha + bfitdata[Group == "Hospitalized",log10Load]*CP_beta), sample = "Hospitalized"),
  data.table(CP = inv.logit(CP_alpha + bfitdata[Group == "Other",log10Load]*CP_beta), sample = "Other")
) %>% 
  .[, sample := factor(sample, levels = levels(p_CP_by_age$data$sample))]

lbl_data =
  data.table(sample = unique(h_data_age$sample), 
             CP = .5,
             x = 1500)

checks = c(c(0,.5,1))
my_CP_hist_age =
  ggplot(h_data_age, aes(x = CP, fill = sample)) + 
  geom_text(data = lbl_data,
            aes(x = CP, y = x, label = sample), angle = 270,size = 3) +
  red_blue_black() +
  geom_histogram(bins = 20, alpha = .5) + 
  ylab("")  + 
  gg_text_size() +
  theme_marginal() + 
  gg_expand() + gg_add_grid("y") +
  coord_flip(xlim = c(-.01,1.01)) +
  theme(axis.title.y.left = element_blank(),
        legend.position = c(.6,.5)) +
  gg_legend_size(1) + 
  gg_expand() + 
  facet_grid(sample~.) +
  theme(legend.position = "none", strip.text.y = element_blank())

p_CP_hdi_by_age_hist = 
  wrap_plots(
    p_CP_by_age +
      theme(plot.margin = margin(0,-5,0,0, unit = "pt"),
            legend.position = "none",strip.text.y = element_blank()) + 
      facet_grid(sample~.) +
      gg_expand() +
      gg_add_grid() +
      gg_text_size(),
    my_CP_hist_age +  theme(legend.position = "none"), 
    widths = c(1,.3),
    ncol = 2
  ) 

### F2E: CP by age HDI ###
p_CP_by_Age.hdi = 
  p_CP_by_Age.hdi.no.postproc + 
  no_y_axis +
  scale_x_continuous(breaks = seq(20,80,20)) +
  facet_grid(Group~.) +
  theme(strip.text.y = element_blank()) +
  gg_expand() + 
  gg_add_grid() +
  ggtitle("E") + 
  gg_text_size()

### F2F: CP differences between age groups
p_age_comp_CP = 
  p_age_comp_CP + 
  gg_add_grid("y") + 
  guides(color = guide_legend(ncol = 1, keywidth = .25, keyheight = .25)) + 
  theme(legend.position = my_legend_position) + 
  labs(fill = "Sample") +
  ggtitle("F")  +
  gg_legend_size(ncol = 1) + 
  coord_cartesian(ylim = c(-.5,.5)) +
  gg_text_size()


p_CP_hdi_by_age_hist[[1]] = p_CP_hdi_by_age_hist[[1]] + ggtitle("D")

F2 = 
((p_load_by_age_hist | p_age_comp_VL | p_CP_by_load_hist) + plot_layout(widths = c(1.5,1,1))) /
    ((p_CP_hdi_by_age_hist | p_CP_by_Age.hdi | p_age_comp_CP) + plot_layout(widths = c(1.5,1.1,1))) 

ggsave(F2,filename = "figures/F2.png",
       width = 30, height = 24, units = "cm", dpi = 300,
       type = "cairo")
ggsave(F2,filename = "figures/F2.pdf",
       width = 30, height = 24, units = "cm")
#save(F2,file = "figures/F2.Rdata")
F2
tmp = gc(verbose = F)
```

## Figure 3: B.1.1.7

```{r makeFigure3, fig.cap="Posterior distributions of estimated viral loads and culture probabilities for B.1.1.7 and non-B.1.1.7 subjects, and their differences. The viral loads and estimated culture probability of 1387 B.1.1.7 and 977 non-B.1.1.7 subjects. To select a comparable subset of non-B.1.1.7 viral loads for the comparison, non-B.1.1.7 subjects were included only from test centres that had detected a B.1.1.7 variant as well as at least one non-B.1.1.7 subject, and only if the non-B.1.1.7 infection was detected on the same day as a B.1.1.7 infection was detected, plus or minus one day. Similar differences exist when viral loads from larger, less restrictive, subsets of non-B.1.1.7 subjects are used in the comparison (Materials and Methods, Table S2).  A) Posterior distribution of log10 viral load. B) Difference of average viral load between B.1.1.7 and non-B.1.1.7 cases. C) Posterior distribution of the estimated culture probability. See also Fig. S2. D) Difference of mean culture probability between B.1.1.7 and non-B.1.1.7 cases. Horizontal lines in A, B, and D indicate 90% credible intervals, and the highest posterior density intervals in C."}
pB117load[[1]] = pB117load[[1]] + gg_legend_size(ncol = 1) + 
  guides(fill = guide_legend(title=element_blank()),
         color = guide_legend(title=element_blank())) + 
  gg_text_size()
pB117cp[[1]] = pB117cp[[1]] + gg_legend_size(ncol = 1) + 
  guides(fill = guide_legend(title=element_blank()))
F3 = pB117load / pB117cp
F3
ggsave(filename = "figures/F3.png",F3, width = 18, height = 12, units = "cm")
ggsave(filename = "figures/F3.pdf",F3, width = 18, height = 12, units = "cm")
#save(F3,file = "figures/F3.Rdata")
```


## Figure 4: Time course

```{r makeFigure4, fig.cap= "Viral load and estimated infectious virus shedding time series. Of 25,381 positive subjects, 4344 had three or more RT-PCR test results available and these were used in a viral load time series analysis. Subjects with only one result cannot be placed in time due to inherent ambiguity from the model having both an increasing and a decreasing phase, and those with only two test results were excluded from the time series analysis due to insufficient data for temporal placement (their number of data points is less than number of model parameters being estimated). A) The number of subjects with three or more RT-PCR test results available, at least two of which were positive, according to age. B) Estimated time course of viral load for 18,136 RT-PCR results from the 4344 subjects with at least three RT-PCR results. Blue lines are expected complete time courses for individual cases. The sample mean is shown in red, with its 90% credible interval as a shaded area. The small histogram on the right shows the distribution of all observed viral loads. The histogram values at zero correspond to the initial and trailing negative tests in subject timelines. Raw viral load time series, per subject and split by number of RT-PCR tests, are shown in Fig. S8. C) Estimated time course of positive cell culture probability, calculated by applying the results shown in Fig. 2C to the estimated viral load time courses in B. Blue lines are expected time courses for individual subjects. The sample average is shown in red, with its 90% credible interval as a shaded area. The small histogram to the right shows the distribution of culture probability in the sample, and was obtained by applying the curve in Fig. 2C to the data in the histogram in B.", fig.width=30/2.54, fig.height=10/2.54}

### F4A: sample for time course test data ###
day_data %>%
  .[, number_tests := cut(N_tests,
                          breaks = c(2.9,3,4,6,9,20),
                          labels = c("3","4","5-6","7-9",">9"),
                          ordered_result = T)]
p_N_time = ggplot(day_data[day == 0], aes(x = Age, fill = number_tests)) +
  geom_histogram(breaks = seq(0,100,5)) + 
  scale_fill_ordinal(name = "Number of tests") +
  theme(legend.position = my_legend_position) +
  gg_text_size() + 
  gg_legend_size(1) + 
  gg_expand() + 
  ylab("Number of subjects")
p_N_time = p_N_time + ggtitle("A")

### F4B: VL time course + histogram
# histogram for time course data
brks = c(-.1,0,.25,.5,.75,.99,1)
lbls = c("0",paste0(c(1,26,51,76),"-",c(25,50,75,99)),"100" )
day_data[, `% tests \nin hosp.` := cut(phosptests,breaks = brks, labels = lbls)]
my_VL_hist_time =
  ggplot(day_data, aes(x = log10Load)) + 
  geom_histogram(bins = 20, fill = "blue", alpha = .5) + 
  coord_cartesian(xlim = c(0,10)) +
  theme(legend.position = c(.7,.9))  +
  ylab("")  + 
  xlab("") +
  coord_flip() +
  gg_text_size() +
  gg_expand() +
  gg_legend_size(1) +
  theme_marginal() + 
  guides(fill = guide_legend(ncol = 1, keywidth = .25, keyheight = .25)) + 
  theme(axis.title.y.left = element_blank())
p_load_by_time_hist = 
  wrap_plots(
    plot_VL_by_day + 
      theme(plot.margin = margin(0,-5,0,0, unit = "pt")) + 
      gg_expand() + 
      gg_add_grid(), 
    my_VL_hist_time , 
    widths = c(1,.3)
  )
p_load_by_time_hist[[1]] = p_load_by_time_hist[[1]] + ggtitle("B") 


### F4C: CP time course + histogram
ddp = day_data[log10Load > 0, c("log10Load","% tests \nin hosp."), with = F]
h_data_time = 
  apply(CPpars[.draw < 500], 1, 
        function(x) 
          inv.logit(x[1] + ddp$log10Load*x[2])) %>%
  data.table() %>%
  .[, `% tests \nin hosp.` := ddp$`% tests \nin hosp.`] %>%  
  .[, TID := 1:nrow(ddp)] %>%
  melt(id.var = c("% tests \nin hosp.","TID"), value.name = "CP") %>%
  .[, .draw := as.numeric(gsub("V","",variable, perl = T))] %>%
  .[, CP := CP*100] %>%
  .[, c("variable",".draw","TID") := NULL]
my_CP_hist_time =
  ggplot(h_data_time, aes(x = CP)) + 
  geom_histogram(bins = 20, fill = "blue", alpha = .5) + 
  coord_cartesian(xlim = c(0,100)) +
  theme(legend.position = c(.6,.9))  +
  gg_text_size() +
  gg_expand() +
  gg_legend_size(1) +
  theme_marginal() + 
  guides(fill = guide_legend(ncol = 1, keywidth = .25, keyheight = .25)) + 
  ylab("")  + 
  coord_flip() +
  theme(axis.title.y.left = element_blank())
p_CP_by_time_hist = 
  wrap_plots(
    plot_CP_by_day + theme(plot.margin = margin(0,-5,0,0, unit = "pt")) + gg_add_grid(), 
    my_CP_hist_time, 
    widths = c(1,.3)
  )
p_CP_by_time_hist[[1]] = p_CP_by_time_hist[[1]]  + ggtitle("C")


F4 = 
  (p_N_time | p_load_by_time_hist | p_CP_by_time_hist) + 
  plot_layout(widths = c(1,1.5,1.5))

ggsave(F4,filename = "figures/F4.png",
       width = 30, height = 10, units = "cm", dpi = 300,
       type = "cairo")
ggsave(F4,filename = "figures/F4.pdf",
       width = 30, height = 10, units = "cm")
F4
#save(F4,file = "figures/F4.Rdata")
rm(F4,p_load_by_time_hist,p_CP_by_time_hist)
tmp = gc(verbose = F)
```

## Figure 5: Peak viral load and culture probability by age

```{r makeFigure5, fig.cap="Estimated expected viral load and culture probability for age groups by time. A) Change in estimated viral load over time according to age group for 4344 subjects with at least three RT-PCR tests, at least two of which were positive. The age colouring, range, and number of subjects in each category is given in the figure legend. Shading indicates the 90% credible interval of the mean. B) Change in estimated culture probability over time according to age. Age groups, colouring, and shading are as in A. C) Estimated age group differences in mean peak viral load, corresponding to the values at day zero in A. D) Estimated age group differences in mean peak culture probability, corresponding to the values at day zero in B. In C and D, adjusted differences account for variations by age in clinical status and gender. Dotted lines indicate grand means for the 4344 subjects.", fig.width=20/2.54, fig.height=20/2.54}
VLCP_by_day_draws[, Age_group := NULL]
grp.dt = unique(day_data[,.(ID,Age_group)])

VL_TC = 
  TC_by_age_grp2[[1]] + 
  gg_add_grid() + 
  ggtitle("A") + 
  coord_cartesian(xlim = c(-5,25), ylim = c(0,10)) 

CP_TC = 
  TC_by_age_grp2[[2]] +
  coord_cartesian(xlim = c(-5,25), ylim = c(0,1)) + 
  gg_expand() + gg_text_size() + 
  theme(legend.position = "none") + 
  gg_add_grid() + ggtitle("B")

p_deltaVL_peak = 
  p_deltaVL_peak + ggtitle("C")
p_deltaCP_peak = 
  p_deltaCP_peak + ggtitle("D")

F5 = 
  (VL_TC | CP_TC) / (p_deltaVL_peak | p_deltaCP_peak)

ggsave("figures/F5.png",F5, width = 20, 
       height = 20, units = "cm",dpi = 300)
ggsave("figures/F5.pdf",F5, width = 20, 
       height = 20, units = "cm")
#save(F5,file = "figures/F5.Rdata")
F5 
rm(F5 ,VL_TC, CP_TC,VL_delta, CP_delta)
```

`r ifelse(show_code == T,"# Stan model for time course estimation","")`

```{r show_group_model, echo=FALSE, results="asis"}
if (show_code == T) {
  tf <- tempfile(fileext=".html")
  cmd = paste0("/Users/guidobiele/anaconda/bin/pygmentize -o %s CP/stan/",model,".stan")
  system(sprintf(cmd, tf))
  cat(readLines(tf), sep="\n")
  unlink(tf)
}
```

# Session Info


```{r}
library(pander)
library(sessioninfo)
my_sessioninfo <- session_info()
pander(my_sessioninfo)
```

# References


